{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: test\n",
    "output-file: template.html\n",
    "title: Template\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# | default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca63bf9ad709420a951a47b32b109da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 20:04:28 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-03-24 20:04:29 INFO: File exists: /home/awchen/stanza_resources/en/default.zip\n",
      "2024-03-24 20:04:32 INFO: Finished downloading models and saved to /home/awchen/stanza_resources.\n",
      "2024-03-24 20:04:32 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc61b6b149f49f1a4819278a3996ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 20:04:33 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| lemma        | combined_nocharlm   |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "| depparse     | combined_charlm     |\n",
      "| sentiment    | sstplus             |\n",
      "| ner          | ontonotes_charlm    |\n",
      "======================================\n",
      "\n",
      "2024-03-24 20:04:33 INFO: Using device: cpu\n",
      "2024-03-24 20:04:33 INFO: Loading: tokenize\n",
      "2024-03-24 20:04:33 INFO: Loading: pos\n",
      "2024-03-24 20:04:33 INFO: Loading: lemma\n",
      "2024-03-24 20:04:33 INFO: Loading: constituency\n",
      "2024-03-24 20:04:34 INFO: Loading: depparse\n",
      "2024-03-24 20:04:34 INFO: Loading: sentiment\n",
      "2024-03-24 20:04:34 INFO: Loading: ner\n",
      "2024-03-24 20:04:34 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# from bertopic import BERTopic\n",
    "# from bertopic.vectorizers import OnlineCountVectorizer\n",
    "import dagshub\n",
    "from datetime import datetime\n",
    "import dill as pickle\n",
    "import dvc.api\n",
    "# from hdbscan import HDBSCAN\n",
    "from itertools import tee, islice, product\n",
    "import joblib\n",
    "import nbdev\n",
    "from nbdev.showdoc import *\n",
    "import pandas as pd\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer\n",
    "    , TfidfTransformer\n",
    "    , TfidfVectorizer\n",
    "    , \n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from src.custom_sklearn_text_transformer_mlflow import CustomSKLearnAnalyzer\n",
    "import src.dataframe_preprocessor as dfpp\n",
    "import stanza\n",
    "from tqdm import tqdm\n",
    "# from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# | export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d459c593be4a89b6f55d99d7ad7aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 20:04:35 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-03-24 20:04:36 INFO: File exists: /home/awchen/stanza_resources/en/default.zip\n",
      "2024-03-24 20:04:39 INFO: Finished downloading models and saved to /home/awchen/stanza_resources.\n",
      "2024-03-24 20:04:39 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e980d5078d124ec99e33d8eace5bc273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 20:04:40 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| lemma        | combined_nocharlm   |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "| depparse     | combined_charlm     |\n",
      "| sentiment    | sstplus             |\n",
      "| ner          | ontonotes_charlm    |\n",
      "======================================\n",
      "\n",
      "2024-03-24 20:04:40 INFO: Using device: cuda\n",
      "2024-03-24 20:04:40 INFO: Loading: tokenize\n",
      "2024-03-24 20:04:42 INFO: Loading: pos\n",
      "2024-03-24 20:04:42 INFO: Loading: lemma\n",
      "2024-03-24 20:04:42 INFO: Loading: constituency\n",
      "2024-03-24 20:04:43 INFO: Loading: depparse\n",
      "2024-03-24 20:04:43 INFO: Loading: sentiment\n",
      "2024-03-24 20:04:43 INFO: Loading: ner\n",
      "2024-03-24 20:04:44 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# instantiate stanza pipeline\n",
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline('en', \n",
    "                    depparse_batch_size=50, \n",
    "                    depparse_min_length_to_batch_separately=50,\n",
    "                    verbose=True,\n",
    "                    use_gpu=True, # set to true when on cloud/not on streaming computer\n",
    "                    batch_size=100\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load raw data and preprocess/clean\n",
    "data = dvc.api.read(\n",
    "    path='../data/recipes-en-201706/epicurious-recipes_m2.json'\n",
    "    , mode='r')\n",
    "raw_df = pd.read_json(data)\n",
    "print('\\n')\n",
    "print('--------------')\n",
    "print('Raw Dataframe:', end='\\n')\n",
    "print(raw_df.head())\n",
    "print(raw_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take sample and train/test split \n",
    "subset_df = raw_df.sample(n=100, random_state=45)\n",
    "train_df, test_df = train_test_split(subset_df,test_size=0.5, random_state=45)\n",
    "\n",
    "# pre_proc_df is cleaned dataframe\n",
    "to_nlp_df = dfpp.preprocess_dataframe(train_df)\n",
    "print('\\n')\n",
    "print('--------------')\n",
    "print('Preprocessed Dataframe:', end='\\n')\n",
    "print(to_nlp_df.head())\n",
    "print(to_nlp_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_params are parameters for the sklearn CountVectorizer or TFIDFVectorizer\n",
    "sklearn_transformer_params = {    \n",
    "    'analyzer': CustomSKLearnAnalyzer().ngram_maker(\n",
    "        min_ngram_length=1,\n",
    "        max_ngram_length=4,\n",
    "        ),\n",
    "    'min_df':3,\n",
    "    # 'binary':False\n",
    "}\n",
    "\n",
    "sklearn_transformer = TfidfVectorizer(**sklearn_transformer_params)\n",
    "\n",
    "model_input = to_nlp_df['ingredients_lemmafied']\n",
    "\n",
    "# Do fit transform on data\n",
    "print(\"fit_transform start: \" + str(datetime.now()))\n",
    "response = sklearn_transformer.fit_transform(tqdm(model_input)) \n",
    "print(\"fit_transform end: \" + str(datetime.now()))\n",
    "\n",
    "transformed_recipe = pd.DataFrame(\n",
    "        response.toarray(),\n",
    "        columns=sklearn_transformer.get_feature_names_out(),\n",
    "        index=model_input.index\n",
    ")\n",
    "\n",
    "print(transformed_recipe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_recipe.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_nlp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare whole dataframe for new processing\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from src.custom_stanza_mlflow import CustomSKLearnWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function allows us to get the experiment ID from an experiment name\n",
    "def get_experiment_id(name):\n",
    "    exp = mlflow.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "      exp_id = mlflow.create_experiment(name)\n",
    "      return exp_id\n",
    "    return exp.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@markdown Enter the username of your DAGsHub account:\n",
    "DAGSHUB_USER_NAME = \"AaronWChen\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the email for your DAGsHub account:\n",
    "DAGSHUB_EMAIL = \"awc33@cornell.edu\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the repo name \n",
    "DAGSHUB_REPO_NAME = \"MeaLeon\"\n",
    "\n",
    "#@markdown Enter the name of the branch you are working on \n",
    "BRANCH = \"NGRAM-1/try-llm-code-speedup\"\n",
    "dagshub.init(repo_name=DAGSHUB_REPO_NAME\n",
    "             , repo_owner=DAGSHUB_USER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting DEV stage for TFIDF Encoded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow')\n",
    "\n",
    "# starter idea for making an experiment name can be the git branch, but need more specificity\n",
    "experiment_name = f\"{DAGSHUB_EMAIL}/OHE_up_to_quadgrams\"\n",
    "mlflow_exp_id = get_experiment_id(experiment_name)\n",
    "\n",
    "# define model location\n",
    "# model_directory = \"/tmp/sklearn_model\"\n",
    "model_directory = \"../models/sklearn_model\"\n",
    "\n",
    "# Define the required artifacts associated with the saved custom pyfunc\n",
    "# sklearn_path = model_directory + \"\"\n",
    "sklearn_model_path = model_directory + \"/python_model.pkl\"\n",
    "sklearn_transformer_path = model_directory + \"/sklearn_transformer.pkl\"\n",
    "transformed_recipes_path = model_directory + \"/transformed_recipes.pkl\"\n",
    "combined_df_path = model_directory + \"/combined_df.pkl\"\n",
    "\n",
    "artifacts = {'sklearn_model': sklearn_model_path,\n",
    "             'sklearn_transformer': sklearn_transformer_path,\n",
    "             'transformed_recipes': transformed_recipes_path,\n",
    "             'combined_data': combined_df_path\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_proc_df is cleaned dataframe\n",
    "print(\"Preprocess start: \" + str(datetime.now()))\n",
    "whole_nlp_df = dfpp.preprocess_dataframe(raw_df)\n",
    "print(\"Preprocess end: \" + str(datetime.now()))\n",
    "print('\\n')\n",
    "print('--------------')\n",
    "print('Preprocessed Dataframe: ', end='\\n')\n",
    "print(whole_nlp_df.head())\n",
    "print(whole_nlp_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_nlp_df.to_parquet('../joblib/2024.03.19/pre_proc_df.parquet.gzip', \n",
    "                        compression='gzip',\n",
    "                        index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dek</th>\n",
       "      <th>hed</th>\n",
       "      <th>aggregateRating</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>prepSteps</th>\n",
       "      <th>reviewsCount</th>\n",
       "      <th>willMakeAgainPct</th>\n",
       "      <th>ingredients_lemmafied</th>\n",
       "      <th>cuisine_name</th>\n",
       "      <th>photo_filename</th>\n",
       "      <th>photo_credit</th>\n",
       "      <th>author_name</th>\n",
       "      <th>date_published</th>\n",
       "      <th>recipe_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54a2b6b019925f464b373351</th>\n",
       "      <td>How does fried chicken achieve No. 1 status? B...</td>\n",
       "      <td>Pickle-Brined Fried Chicken</td>\n",
       "      <td>3.11</td>\n",
       "      <td>[1 tablespoons yellow mustard seeds, 1 tablesp...</td>\n",
       "      <td>[Toast mustard and coriander seeds in a dry me...</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>tablespoon yellow mustard seed brk tablespoon ...</td>\n",
       "      <td>Missing Cuisine</td>\n",
       "      <td>51247610_fried-chicken_1x1.jpg</td>\n",
       "      <td>Michael Graydon and Nikole Herriott</td>\n",
       "      <td>Missing Author Name</td>\n",
       "      <td>2014-08-19 04:00:00+00:00</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a408a019925f464b3733bc</th>\n",
       "      <td>Spinaci all'Ebraica</td>\n",
       "      <td>Spinach Jewish Style</td>\n",
       "      <td>3.22</td>\n",
       "      <td>[3 pounds small-leaved bulk spinach, Salt, 1/2...</td>\n",
       "      <td>[Remove the stems and roots from the spinach. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>pound small leave bulk spinach brk salt brk cu...</td>\n",
       "      <td>Italian</td>\n",
       "      <td>EP_12162015_placeholders_rustic.jpg</td>\n",
       "      <td>Photo by Chelsea Kyle, Prop Styling by Anna St...</td>\n",
       "      <td>Edda Servi Machlin</td>\n",
       "      <td>2008-09-09 04:00:00+00:00</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a408a26529d92b2c003631</th>\n",
       "      <td>This majestic, moist, and richly spiced honey ...</td>\n",
       "      <td>New Year’s Honey Cake</td>\n",
       "      <td>3.62</td>\n",
       "      <td>[3 1/2 cups all-purpose flour, 1 tablespoon ba...</td>\n",
       "      <td>[I like this cake best baked in a 9-inch angel...</td>\n",
       "      <td>105</td>\n",
       "      <td>88</td>\n",
       "      <td>cup purpose flour brk tablespoon baking powder...</td>\n",
       "      <td>Kosher</td>\n",
       "      <td>EP_09022015_honeycake-2.jpg</td>\n",
       "      <td>Photo by Chelsea Kyle, Food Styling by Anna St...</td>\n",
       "      <td>Marcy Goldman</td>\n",
       "      <td>2008-09-10 04:00:00+00:00</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a408a66529d92b2c003638</th>\n",
       "      <td>The idea for this sandwich came to me when my ...</td>\n",
       "      <td>The B.L.A.Bagel with Lox and Avocado</td>\n",
       "      <td>4.00</td>\n",
       "      <td>[1 small ripe avocado, preferably Hass (see No...</td>\n",
       "      <td>[A short time before serving, mash avocado and...</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>small ripe avocado hass see note brk teaspoon ...</td>\n",
       "      <td>Kosher</td>\n",
       "      <td>EP_12162015_placeholders_casual.jpg</td>\n",
       "      <td>Photo by Chelsea Kyle, Prop Styling by Rhoda B...</td>\n",
       "      <td>Faye Levy</td>\n",
       "      <td>2008-09-08 04:00:00+00:00</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a408a719925f464b3733cc</th>\n",
       "      <td>In 1930, Simon Agranat, the chief justice of t...</td>\n",
       "      <td>Shakshuka a la Doktor Shakshuka</td>\n",
       "      <td>2.71</td>\n",
       "      <td>[2 pounds fresh tomatoes, unpeeled and cut in ...</td>\n",
       "      <td>[1. Place the tomatoes, garlic, salt, paprika,...</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>pound fresh tomato unpeeled cut quarter ounce ...</td>\n",
       "      <td>Kosher</td>\n",
       "      <td>EP_12162015_placeholders_formal.jpg</td>\n",
       "      <td>Photo by Chelsea Kyle, Prop Styling by Rhoda B...</td>\n",
       "      <td>Joan Nathan</td>\n",
       "      <td>2008-09-09 04:00:00+00:00</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        dek  \\\n",
       "id                                                                            \n",
       "54a2b6b019925f464b373351  How does fried chicken achieve No. 1 status? B...   \n",
       "54a408a019925f464b3733bc                                Spinaci all'Ebraica   \n",
       "54a408a26529d92b2c003631  This majestic, moist, and richly spiced honey ...   \n",
       "54a408a66529d92b2c003638  The idea for this sandwich came to me when my ...   \n",
       "54a408a719925f464b3733cc  In 1930, Simon Agranat, the chief justice of t...   \n",
       "\n",
       "                                                            hed  \\\n",
       "id                                                                \n",
       "54a2b6b019925f464b373351            Pickle-Brined Fried Chicken   \n",
       "54a408a019925f464b3733bc                   Spinach Jewish Style   \n",
       "54a408a26529d92b2c003631                  New Year’s Honey Cake   \n",
       "54a408a66529d92b2c003638  The B.L.A.Bagel with Lox and Avocado   \n",
       "54a408a719925f464b3733cc        Shakshuka a la Doktor Shakshuka   \n",
       "\n",
       "                          aggregateRating  \\\n",
       "id                                          \n",
       "54a2b6b019925f464b373351             3.11   \n",
       "54a408a019925f464b3733bc             3.22   \n",
       "54a408a26529d92b2c003631             3.62   \n",
       "54a408a66529d92b2c003638             4.00   \n",
       "54a408a719925f464b3733cc             2.71   \n",
       "\n",
       "                                                                ingredients  \\\n",
       "id                                                                            \n",
       "54a2b6b019925f464b373351  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
       "54a408a019925f464b3733bc  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
       "54a408a26529d92b2c003631  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
       "54a408a66529d92b2c003638  [1 small ripe avocado, preferably Hass (see No...   \n",
       "54a408a719925f464b3733cc  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
       "\n",
       "                                                                  prepSteps  \\\n",
       "id                                                                            \n",
       "54a2b6b019925f464b373351  [Toast mustard and coriander seeds in a dry me...   \n",
       "54a408a019925f464b3733bc  [Remove the stems and roots from the spinach. ...   \n",
       "54a408a26529d92b2c003631  [I like this cake best baked in a 9-inch angel...   \n",
       "54a408a66529d92b2c003638  [A short time before serving, mash avocado and...   \n",
       "54a408a719925f464b3733cc  [1. Place the tomatoes, garlic, salt, paprika,...   \n",
       "\n",
       "                          reviewsCount  willMakeAgainPct  \\\n",
       "id                                                         \n",
       "54a2b6b019925f464b373351             7               100   \n",
       "54a408a019925f464b3733bc             5                80   \n",
       "54a408a26529d92b2c003631           105                88   \n",
       "54a408a66529d92b2c003638             7               100   \n",
       "54a408a719925f464b3733cc             7                83   \n",
       "\n",
       "                                                      ingredients_lemmafied  \\\n",
       "id                                                                            \n",
       "54a2b6b019925f464b373351  tablespoon yellow mustard seed brk tablespoon ...   \n",
       "54a408a019925f464b3733bc  pound small leave bulk spinach brk salt brk cu...   \n",
       "54a408a26529d92b2c003631  cup purpose flour brk tablespoon baking powder...   \n",
       "54a408a66529d92b2c003638  small ripe avocado hass see note brk teaspoon ...   \n",
       "54a408a719925f464b3733cc  pound fresh tomato unpeeled cut quarter ounce ...   \n",
       "\n",
       "                             cuisine_name  \\\n",
       "id                                          \n",
       "54a2b6b019925f464b373351  Missing Cuisine   \n",
       "54a408a019925f464b3733bc          Italian   \n",
       "54a408a26529d92b2c003631           Kosher   \n",
       "54a408a66529d92b2c003638           Kosher   \n",
       "54a408a719925f464b3733cc           Kosher   \n",
       "\n",
       "                                               photo_filename  \\\n",
       "id                                                              \n",
       "54a2b6b019925f464b373351       51247610_fried-chicken_1x1.jpg   \n",
       "54a408a019925f464b3733bc  EP_12162015_placeholders_rustic.jpg   \n",
       "54a408a26529d92b2c003631          EP_09022015_honeycake-2.jpg   \n",
       "54a408a66529d92b2c003638  EP_12162015_placeholders_casual.jpg   \n",
       "54a408a719925f464b3733cc  EP_12162015_placeholders_formal.jpg   \n",
       "\n",
       "                                                               photo_credit  \\\n",
       "id                                                                            \n",
       "54a2b6b019925f464b373351                Michael Graydon and Nikole Herriott   \n",
       "54a408a019925f464b3733bc  Photo by Chelsea Kyle, Prop Styling by Anna St...   \n",
       "54a408a26529d92b2c003631  Photo by Chelsea Kyle, Food Styling by Anna St...   \n",
       "54a408a66529d92b2c003638  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
       "54a408a719925f464b3733cc  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
       "\n",
       "                                  author_name            date_published  \\\n",
       "id                                                                        \n",
       "54a2b6b019925f464b373351  Missing Author Name 2014-08-19 04:00:00+00:00   \n",
       "54a408a019925f464b3733bc   Edda Servi Machlin 2008-09-09 04:00:00+00:00   \n",
       "54a408a26529d92b2c003631        Marcy Goldman 2008-09-10 04:00:00+00:00   \n",
       "54a408a66529d92b2c003638            Faye Levy 2008-09-08 04:00:00+00:00   \n",
       "54a408a719925f464b3733cc          Joan Nathan 2008-09-09 04:00:00+00:00   \n",
       "\n",
       "                                                                 recipe_url  \n",
       "id                                                                           \n",
       "54a2b6b019925f464b373351  https://www.epicurious.com/recipes/food/views/...  \n",
       "54a408a019925f464b3733bc  https://www.epicurious.com/recipes/food/views/...  \n",
       "54a408a26529d92b2c003631  https://www.epicurious.com/recipes/food/views/...  \n",
       "54a408a66529d92b2c003638  https://www.epicurious.com/recipes/food/views/...  \n",
       "54a408a719925f464b3733cc  https://www.epicurious.com/recipes/food/views/...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_nlp_df = pd.read_parquet('../joblib/2024.03.19/pre_proc_df.parquet.gzip')\n",
    "whole_nlp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "sklearn fit transform on ingredients:\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Input Data: \n",
      "id\n",
      "54a2b6b019925f464b373351    tablespoon yellow mustard seed brk tablespoon ...\n",
      "54a408a019925f464b3733bc    pound small leave bulk spinach brk salt brk cu...\n",
      "54a408a26529d92b2c003631    cup purpose flour brk tablespoon baking powder...\n",
      "54a408a66529d92b2c003638    small ripe avocado hass see note brk teaspoon ...\n",
      "54a408a719925f464b3733cc    pound fresh tomato unpeeled cut quarter ounce ...\n",
      "                                                  ...                        \n",
      "59541a31bff3052847ae2107    tablespoon unsalt butter room temperature brk ...\n",
      "5954233ad52ca90dc28200e7    tablespoon stick salt butter room temperature ...\n",
      "595424c2109c972493636f83    tablespoon unsalted butter more greasing pan b...\n",
      "5956638625dc3d1d829b7166    coarse salt brk lime wedge brk ounce tomato ju...\n",
      "59566daa25dc3d1d829b7169    bottle millileter sour beer such almanac citra...\n",
      "Name: ingredients_lemmafied, Length: 34756, dtype: object\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Input Data Shape: \n",
      "(34756,)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Random 3 Records from Input Data: \n",
      "id\n",
      "54a40caa19925f464b374017    boneless muscovy duck breast half pound total ...\n",
      "55d4e08063b1ba1b5534b198    tablespoon white wine vinegar brk teaspoon sug...\n",
      "54a43ad16529d92b2c019fc3    cup basmati rice ounce brk cup sweeten flake c...\n",
      "Name: ingredients_lemmafied, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34756/34756 [00:03<00:00, 10225.71it/s]\n",
      "/home/awchen/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/mlflow/models/signature.py:213: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  outputs = _infer_schema(model_output) if model_output is not None else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Transformed Data:\n",
      "                          100g  125g  13x9x2  150g  1pound  1tablespoon  \\\n",
      "id                                                                        \n",
      "54a2b6b019925f464b373351     0     0       0     0       0            0   \n",
      "54a408a019925f464b3733bc     0     0       0     0       0            0   \n",
      "54a408a26529d92b2c003631     0     0       0     0       0            0   \n",
      "54a408a66529d92b2c003638     0     0       0     0       0            0   \n",
      "54a408a719925f464b3733cc     0     0       0     0       0            0   \n",
      "\n",
      "                          1teaspoon  200g  250g  2cup  ...  árbol divide  \\\n",
      "id                                                     ...                 \n",
      "54a2b6b019925f464b373351          0     0     0     0  ...             0   \n",
      "54a408a019925f464b3733bc          0     0     0     0  ...             0   \n",
      "54a408a26529d92b2c003631          0     0     0     0  ...             0   \n",
      "54a408a66529d92b2c003638          0     0     0     0  ...             0   \n",
      "54a408a719925f464b3733cc          0     0     0     0  ...             0   \n",
      "\n",
      "                          árbol seed  árbol seed remove  árbol stem  \\\n",
      "id                                                                    \n",
      "54a2b6b019925f464b373351           0                  0           0   \n",
      "54a408a019925f464b3733bc           0                  0           0   \n",
      "54a408a26529d92b2c003631           0                  0           0   \n",
      "54a408a66529d92b2c003638           0                  0           0   \n",
      "54a408a719925f464b3733cc           0                  0           0   \n",
      "\n",
      "                          árbol teaspoon  árbol teaspoon crush  \\\n",
      "id                                                               \n",
      "54a2b6b019925f464b373351               0                     0   \n",
      "54a408a019925f464b3733bc               0                     0   \n",
      "54a408a26529d92b2c003631               0                     0   \n",
      "54a408a66529d92b2c003638               0                     0   \n",
      "54a408a719925f464b3733cc               0                     0   \n",
      "\n",
      "                          árbol teaspoon crush red  árbol wipe  \\\n",
      "id                                                               \n",
      "54a2b6b019925f464b373351                         0           0   \n",
      "54a408a019925f464b3733bc                         0           0   \n",
      "54a408a26529d92b2c003631                         0           0   \n",
      "54a408a66529d92b2c003638                         0           0   \n",
      "54a408a719925f464b3733cc                         0           0   \n",
      "\n",
      "                          árbol wipe clean  épice  \n",
      "id                                                 \n",
      "54a2b6b019925f464b373351                 0      0  \n",
      "54a408a019925f464b3733bc                 0      0  \n",
      "54a408a26529d92b2c003631                 0      0  \n",
      "54a408a66529d92b2c003638                 0      0  \n",
      "54a408a719925f464b3733cc                 0      0  \n",
      "\n",
      "[5 rows x 78378 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4051ef4183e44479a4f3b716783d898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9a2abc13024c128a3cdb33140f7977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890de6581cd04546b29f99e90292d4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MlflowException",
     "evalue": "The following failures occurred while downloading one or more artifacts from ../models/sklearn_model:\n##### File transformed_recipes.pkl #####\n[Errno 28] No space left on device: '../models/sklearn_model/transformed_recipes.pkl' -> '/tmp/tmpzcbs9ncw/transformed_recipes.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 103\u001b[0m\n\u001b[1;32m     97\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(transformed_recipe, fo)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# with open(combined_df_path, 'wb') as fo:\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m#     pickle.dump(combined_df, fo)\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m model_info \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../src/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCustomSKLearnWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhole_nlp_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mingredients_lemmafied\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msklearn_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# since this uses a custom Stanza analyzer, we have to use a custom mlflow.Pyfunc.PythonModel\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:2116\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(artifact_path, loader_module, data_path, code_path, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config)\u001b[0m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[38;5;241m.\u001b[39mformat(package_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_model\u001b[39m(\n\u001b[1;32m   1951\u001b[0m     artifact_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1965\u001b[0m     model_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1966\u001b[0m ):\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;124;03m    Log a Pyfunc model with custom inference logic and optional data dependencies as an MLflow\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;124;03m    artifact for the current run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2114\u001b[0m \u001b[38;5;124;03m             metadata of the logged model.\u001b[39;00m\n\u001b[1;32m   2115\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2117\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/mlflow/models/model.py:619\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    614\u001b[0m     (tracking_uri \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabricks\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m get_uri_scheme(tracking_uri) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabricks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignature\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    617\u001b[0m ):\n\u001b[1;32m    618\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mwarning(_LOG_MODEL_MISSING_SIGNATURE_WARNING)\n\u001b[0;32m--> 619\u001b[0m \u001b[43mflavor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mfluent\u001b[38;5;241m.\u001b[39mlog_artifacts(local_path, mlflow_model\u001b[38;5;241m.\u001b[39martifact_path)\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:1934\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(path, loader_module, data_path, code_path, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, **kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _save_model_with_loader_module_and_data_path(\n\u001b[1;32m   1923\u001b[0m         path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m   1924\u001b[0m         loader_module\u001b[38;5;241m=\u001b[39mloader_module,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1931\u001b[0m         model_config\u001b[38;5;241m=\u001b[39mmodel_config,\n\u001b[1;32m   1932\u001b[0m     )\n\u001b[1;32m   1933\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m second_argument_set_specified:\n\u001b[0;32m-> 1934\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model_with_class_artifacts_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/mlflow/pyfunc/model.py:283\u001b[0m, in \u001b[0;36m_save_model_with_class_artifacts_params\u001b[0;34m(path, python_model, signature, hints, artifacts, conda_env, code_paths, mlflow_model, pip_requirements, extra_pip_requirements, model_config)\u001b[0m\n\u001b[1;32m    279\u001b[0m     saved_artifact_subpath \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    280\u001b[0m         Path(snapshot_location)\u001b[38;5;241m.\u001b[39mrelative_to(Path(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(path)))\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 283\u001b[0m     tmp_artifact_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_artifacts_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m     relative_path \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    288\u001b[0m         Path(tmp_artifact_path)\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;241m.\u001b[39mrelative_to(Path(tmp_artifacts_dir\u001b[38;5;241m.\u001b[39mpath()))\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    293\u001b[0m     saved_artifact_subpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    294\u001b[0m         saved_artifacts_dir_subpath, relative_path\n\u001b[1;32m    295\u001b[0m     )\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/mlflow/tracking/artifact_utils.py:100\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m:param artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m:param output_path: The local filesystem path to which to download the artifact. If unspecified,\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m                    a local output path will be created.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m root_uri, artifact_path \u001b[38;5;241m=\u001b[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_uri\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py:76\u001b[0m, in \u001b[0;36mLocalArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mArtifacts tracked by ``LocalArtifactRepository`` already exist on the local filesystem.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03mIf ``dst_path`` is ``None``, the absolute filesystem path of the specified artifact is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m:return: Absolute path of the local filesystem location containing the desired artifacts.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dst_path:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# NOTE: The artifact_path is expected to be in posix format.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Posix paths work fine on windows but just in case we normalize it here.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m local_artifact_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(artifact_path))\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repo.py:221\u001b[0m, in \u001b[0;36mArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[1;32m    217\u001b[0m     template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##### File \u001b[39m\u001b[38;5;132;01m{path}\u001b[39;00m\u001b[38;5;124m #####\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{error}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m     failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    219\u001b[0m         template\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mpath, error\u001b[38;5;241m=\u001b[39merror) \u001b[38;5;28;01mfor\u001b[39;00m path, error \u001b[38;5;129;01min\u001b[39;00m failed_downloads\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    220\u001b[0m     )\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    222\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following failures occurred while downloading one or more\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m artifacts from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_truncate_error(failures)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst_path, artifact_path)\n",
      "\u001b[0;31mMlflowException\u001b[0m: The following failures occurred while downloading one or more artifacts from ../models/sklearn_model:\n##### File transformed_recipes.pkl #####\n[Errno 28] No space left on device: '../models/sklearn_model/transformed_recipes.pkl' -> '/tmp/tmpzcbs9ncw/transformed_recipes.pkl'"
     ]
    }
   ],
   "source": [
    "# load from MLflow\n",
    "mlflow_client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow')\n",
    "\n",
    "# cv_params are parameters for the sklearn CountVectorizer or TFIDFVectorizer\n",
    "sklearn_transformer_params = {    \n",
    "    'analyzer': CustomSKLearnAnalyzer().ngram_maker(\n",
    "        min_ngram_length=1,\n",
    "        max_ngram_length=4,\n",
    "        ),\n",
    "    'min_df':3,\n",
    "    'binary':True\n",
    "}\n",
    "\n",
    "# pipeline_params are parameters that will be logged in MLFlow and are a superset of library parameters\n",
    "pipeline_params = {\n",
    "    'stanza_model': 'en',\n",
    "    'sklearn-transformer': 'OHE'\n",
    "}\n",
    "\n",
    "# update the pipeline parameters with the library-specific ones so that they show up in MLflow Tracking\n",
    "pipeline_params.update(sklearn_transformer_params)\n",
    "\n",
    "with mlflow.start_run(experiment_id=mlflow_exp_id):    \n",
    "    # LOG PARAMETERS\n",
    "    mlflow.log_params(pipeline_params)\n",
    "\n",
    "    # LOG INPUTS (QUERIES) AND OUTPUTS\n",
    "    # MLflow example uses a list of strings or a list of str->str dicts\n",
    "    # Will be useful in STAGING/Evaluation\n",
    "    \n",
    "    # LOG MODEL\n",
    "    # Instantiate sklearn OneHotEncoder\n",
    "    sklearn_transformer = CountVectorizer(**sklearn_transformer_params)\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('sklearn fit transform on ingredients:', end='\\n')\n",
    "\n",
    "    model_input = whole_nlp_df['ingredients_lemmafied']\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('Input Data: ', end='\\n')\n",
    "    print(model_input)\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('Input Data Shape: ', end='\\n')\n",
    "    print(model_input.shape)\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('Random 3 Records from Input Data: ', end='\\n')\n",
    "    print(model_input.sample(3, random_state=200))\n",
    "\n",
    "    # Do fit transform on data\n",
    "    response = sklearn_transformer.fit_transform(tqdm(model_input)) \n",
    "    \n",
    "    transformed_recipe = pd.DataFrame(\n",
    "            response.toarray(),\n",
    "            columns=sklearn_transformer.get_feature_names_out(),\n",
    "            index=model_input.index\n",
    "    )\n",
    "\n",
    "    signature = infer_signature(model_input=model_input,\n",
    "                                model_output=transformed_recipe\n",
    "                                )\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('Transformed Data:', end='\\n')\n",
    "    print(transformed_recipe.head())\n",
    "    \n",
    "    # mlflow.pyfunc.save_model(\n",
    "    #     path=model_directory,\n",
    "    #     code_path=[\"../src/\"],\n",
    "    #     python_model=CustomSKLearnWrapper(),\n",
    "    #     input_example=to_nlp_df['ingredients'][0],    \n",
    "    #     artifacts=artifacts\n",
    "    # )\n",
    "\n",
    "    # combined_df = pd.concat(\n",
    "    #     [transformed_recipe,\n",
    "    #      whole_nlp_df\n",
    "    #      ]\n",
    "    #     , axis=1)\n",
    "    # print('\\n')\n",
    "    # print('-' * 80)\n",
    "    # print('Combined Data:', end='\\n')\n",
    "    # print(combined_df.head())\n",
    "\n",
    "    with open(sklearn_transformer_path, \"wb\") as fo:\n",
    "        pickle.dump(sklearn_transformer, fo)\n",
    "    \n",
    "    with open(transformed_recipes_path, \"wb\") as fo:\n",
    "        pickle.dump(transformed_recipe, fo)\n",
    "    \n",
    "    # with open(combined_df_path, 'wb') as fo:\n",
    "    #     pickle.dump(combined_df, fo)\n",
    "\n",
    "\n",
    "    model_info = mlflow.pyfunc.log_model( \n",
    "        code_path=[\"../src/\"],\n",
    "        python_model=CustomSKLearnWrapper(),\n",
    "        input_example=whole_nlp_df['ingredients_lemmafied'][0],\n",
    "        signature=signature,        \n",
    "        artifact_path=\"sklearn_model\",\n",
    "        artifacts=artifacts\n",
    "        ) \n",
    "\n",
    "    # since this uses a custom Stanza analyzer, we have to use a custom mlflow.Pyfunc.PythonModel\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_proc_df is cleaned dataframe\n",
    "whole_nlp_df = dfpp.preprocess_dataframe(raw_df)\n",
    "print('\\n')\n",
    "print('--------------')\n",
    "print('Preprocessed Dataframe:', end='\\n')\n",
    "print(whole_nlp_df.head())\n",
    "print(whole_nlp_df.shape)\n",
    "\n",
    "# cv_params are parameters for the sklearn CountVectorizer or TFIDFVectorizer\n",
    "sklearn_transformer_params = {    \n",
    "    'analyzer': CustomSKLearnAnalyzer().ngram_maker(\n",
    "        min_ngram_length=1,\n",
    "        max_ngram_length=4,\n",
    "        ),\n",
    "    'min_df':3,\n",
    "}\n",
    "\n",
    "sklearn_transformer = TfidfVectorizer(**sklearn_transformer_params)\n",
    "\n",
    "model_input = whole_nlp_df['ingredients_lemmafied']\n",
    "\n",
    "# Do fit transform on data\n",
    "print(\"fit_transform start: \" + str(datetime.now()))\n",
    "response = sklearn_transformer.fit_transform(tqdm(model_input)) \n",
    "print(\"fit_transform end: \" + str(datetime.now()))\n",
    "\n",
    "transformed_recipe = pd.DataFrame(\n",
    "        response.toarray(),\n",
    "        columns=sklearn_transformer.get_feature_names_out(),\n",
    "        index=model_input.index\n",
    ")\n",
    "\n",
    "combined_df = pd.concat([transformed_recipe, whole_nlp_df], axis=1)\n",
    "\n",
    "with open(\"../joblib/2024.03.19/combined_df.joblib\", 'wb') as fo:\n",
    "    joblib.dump()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictor = mlflow.pyfunc.load_model(model_uri=model_info.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_proc_df is cleaned dataframe\n",
    "pre_proc_test_df = dfpp.preprocess_dataframe(test_df)\n",
    "print('\\n')\n",
    "print('--------------')\n",
    "print('Preprocessed Dataframe: ', end='\\n')\n",
    "print(pre_proc_test_df.head())\n",
    "print(pre_proc_test_df.shape)\n",
    "\n",
    "# create subset for dev purposes\n",
    "# to_nlp_test_df = pre_proc_test_df\n",
    "# print('\\n')\n",
    "# print('-' * 80)\n",
    "# print('Subset Dataframe:', end='\\n')\n",
    "# print(to_nlp_test_df.head())\n",
    "# print(to_nlp_test_df.shape)\n",
    "\n",
    "test_model_input = pre_proc_test_df['ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_input.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info.signature.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictor.predict(test_model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "print('-' * 80)\n",
    "print('Input Data: ', end='\\n')\n",
    "print(test_model_input)\n",
    "\n",
    "print('\\n')\n",
    "print('-' * 80)\n",
    "print('Input Data Shape: ', end='\\n')\n",
    "print(test_model_input.shape)\n",
    "\n",
    "print('\\n')\n",
    "print('-' * 80)\n",
    "print('Random 3 Records from Input Data: ', end='\\n')\n",
    "print(test_model_input.sample(3, random_state=200))\n",
    "\n",
    "# test_response = sklearn_transformer.transform(tqdm(test_model_input)) \n",
    "test_response = sklearn_transformer.transform(test_model_input)\n",
    "    \n",
    "    \n",
    "test_transformed_recipe = pd.DataFrame(\n",
    "            test_response.toarray(),\n",
    "            columns=sklearn_transformer.get_feature_names_out(),\n",
    "            index=test_model_input.index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed_recipe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
