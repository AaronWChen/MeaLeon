{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: test\n",
    "output-file: template.html\n",
    "title: Template\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# | default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import OnlineCountVectorizer\n",
    "import dagshub\n",
    "import dill as pickle\n",
    "import dvc.api\n",
    "from hdbscan import HDBSCAN\n",
    "from itertools import tee, islice\n",
    "import mlflow\n",
    "import nbdev\n",
    "from nbdev.showdoc import *\n",
    "import pandas as pd\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer\n",
    "    , TfidfTransformer\n",
    "    , TfidfVectorizer\n",
    "    ,\n",
    ")\n",
    "from src.custom_stanza_mlflow import StanzaWrapper\n",
    "import src.dataframe_preprocessor as dfpp\n",
    "import stanza\n",
    "import tqdm\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# | export\n",
    "def foo():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# this function allows us to get the experiment ID from an experiment name\n",
    "def get_experiment_id(name):\n",
    "    exp = mlflow.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "      exp_id = mlflow.create_experiment(name)\n",
    "      return exp_id\n",
    "    return exp.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# | Below this are blocks to use DagsHub with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@markdown Enter the username of your DAGsHub account:\n",
    "DAGSHUB_USER_NAME = \"AaronWChen\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the email for your DAGsHub account:\n",
    "DAGSHUB_EMAIL = \"awc33@cornell.edu\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the repo name \n",
    "DAGSHUB_REPO_NAME=\"MeaLeon\"\n",
    "\n",
    "#@markdown Enter the name of the branch you are working on \n",
    "BRANCH=\"STANZA-2/investigate_bertopic_compatibility\"\n",
    "dagshub.init(repo_name=DAGSHUB_REPO_NAME\n",
    "             , repo_owner=DAGSHUB_USER_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac512908842477ea053d6836df9a3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 09:51:40 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-12-09 09:51:41 INFO: File exists: /home/awchen/stanza_resources/en/default.zip\n",
      "2023-12-09 09:51:44 INFO: Finished downloading models and saved to /home/awchen/stanza_resources.\n",
      "2023-12-09 09:51:44 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ad67ceae634ee7a24f345c88f760a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 09:51:45 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| lemma        | combined_nocharlm   |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "| depparse     | combined_charlm     |\n",
      "| sentiment    | sstplus             |\n",
      "| ner          | ontonotes_charlm    |\n",
      "======================================\n",
      "\n",
      "2023-12-09 09:51:45 INFO: Using device: cpu\n",
      "2023-12-09 09:51:45 INFO: Loading: tokenize\n",
      "2023-12-09 09:51:45 INFO: Loading: pos\n",
      "2023-12-09 09:51:45 INFO: Loading: lemma\n",
      "2023-12-09 09:51:45 INFO: Loading: constituency\n",
      "2023-12-09 09:51:46 INFO: Loading: depparse\n",
      "2023-12-09 09:51:46 INFO: Loading: sentiment\n",
      "2023-12-09 09:51:46 INFO: Loading: ner\n",
      "2023-12-09 09:51:46 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# instantiate stanza pipeline\n",
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline('en', \n",
    "                      depparse_batch_size=50, \n",
    "                      depparse_min_length_to_batch_separately=50,\n",
    "                      verbose=True,\n",
    "                      use_gpu=False,\n",
    "                    #   batch_size=100\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow')\n",
    "\n",
    "# starter idea for making an experiment name can be the git branch, but need more specificity\n",
    "experiment_name = f\"{DAGSHUB_EMAIL}/bertopic_stanza_small_set_v1\"\n",
    "mlflow_exp_id = get_experiment_id(experiment_name)\n",
    "\n",
    "# run_id that has the logged info needed\n",
    "mlflow_run_id = 'c6fbcf396af34ee3aade5503ee01c2bb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------\n",
      "Raw Dataframe:\n",
      "                         id  \\\n",
      "0  54a2b6b019925f464b373351   \n",
      "1  54a408a019925f464b3733bc   \n",
      "2  54a408a26529d92b2c003631   \n",
      "3  54a408a66529d92b2c003638   \n",
      "4  54a408a719925f464b3733cc   \n",
      "\n",
      "                                                 dek  \\\n",
      "0  How does fried chicken achieve No. 1 status? B...   \n",
      "1                                Spinaci all'Ebraica   \n",
      "2  This majestic, moist, and richly spiced honey ...   \n",
      "3  The idea for this sandwich came to me when my ...   \n",
      "4  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                     hed                   pubDate  \\\n",
      "0            Pickle-Brined Fried Chicken  2014-08-19T04:00:00.000Z   \n",
      "1                   Spinach Jewish Style  2008-09-09T04:00:00.000Z   \n",
      "2                  New Year’s Honey Cake  2008-09-10T04:00:00.000Z   \n",
      "3  The B.L.A.Bagel with Lox and Avocado  2008-09-08T04:00:00.000Z   \n",
      "4        Shakshuka a la Doktor Shakshuka  2008-09-09T04:00:00.000Z   \n",
      "\n",
      "                             author    type  \\\n",
      "0                                []  recipe   \n",
      "1  [{'name': 'Edda Servi Machlin'}]  recipe   \n",
      "2       [{'name': 'Marcy Goldman'}]  recipe   \n",
      "3           [{'name': 'Faye Levy'}]  recipe   \n",
      "4         [{'name': 'Joan Nathan'}]  recipe   \n",
      "\n",
      "                                                 url  \\\n",
      "0  /recipes/food/views/pickle-brined-fried-chicke...   \n",
      "1    /recipes/food/views/spinach-jewish-style-350152   \n",
      "2  /recipes/food/views/majestic-and-moist-new-yea...   \n",
      "3  /recipes/food/views/the-b-l-a-bagel-with-lox-a...   \n",
      "4  /recipes/food/views/shakshuka-a-la-doktor-shak...   \n",
      "\n",
      "                                           photoData  \\\n",
      "0  {'id': '54a2b64a6529d92b2c003409', 'filename':...   \n",
      "1  {'id': '56746182accb4c9831e45e0a', 'filename':...   \n",
      "2  {'id': '55e85ba4cf90d6663f728014', 'filename':...   \n",
      "3  {'id': '5674617e47d1a28026045e4f', 'filename':...   \n",
      "4  {'id': '56746183b47c050a284a4e15', 'filename':...   \n",
      "\n",
      "                                                 tag  aggregateRating  \\\n",
      "0  {'category': 'ingredient', 'name': 'Chicken', ...             3.11   \n",
      "1  {'category': 'cuisine', 'name': 'Italian', 'ur...             3.22   \n",
      "2  {'category': 'cuisine', 'name': 'Jewish', 'url...             3.62   \n",
      "3  {'category': 'cuisine', 'name': 'Jewish', 'url...             4.00   \n",
      "4  {'category': 'cuisine', 'name': 'Jewish', 'url...             2.71   \n",
      "\n",
      "                                         ingredients  \\\n",
      "0  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "1  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "2  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "3  [1 small ripe avocado, preferably Hass (see No...   \n",
      "4  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                           prepSteps  reviewsCount  \\\n",
      "0  [Toast mustard and coriander seeds in a dry me...             7   \n",
      "1  [Remove the stems and roots from the spinach. ...             5   \n",
      "2  [I like this cake best baked in a 9-inch angel...           105   \n",
      "3  [A short time before serving, mash avocado and...             7   \n",
      "4  [1. Place the tomatoes, garlic, salt, paprika,...             7   \n",
      "\n",
      "   willMakeAgainPct  dateCrawled  \n",
      "0               100   1498547035  \n",
      "1                80   1498547740  \n",
      "2                88   1498547738  \n",
      "3               100   1498547740  \n",
      "4                83   1498547740  \n",
      "(34756, 15)\n",
      "\n",
      "\n",
      "--------------\n",
      "Preprocessed Dataframe:\n",
      "                                                                        dek  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  How does fried chicken achieve No. 1 status? B...   \n",
      "54a408a019925f464b3733bc                                Spinaci all'Ebraica   \n",
      "54a408a26529d92b2c003631  This majestic, moist, and richly spiced honey ...   \n",
      "54a408a66529d92b2c003638  The idea for this sandwich came to me when my ...   \n",
      "54a408a719925f464b3733cc  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                                            hed  \\\n",
      "id                                                                \n",
      "54a2b6b019925f464b373351            Pickle-Brined Fried Chicken   \n",
      "54a408a019925f464b3733bc                   Spinach Jewish Style   \n",
      "54a408a26529d92b2c003631                  New Year’s Honey Cake   \n",
      "54a408a66529d92b2c003638  The B.L.A.Bagel with Lox and Avocado   \n",
      "54a408a719925f464b3733cc        Shakshuka a la Doktor Shakshuka   \n",
      "\n",
      "                          aggregateRating  \\\n",
      "id                                          \n",
      "54a2b6b019925f464b373351             3.11   \n",
      "54a408a019925f464b3733bc             3.22   \n",
      "54a408a26529d92b2c003631             3.62   \n",
      "54a408a66529d92b2c003638             4.00   \n",
      "54a408a719925f464b3733cc             2.71   \n",
      "\n",
      "                                                                ingredients  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "54a408a019925f464b3733bc  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "54a408a26529d92b2c003631  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "54a408a66529d92b2c003638  [1 small ripe avocado, preferably Hass (see No...   \n",
      "54a408a719925f464b3733cc  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                                                  prepSteps  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [Toast mustard and coriander seeds in a dry me...   \n",
      "54a408a019925f464b3733bc  [Remove the stems and roots from the spinach. ...   \n",
      "54a408a26529d92b2c003631  [I like this cake best baked in a 9-inch angel...   \n",
      "54a408a66529d92b2c003638  [A short time before serving, mash avocado and...   \n",
      "54a408a719925f464b3733cc  [1. Place the tomatoes, garlic, salt, paprika,...   \n",
      "\n",
      "                          reviewsCount  willMakeAgainPct     cuisine_name  \\\n",
      "id                                                                          \n",
      "54a2b6b019925f464b373351             7               100  Missing Cuisine   \n",
      "54a408a019925f464b3733bc             5                80          Italian   \n",
      "54a408a26529d92b2c003631           105                88           Kosher   \n",
      "54a408a66529d92b2c003638             7               100           Kosher   \n",
      "54a408a719925f464b3733cc             7                83           Kosher   \n",
      "\n",
      "                                               photo_filename  \\\n",
      "id                                                              \n",
      "54a2b6b019925f464b373351       51247610_fried-chicken_1x1.jpg   \n",
      "54a408a019925f464b3733bc  EP_12162015_placeholders_rustic.jpg   \n",
      "54a408a26529d92b2c003631          EP_09022015_honeycake-2.jpg   \n",
      "54a408a66529d92b2c003638  EP_12162015_placeholders_casual.jpg   \n",
      "54a408a719925f464b3733cc  EP_12162015_placeholders_formal.jpg   \n",
      "\n",
      "                                                               photo_credit  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351                Michael Graydon and Nikole Herriott   \n",
      "54a408a019925f464b3733bc  Photo by Chelsea Kyle, Prop Styling by Anna St...   \n",
      "54a408a26529d92b2c003631  Photo by Chelsea Kyle, Food Styling by Anna St...   \n",
      "54a408a66529d92b2c003638  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "54a408a719925f464b3733cc  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "\n",
      "                                  author_name            date_published  \\\n",
      "id                                                                        \n",
      "54a2b6b019925f464b373351  Missing Author Name 2014-08-19 04:00:00+00:00   \n",
      "54a408a019925f464b3733bc   Edda Servi Machlin 2008-09-09 04:00:00+00:00   \n",
      "54a408a26529d92b2c003631        Marcy Goldman 2008-09-10 04:00:00+00:00   \n",
      "54a408a66529d92b2c003638            Faye Levy 2008-09-08 04:00:00+00:00   \n",
      "54a408a719925f464b3733cc          Joan Nathan 2008-09-09 04:00:00+00:00   \n",
      "\n",
      "                                                                 recipe_url  \n",
      "id                                                                           \n",
      "54a2b6b019925f464b373351  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a019925f464b3733bc  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a26529d92b2c003631  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a66529d92b2c003638  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a719925f464b3733cc  https://www.epicurious.com/recipes/food/views/...  \n",
      "(34656, 13)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Subset Dataframe:\n",
      "                                                                        dek  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  How does fried chicken achieve No. 1 status? B...   \n",
      "54a408a019925f464b3733bc                                Spinaci all'Ebraica   \n",
      "54a408a26529d92b2c003631  This majestic, moist, and richly spiced honey ...   \n",
      "54a408a66529d92b2c003638  The idea for this sandwich came to me when my ...   \n",
      "54a408a719925f464b3733cc  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                                            hed  \\\n",
      "id                                                                \n",
      "54a2b6b019925f464b373351            Pickle-Brined Fried Chicken   \n",
      "54a408a019925f464b3733bc                   Spinach Jewish Style   \n",
      "54a408a26529d92b2c003631                  New Year’s Honey Cake   \n",
      "54a408a66529d92b2c003638  The B.L.A.Bagel with Lox and Avocado   \n",
      "54a408a719925f464b3733cc        Shakshuka a la Doktor Shakshuka   \n",
      "\n",
      "                          aggregateRating  \\\n",
      "id                                          \n",
      "54a2b6b019925f464b373351             3.11   \n",
      "54a408a019925f464b3733bc             3.22   \n",
      "54a408a26529d92b2c003631             3.62   \n",
      "54a408a66529d92b2c003638             4.00   \n",
      "54a408a719925f464b3733cc             2.71   \n",
      "\n",
      "                                                                ingredients  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "54a408a019925f464b3733bc  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "54a408a26529d92b2c003631  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "54a408a66529d92b2c003638  [1 small ripe avocado, preferably Hass (see No...   \n",
      "54a408a719925f464b3733cc  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                                                  prepSteps  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [Toast mustard and coriander seeds in a dry me...   \n",
      "54a408a019925f464b3733bc  [Remove the stems and roots from the spinach. ...   \n",
      "54a408a26529d92b2c003631  [I like this cake best baked in a 9-inch angel...   \n",
      "54a408a66529d92b2c003638  [A short time before serving, mash avocado and...   \n",
      "54a408a719925f464b3733cc  [1. Place the tomatoes, garlic, salt, paprika,...   \n",
      "\n",
      "                          reviewsCount  willMakeAgainPct     cuisine_name  \\\n",
      "id                                                                          \n",
      "54a2b6b019925f464b373351             7               100  Missing Cuisine   \n",
      "54a408a019925f464b3733bc             5                80          Italian   \n",
      "54a408a26529d92b2c003631           105                88           Kosher   \n",
      "54a408a66529d92b2c003638             7               100           Kosher   \n",
      "54a408a719925f464b3733cc             7                83           Kosher   \n",
      "\n",
      "                                               photo_filename  \\\n",
      "id                                                              \n",
      "54a2b6b019925f464b373351       51247610_fried-chicken_1x1.jpg   \n",
      "54a408a019925f464b3733bc  EP_12162015_placeholders_rustic.jpg   \n",
      "54a408a26529d92b2c003631          EP_09022015_honeycake-2.jpg   \n",
      "54a408a66529d92b2c003638  EP_12162015_placeholders_casual.jpg   \n",
      "54a408a719925f464b3733cc  EP_12162015_placeholders_formal.jpg   \n",
      "\n",
      "                                                               photo_credit  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351                Michael Graydon and Nikole Herriott   \n",
      "54a408a019925f464b3733bc  Photo by Chelsea Kyle, Prop Styling by Anna St...   \n",
      "54a408a26529d92b2c003631  Photo by Chelsea Kyle, Food Styling by Anna St...   \n",
      "54a408a66529d92b2c003638  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "54a408a719925f464b3733cc  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "\n",
      "                                  author_name            date_published  \\\n",
      "id                                                                        \n",
      "54a2b6b019925f464b373351  Missing Author Name 2014-08-19 04:00:00+00:00   \n",
      "54a408a019925f464b3733bc   Edda Servi Machlin 2008-09-09 04:00:00+00:00   \n",
      "54a408a26529d92b2c003631        Marcy Goldman 2008-09-10 04:00:00+00:00   \n",
      "54a408a66529d92b2c003638            Faye Levy 2008-09-08 04:00:00+00:00   \n",
      "54a408a719925f464b3733cc          Joan Nathan 2008-09-09 04:00:00+00:00   \n",
      "\n",
      "                                                                 recipe_url  \n",
      "id                                                                           \n",
      "54a2b6b019925f464b373351  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a019925f464b3733bc  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a26529d92b2c003631  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a66529d92b2c003638  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a719925f464b3733cc  https://www.epicurious.com/recipes/food/views/...  \n",
      "(50, 13)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Recipe steps:\n",
      "id\n",
      "54a2b6b019925f464b373351    toast mustard and coriander seeds in a dry med...\n",
      "54a408a019925f464b3733bc    remove the stems and roots from the spinach . ...\n",
      "54a408a26529d92b2c003631    i like this cake best baked in a 9 - inch ange...\n",
      "54a408a66529d92b2c003638    a short time before serving , mash avocado and...\n",
      "54a408a719925f464b3733cc    1. place the tomatoes , garlic , salt , paprik...\n",
      "54a408a919925f464b3733d3    1. combine the rice , cream , and butter . add...\n",
      "54a408aa19925f464b3733d6    1. preheat the oven to 350°f . lightly grease ...\n",
      "54a408ab19925f464b3733da    1. combine the sugar , water , egg whites , an...\n",
      "54a408ac19925f464b3733de    1. with a mixer on medium speed , beat togethe...\n",
      "54a408ac6529d92b2c003653    1. place the cake on the cake plate . reserve ...\n",
      "54a408ad6529d92b2c003657                       1. preheat the oven to 350°f .\n",
      "54a408af19925f464b3733eb    whisk 5 teaspoons lemon juice and mustard in s...\n",
      "54a408b019925f464b3733f1    place guajillo chiles in medium saucepan ; add...\n",
      "54a408b219925f464b3733f9    preheat oven to 350°f . line baking sheet with...\n",
      "54a408b76529d92b2c00366b    using vegetable peeler , remove peel from lemo...\n",
      "54a408b919925f464b37340b    stir mustard seeds in small dry skillet over m...\n",
      "54a408bb6529d92b2c00367b    combine apple juice and 4 tablespoons lemon ju...\n",
      "54a408bc19925f464b373413    combine tomatoes , onions , peppers , and 1/4 ...\n",
      "54a408be19925f464b37341a    combine 4 tablespoons ice water and cider vine...\n",
      "54a408c06529d92b2c003696    arrange rack 6 inches below broiler . preheat ...\n",
      "54a408c119925f464b373424    bring 1/2 cup sugar , cranberry juice concentr...\n",
      "54a408c219925f464b37342c    bring maple syrup , brown sugar , corn syrup ,...\n",
      "54a408c36529d92b2c0036a1    blend first 3 ingredients in processor 5 secon...\n",
      "54a408c519925f464b37343b    heat heavy small skillet over medium heat . ad...\n",
      "54a408c619925f464b373441    soak cherries in cassis in small bowl at least...\n",
      "54a408c819925f464b373449    position rack in center of oven ; preheat to 3...\n",
      "54a408ca19925f464b373451    melt butter in heavy large skillet over medium...\n",
      "54a408cc6529d92b2c0036c2    melt butter in large pot over medium - low hea...\n",
      "54a408cc6529d92b2c0036c5    heat oil in heavy large skillet over medium he...\n",
      "54a408ce6529d92b2c0036ce    preheat oven to 450°f . toss first 3 ingredien...\n",
      "54a408d019925f464b373466    cook cauliflower in large pot of boiling salte...\n",
      "54a408d119925f464b37346c    melt butter in heavy large skillet over medium...\n",
      "54a408d319925f464b373474    combine breadcrumbs and 1/4 cup water in small...\n",
      "54a408d46529d92b2c0036e5    sprinkle ribs with coarse salt and pepper . pl...\n",
      "54a408d519925f464b373482    preheat oven to 250°f . cut each plum tomato i...\n",
      "54a408d86529d92b2c0036ef    preheat oven to 450°f . toss squash , olive oi...\n",
      "54a408da6529d92b2c0036f9    preheat oven to 350°f . and grease a 9 - inch ...\n",
      "54a408dc6529d92b2c003702                              preheat oven to 400°f .\n",
      "54a408de19925f464b37349d    melt butter in heavy large pot over medium - h...\n",
      "54a408df19925f464b3734a2    1. cut the seafood into 1 / 4 - inch dice . ( ...\n",
      "54a408e119925f464b3734a4    preheat the oven to 350°f . grease an 8 - inch...\n",
      "54a408e219925f464b3734a9    cut peel and white pith from oranges and grape...\n",
      "54a408e319925f464b3734b0    mix flour and salt in processor . add butter a...\n",
      "54a408e56529d92b2c003720    whisk first 6 ingredients in small bowl to ble...\n",
      "54a408e719925f464b3734b8    to make the soup : in a high - speed blender ,...\n",
      "54a408e819925f464b3734c4    place yogurt in medium bowl . gradually whisk ...\n",
      "54a408e96529d92b2c003736    mix lemon juice , basil , oregano and garlic ....\n",
      "54a408eb19925f464b3734d0    place porcini in 1 cup hot water . let soak un...\n",
      "54a408ec6529d92b2c00373e    place chiles in medium bowl . pour enough boil...\n",
      "54a408ef6529d92b2c003746    position rack in center of oven ; preheat to 3...\n",
      "Name: prepSteps, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199fc4ce2bfa4141a377a5b8a63ee54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 10:34:55,903 - BERTopic - Transformed documents to Embeddings\n",
      "2023-12-09 10:34:57,257 - BERTopic - Reduced dimensionality\n",
      "2023-12-09 10:34:57,266 - BERTopic - Clustered reduced embeddings\n",
      "2023-12-09 10:34:57,288 - BERTopic - Reduced number of topics from 3 to 3\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 106167298048 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=147'>148</a>\u001b[0m steps_vectorizer_model \u001b[39m=\u001b[39m OnlineCountVectorizer(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcv_params)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=149'>150</a>\u001b[0m \u001b[39m# Do fit transform on data\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=150'>151</a>\u001b[0m \u001b[39m# steps_test_tfidf_transform = steps_tfidf_vectorizer_model.fit_transform(tqdm(to_nlp_df[\"steps\"]))\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=151'>152</a>\u001b[0m topic_model\u001b[39m.\u001b[39;49mupdate_topics(\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=152'>153</a>\u001b[0m     recipe_steps\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=153'>154</a>\u001b[0m     , vectorizer_model\u001b[39m=\u001b[39;49msteps_vectorizer_model\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=154'>155</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=156'>157</a>\u001b[0m \u001b[39m# Display topic model results\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=157'>158</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/bertopic/_bertopic.py:1386\u001b[0m, in \u001b[0;36mBERTopic.update_topics\u001b[0;34m(self, docs, images, topics, top_n_words, n_gram_range, vectorizer_model, ctfidf_model, representation_model)\u001b[0m\n\u001b[1;32m   1384\u001b[0m documents \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m\"\u001b[39m\u001b[39mDocument\u001b[39m\u001b[39m\"\u001b[39m: docs, \u001b[39m\"\u001b[39m\u001b[39mTopic\u001b[39m\u001b[39m\"\u001b[39m: topics, \u001b[39m\"\u001b[39m\u001b[39mID\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(docs)), \u001b[39m\"\u001b[39m\u001b[39mImage\u001b[39m\u001b[39m\"\u001b[39m: images})\n\u001b[1;32m   1385\u001b[0m documents_per_topic \u001b[39m=\u001b[39m documents\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mTopic\u001b[39m\u001b[39m'\u001b[39m], as_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39magg({\u001b[39m'\u001b[39m\u001b[39mDocument\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin})\n\u001b[0;32m-> 1386\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_tf_idf_, words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_tf_idf(documents_per_topic)\n\u001b[1;32m   1387\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtopic_representations_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extract_words_per_topic(words, documents)\n\u001b[1;32m   1388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(topics) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtopics_:\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/bertopic/_bertopic.py:3488\u001b[0m, in \u001b[0;36mBERTopic._c_tf_idf\u001b[0;34m(self, documents_per_topic, fit, partial_fit)\u001b[0m\n\u001b[1;32m   3486\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorizer_model\u001b[39m.\u001b[39mpartial_fit(documents)\u001b[39m.\u001b[39mupdate_bow(documents)\n\u001b[1;32m   3487\u001b[0m \u001b[39melif\u001b[39;00m fit:\n\u001b[0;32m-> 3488\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectorizer_model\u001b[39m.\u001b[39;49mfit(documents)\n\u001b[1;32m   3489\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorizer_model\u001b[39m.\u001b[39mtransform(documents)\n\u001b[1;32m   3490\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1340\u001b[0m, in \u001b[0;36mCountVectorizer.fit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, raw_documents, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1325\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Learn a vocabulary dictionary of all tokens in the raw documents.\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \n\u001b[1;32m   1327\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[39m        Fitted vectorizer.\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[1;32m   1341\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1389\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1381\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1386\u001b[0m             )\n\u001b[1;32m   1387\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[1;32m   1391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[1;32m   1392\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1276\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[1;32m   1275\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[0;32m-> 1276\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[1;32m   1277\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/src/custom_stanza_mlflow.py:84\u001b[0m, in \u001b[0;36mStanzaWrapper.stanza_analyzer.<locals>.ngrams_per_line\u001b[0;34m(ingredients_list)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m lowered \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     lowered \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMissing ingredients\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 84\u001b[0m preproc \u001b[39m=\u001b[39m stanza_pipeline(lowered)\n\u001b[1;32m     86\u001b[0m lemmad \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m,\n\u001b[1;32m     87\u001b[0m                     [word\u001b[39m.\u001b[39mlemma \n\u001b[1;32m     88\u001b[0m                     \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m preproc\u001b[39m.\u001b[39msentences \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 )\n\u001b[1;32m     94\u001b[0m             )\n\u001b[1;32m     96\u001b[0m \u001b[39m# analyze each line of the input string seperately\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/stanza/pipeline/core.py:471\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, doc, processors)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, doc, processors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 471\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess(doc, processors)\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/stanza/pipeline/core.py:422\u001b[0m, in \u001b[0;36mPipeline.process\u001b[0;34m(self, doc, processors)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessors\u001b[39m.\u001b[39mget(processor_name):\n\u001b[1;32m    421\u001b[0m         process \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessors[processor_name]\u001b[39m.\u001b[39mbulk_process \u001b[39mif\u001b[39;00m bulk \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessors[processor_name]\u001b[39m.\u001b[39mprocess\n\u001b[0;32m--> 422\u001b[0m         doc \u001b[39m=\u001b[39m process(doc)\n\u001b[1;32m    423\u001b[0m \u001b[39mreturn\u001b[39;00m doc\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/stanza/pipeline/depparse_processor.py:65\u001b[0m, in \u001b[0;36mDepparseProcessor.process\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     63\u001b[0m     preds \u001b[39m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m     \u001b[39mfor\u001b[39;00m i, b \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(batch):\n\u001b[0;32m---> 65\u001b[0m         preds \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mpredict(b)\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m batch\u001b[39m.\u001b[39mdata_orig_idx \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     preds \u001b[39m=\u001b[39m unsort(preds, batch\u001b[39m.\u001b[39mdata_orig_idx)\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/stanza/models/depparse/trainer.py:70\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, batch, unsort)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[1;32m     69\u001b[0m batch_size \u001b[39m=\u001b[39m word\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m _, preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, lemma, head, deprel, word_orig_idx, sentlens, wordlens, text)\n\u001b[1;32m     71\u001b[0m head_seqs \u001b[39m=\u001b[39m [chuliu_edmonds_one_root(adj[:l, :l])[\u001b[39m1\u001b[39m:] \u001b[39mfor\u001b[39;00m adj, l \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(preds[\u001b[39m0\u001b[39m], sentlens)] \u001b[39m# remove attachment for the root\u001b[39;00m\n\u001b[1;32m     72\u001b[0m deprel_seqs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab[\u001b[39m'\u001b[39m\u001b[39mdeprel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munmap([preds[\u001b[39m1\u001b[39m][i][j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m][h] \u001b[39mfor\u001b[39;00m j, h \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(hs)]) \u001b[39mfor\u001b[39;00m i, hs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(head_seqs)]\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/stanza/models/depparse/model.py:205\u001b[0m, in \u001b[0;36mParser.forward\u001b[0;34m(self, word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, lemma, head, deprel, word_orig_idx, sentlens, wordlens, text)\u001b[0m\n\u001b[1;32m    202\u001b[0m lstm_outputs, _ \u001b[39m=\u001b[39m pad_packed_sequence(lstm_outputs, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    204\u001b[0m unlabeled_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munlabeled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop(lstm_outputs), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop(lstm_outputs))\u001b[39m.\u001b[39msqueeze(\u001b[39m3\u001b[39m)\n\u001b[0;32m--> 205\u001b[0m deprel_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeprel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdrop(lstm_outputs), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdrop(lstm_outputs))\n\u001b[1;32m    207\u001b[0m \u001b[39m#goldmask = head.new_zeros(*head.size(), head.size(-1)+1, dtype=torch.uint8)\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m#goldmask.scatter_(2, head.unsqueeze(2), 1)\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mlinearization\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/stanza/models/common/biaffine.py:74\u001b[0m, in \u001b[0;36mDeepBiaffineScorer.forward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input1, input2):\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscorer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden_func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW1(input1))), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden_func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW2(input2))))\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/stanza/models/common/biaffine.py:59\u001b[0m, in \u001b[0;36mPairwiseBiaffineScorer.forward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m     57\u001b[0m input1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([input1, input1\u001b[39m.\u001b[39mnew_ones(\u001b[39m*\u001b[39minput1\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m)], \u001b[39mlen\u001b[39m(input1\u001b[39m.\u001b[39msize())\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     58\u001b[0m input2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([input2, input2\u001b[39m.\u001b[39mnew_ones(\u001b[39m*\u001b[39minput2\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m)], \u001b[39mlen\u001b[39m(input2\u001b[39m.\u001b[39msize())\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW_bilin(input1, input2)\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/stanza/models/common/biaffine.py:29\u001b[0m, in \u001b[0;36mPairwiseBilinear.forward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m     27\u001b[0m input2 \u001b[39m=\u001b[39m input2\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[39m# (N x (L1 x O) x D2) * (N x D2 x L2) -> (N x (L1 x O) x L2)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m output \u001b[39m=\u001b[39m intermediate\u001b[39m.\u001b[39;49mview(input1_size[\u001b[39m0\u001b[39;49m], input1_size[\u001b[39m1\u001b[39;49m] \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_size, input2_size[\u001b[39m2\u001b[39;49m])\u001b[39m.\u001b[39;49mbmm(input2)\n\u001b[1;32m     30\u001b[0m \u001b[39m# (N x (L1 x O) x L2) -> (N x L1 x L2 x O)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mview(input1_size[\u001b[39m0\u001b[39m], input1_size[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_size, input2_size[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 106167298048 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "# load from MLflow\n",
    "mlflow_client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow')\n",
    "\n",
    "# load dataframes from artifacts\n",
    "# mlflow.artifacts.download_artifacts(\n",
    "#     run_id=mlflow_run_id\n",
    "# )\n",
    "\n",
    "# cv_params are parameters for the sklearn CountVectorizer or TFIDFVectorizer\n",
    "cv_params = {\n",
    "    'strip_accents':\"unicode\",\n",
    "    'lowercase':True,\n",
    "    'analyzer': StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4),\n",
    "    'min_df':3,\n",
    "}\n",
    "\n",
    "# bertopic_params are a superset of cv_params\n",
    "bertopic_params = {\n",
    "    'top_n_words':20,\n",
    "    'min_topic_size':5,\n",
    "    'nr_topics':'auto',\n",
    "    'verbose':True,\n",
    "    'low_memory':True,\n",
    "    'calculate_probabilities':True\n",
    "}\n",
    "\n",
    "# update bertopic_params to include cv_params\n",
    "# bertopic_params.update(cv_params)\n",
    "\n",
    "# pipeline_params are parameters that will be logged in MLFlow and are a superset of library parameters\n",
    "pipeline_params = {\n",
    "    'stanza_model': 'en',\n",
    "    'sklearn-transformer': 'TfidfVectorizer'\n",
    "}\n",
    "\n",
    "# update the pipeline parameters with the library-specific ones so that they show up in MLflow Tracking\n",
    "pipeline_params.update(cv_params)\n",
    "pipeline_params.update(bertopic_params)\n",
    "\n",
    "with mlflow.start_run(experiment_id=mlflow_exp_id):    \n",
    "    # LOG PARAMETERS\n",
    "    mlflow.log_params(pipeline_params)\n",
    "\n",
    "    # LOG INPUTS (QUERIES) AND OUTPUTS\n",
    "    # MLflow example uses a list of strings or a list of str->str dicts\n",
    "    \n",
    "    # load raw data and preprocess/clean\n",
    "    data = dvc.api.read(\n",
    "           path='../data/recipes-en-201706/epicurious-recipes_m2.json'\n",
    "           , mode='r')\n",
    "    raw_df = pd.read_json(data)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print('Raw Dataframe:', end='\\n')\n",
    "    print(raw_df.head())\n",
    "    print(raw_df.shape)\n",
    "\n",
    "    # pre_proc_df is cleaned dataframe\n",
    "    pre_proc_df = dfpp.preprocess_dataframe(raw_df)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print('Preprocessed Dataframe:', end='\\n')\n",
    "    print(pre_proc_df.head())\n",
    "    print(pre_proc_df.shape)\n",
    "\n",
    "\n",
    "    # pre_proc_df = pd.read_json(\n",
    "    #     mlflow.artifacts.download_artifacts(\n",
    "    #         run_id=mlflow_run_id,\n",
    "    #         artifact_path='artifacts/preprocessed_dataframes/preprocessed_dataframe.json',\n",
    "    #         # tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow'\n",
    "    #     )\n",
    "    # )\n",
    "    # print('\\n')\n",
    "    # print('-' * 80)\n",
    "    # print('Preprocessed Dataframe:', end='\\n')\n",
    "    # print(pre_proc_df.head())\n",
    "    # print(pre_proc_df.shape)\n",
    "\n",
    "    # create subset for dev purposes\n",
    "    to_nlp_df = pre_proc_df[0:50]\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('Subset Dataframe:', end='\\n')\n",
    "    print(to_nlp_df.head())\n",
    "    print(to_nlp_df.shape)\n",
    "\n",
    "    # LOG MODEL\n",
    "    # Instantiate BERTopic\n",
    "    topic_model = BERTopic(\n",
    "        **bertopic_params,\n",
    "    )\n",
    "\n",
    "    def custom_analyzer(step_list, stanza_pipeline, minNgramLength, maxNgramLength):\n",
    "            lowered = \" brk \".join(map(str, [step for step in step_list if step is not None])).lower()\n",
    "\n",
    "            preproc = stanza_pipeline(lowered)\n",
    "            \n",
    "            lemmad = \" \".join(map(str,\n",
    "                                [word.text\n",
    "                                for sent in preproc.sentences \n",
    "                                for word in sent.words if (\n",
    "                                    word is not None\n",
    "                                )]\n",
    "                            )\n",
    "                        )\n",
    "            \n",
    "            # analyze each line of the input string seperately\n",
    "            for ln in lemmad.split(' brk '):\n",
    "                \n",
    "                # tokenize the input string (customize the regex as desired)\n",
    "                at_least_two_english_characters_whole_words = \"(?u)\\b[a-zA-Z]{2,}\\b\"\n",
    "                terms = re.split(at_least_two_english_characters_whole_words, ln)\n",
    "\n",
    "                # loop ngram creation for every number between min and max ngram length\n",
    "                for ngramLength in range(minNgramLength, maxNgramLength+1):\n",
    "\n",
    "                    # find and return all ngrams\n",
    "                    # for ngram in zip(*[terms[i:] for i in range(3)]): \n",
    "                        # <-- solution without a generator (works the same but has higher memory usage)\n",
    "                    for ngram in zip(*[islice(seq, i, len(terms)) for i, seq in enumerate(tee(terms, ngramLength))]):   # <-- solution using a generator\n",
    "                        \n",
    "                        ngram = ' '.join(map(str, ngram))\n",
    "                        # yield ngram\n",
    "                        return str(ngram)\n",
    "\n",
    "    analyzer_kwargs = {'stanza_pipeline': nlp\n",
    "                       , 'minNgramLength': 1\n",
    "                       , 'maxNgramLength': 4}\n",
    "    \n",
    "    recipe_steps = to_nlp_df[\"prepSteps\"].apply(custom_analyzer, **analyzer_kwargs)\n",
    "\n",
    "    # recipe_steps = \"\".join(str(to_nlp_df[\"prepSteps\"].apply(StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4))))\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('Recipe steps:', end='\\n')\n",
    "    print(recipe_steps)\n",
    "\n",
    "    # train on the recipes' steps\n",
    "    topics, probs = topic_model.fit_transform(recipe_steps)\n",
    "\n",
    "    # since this uses a custom Stanza analyzer, we have to use a custom mlflow.Pyfunc.PythonModel\n",
    "    # Instantiate sklearn CountVectorizer\n",
    "    # steps_vectorizer_model = CountVectorizer(**cv_params)\n",
    "\n",
    "    # May need to use BERTopic's OnlineCountVectorizer\n",
    "    steps_vectorizer_model = OnlineCountVectorizer(**cv_params)\n",
    "\n",
    "    # Do fit transform on data\n",
    "    # steps_test_tfidf_transform = steps_tfidf_vectorizer_model.fit_transform(tqdm(to_nlp_df[\"steps\"]))\n",
    "    topic_model.update_topics(\n",
    "        recipe_steps\n",
    "        , vectorizer_model=steps_vectorizer_model\n",
    "    )\n",
    "\n",
    "    # Display topic model results\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('BERTopic Model Dataframe:', end='\\n')\n",
    "    print(topic_model.get_topic_info())\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('BERTopic Model Representations:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representation'])\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('BERTopic Model Representations:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representative_Docs'])\n",
    "\n",
    "    # Save and log the topic model dataframe\n",
    "    topic_model.get_topic_info().to_json('../data/processed/bertopic_model_small_set_df.json')\n",
    "    mlflow.log_artifact('../data/processed/bertopic_model_small_set_df.json',\n",
    "                        artifact_path='bertopic_models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------\n",
      "Raw Dataframe:\n",
      "                         id  \\\n",
      "0  54a2b6b019925f464b373351   \n",
      "1  54a408a019925f464b3733bc   \n",
      "2  54a408a26529d92b2c003631   \n",
      "3  54a408a66529d92b2c003638   \n",
      "4  54a408a719925f464b3733cc   \n",
      "\n",
      "                                                 dek  \\\n",
      "0  How does fried chicken achieve No. 1 status? B...   \n",
      "1                                Spinaci all'Ebraica   \n",
      "2  This majestic, moist, and richly spiced honey ...   \n",
      "3  The idea for this sandwich came to me when my ...   \n",
      "4  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                     hed                   pubDate  \\\n",
      "0            Pickle-Brined Fried Chicken  2014-08-19T04:00:00.000Z   \n",
      "1                   Spinach Jewish Style  2008-09-09T04:00:00.000Z   \n",
      "2                  New Year’s Honey Cake  2008-09-10T04:00:00.000Z   \n",
      "3  The B.L.A.Bagel with Lox and Avocado  2008-09-08T04:00:00.000Z   \n",
      "4        Shakshuka a la Doktor Shakshuka  2008-09-09T04:00:00.000Z   \n",
      "\n",
      "                             author    type  \\\n",
      "0                                []  recipe   \n",
      "1  [{'name': 'Edda Servi Machlin'}]  recipe   \n",
      "2       [{'name': 'Marcy Goldman'}]  recipe   \n",
      "3           [{'name': 'Faye Levy'}]  recipe   \n",
      "4         [{'name': 'Joan Nathan'}]  recipe   \n",
      "\n",
      "                                                 url  \\\n",
      "0  /recipes/food/views/pickle-brined-fried-chicke...   \n",
      "1    /recipes/food/views/spinach-jewish-style-350152   \n",
      "2  /recipes/food/views/majestic-and-moist-new-yea...   \n",
      "3  /recipes/food/views/the-b-l-a-bagel-with-lox-a...   \n",
      "4  /recipes/food/views/shakshuka-a-la-doktor-shak...   \n",
      "\n",
      "                                           photoData  \\\n",
      "0  {'id': '54a2b64a6529d92b2c003409', 'filename':...   \n",
      "1  {'id': '56746182accb4c9831e45e0a', 'filename':...   \n",
      "2  {'id': '55e85ba4cf90d6663f728014', 'filename':...   \n",
      "3  {'id': '5674617e47d1a28026045e4f', 'filename':...   \n",
      "4  {'id': '56746183b47c050a284a4e15', 'filename':...   \n",
      "\n",
      "                                                 tag  aggregateRating  \\\n",
      "0  {'category': 'ingredient', 'name': 'Chicken', ...             3.11   \n",
      "1  {'category': 'cuisine', 'name': 'Italian', 'ur...             3.22   \n",
      "2  {'category': 'cuisine', 'name': 'Jewish', 'url...             3.62   \n",
      "3  {'category': 'cuisine', 'name': 'Jewish', 'url...             4.00   \n",
      "4  {'category': 'cuisine', 'name': 'Jewish', 'url...             2.71   \n",
      "\n",
      "                                         ingredients  \\\n",
      "0  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "1  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "2  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "3  [1 small ripe avocado, preferably Hass (see No...   \n",
      "4  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                           prepSteps  reviewsCount  \\\n",
      "0  [Toast mustard and coriander seeds in a dry me...             7   \n",
      "1  [Remove the stems and roots from the spinach. ...             5   \n",
      "2  [I like this cake best baked in a 9-inch angel...           105   \n",
      "3  [A short time before serving, mash avocado and...             7   \n",
      "4  [1. Place the tomatoes, garlic, salt, paprika,...             7   \n",
      "\n",
      "   willMakeAgainPct  dateCrawled  \n",
      "0               100   1498547035  \n",
      "1                80   1498547740  \n",
      "2                88   1498547738  \n",
      "3               100   1498547740  \n",
      "4                83   1498547740  \n",
      "(34756, 15)\n",
      "\n",
      "\n",
      "--------------\n",
      "Preprocessed Dataframe:\n",
      "                                                                        dek  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  How does fried chicken achieve No. 1 status? B...   \n",
      "54a408a019925f464b3733bc                                Spinaci all'Ebraica   \n",
      "54a408a26529d92b2c003631  This majestic, moist, and richly spiced honey ...   \n",
      "54a408a66529d92b2c003638  The idea for this sandwich came to me when my ...   \n",
      "54a408a719925f464b3733cc  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                                            hed  \\\n",
      "id                                                                \n",
      "54a2b6b019925f464b373351            Pickle-Brined Fried Chicken   \n",
      "54a408a019925f464b3733bc                   Spinach Jewish Style   \n",
      "54a408a26529d92b2c003631                  New Year’s Honey Cake   \n",
      "54a408a66529d92b2c003638  The B.L.A.Bagel with Lox and Avocado   \n",
      "54a408a719925f464b3733cc        Shakshuka a la Doktor Shakshuka   \n",
      "\n",
      "                          aggregateRating  \\\n",
      "id                                          \n",
      "54a2b6b019925f464b373351             3.11   \n",
      "54a408a019925f464b3733bc             3.22   \n",
      "54a408a26529d92b2c003631             3.62   \n",
      "54a408a66529d92b2c003638             4.00   \n",
      "54a408a719925f464b3733cc             2.71   \n",
      "\n",
      "                                                                ingredients  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "54a408a019925f464b3733bc  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "54a408a26529d92b2c003631  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "54a408a66529d92b2c003638  [1 small ripe avocado, preferably Hass (see No...   \n",
      "54a408a719925f464b3733cc  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                                                  prepSteps  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [Toast mustard and coriander seeds in a dry me...   \n",
      "54a408a019925f464b3733bc  [Remove the stems and roots from the spinach. ...   \n",
      "54a408a26529d92b2c003631  [I like this cake best baked in a 9-inch angel...   \n",
      "54a408a66529d92b2c003638  [A short time before serving, mash avocado and...   \n",
      "54a408a719925f464b3733cc  [1. Place the tomatoes, garlic, salt, paprika,...   \n",
      "\n",
      "                          reviewsCount  willMakeAgainPct     cuisine_name  \\\n",
      "id                                                                          \n",
      "54a2b6b019925f464b373351             7               100  Missing Cuisine   \n",
      "54a408a019925f464b3733bc             5                80          Italian   \n",
      "54a408a26529d92b2c003631           105                88           Kosher   \n",
      "54a408a66529d92b2c003638             7               100           Kosher   \n",
      "54a408a719925f464b3733cc             7                83           Kosher   \n",
      "\n",
      "                                               photo_filename  \\\n",
      "id                                                              \n",
      "54a2b6b019925f464b373351       51247610_fried-chicken_1x1.jpg   \n",
      "54a408a019925f464b3733bc  EP_12162015_placeholders_rustic.jpg   \n",
      "54a408a26529d92b2c003631          EP_09022015_honeycake-2.jpg   \n",
      "54a408a66529d92b2c003638  EP_12162015_placeholders_casual.jpg   \n",
      "54a408a719925f464b3733cc  EP_12162015_placeholders_formal.jpg   \n",
      "\n",
      "                                                               photo_credit  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351                Michael Graydon and Nikole Herriott   \n",
      "54a408a019925f464b3733bc  Photo by Chelsea Kyle, Prop Styling by Anna St...   \n",
      "54a408a26529d92b2c003631  Photo by Chelsea Kyle, Food Styling by Anna St...   \n",
      "54a408a66529d92b2c003638  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "54a408a719925f464b3733cc  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "\n",
      "                                  author_name            date_published  \\\n",
      "id                                                                        \n",
      "54a2b6b019925f464b373351  Missing Author Name 2014-08-19 04:00:00+00:00   \n",
      "54a408a019925f464b3733bc   Edda Servi Machlin 2008-09-09 04:00:00+00:00   \n",
      "54a408a26529d92b2c003631        Marcy Goldman 2008-09-10 04:00:00+00:00   \n",
      "54a408a66529d92b2c003638            Faye Levy 2008-09-08 04:00:00+00:00   \n",
      "54a408a719925f464b3733cc          Joan Nathan 2008-09-09 04:00:00+00:00   \n",
      "\n",
      "                                                                 recipe_url  \n",
      "id                                                                           \n",
      "54a2b6b019925f464b373351  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a019925f464b3733bc  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a26529d92b2c003631  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a66529d92b2c003638  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a719925f464b3733cc  https://www.epicurious.com/recipes/food/views/...  \n",
      "(34656, 13)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Recipe ingredients:\n",
      "id\n",
      "54a2b6b019925f464b373351                   1 tablespoons yellow mustard seeds\n",
      "54a408a019925f464b3733bc                 3 pounds small - leaved bulk spinach\n",
      "54a408a26529d92b2c003631                       3 1/2 cups all - purpose flour\n",
      "54a408a66529d92b2c003638    1 small ripe avocado , preferably hass ( see n...\n",
      "54a408a719925f464b3733cc    2 pounds fresh tomatoes , unpeeled and cut in ...\n",
      "                                                  ...                        \n",
      "59541a31bff3052847ae2107    1 tablespoon unsalted butter , at room tempera...\n",
      "5954233ad52ca90dc28200e7    8 tablespoons ( 1 stick ) salted butter , at r...\n",
      "595424c2109c972493636f83    3 tablespoons unsalted butter , plus more for ...\n",
      "5956638625dc3d1d829b7166                                          coarse salt\n",
      "59566daa25dc3d1d829b7169    1 bottle ( 375 ml ) sour beer , such as almana...\n",
      "Name: ingredients, Length: 34656, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2870860c0784992991a13d5410b1ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1083 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 07:16:59,080 - BERTopic - Transformed documents to Embeddings\n",
      "2023-12-10 07:17:36,106 - BERTopic - Reduced dimensionality\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2023-12-10 07:50:28,066 - BERTopic - Clustered reduced embeddings\n",
      "2023-12-10 07:50:31,241 - BERTopic - Reduced number of topics from 1479 to 515\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# load from MLflow\n",
    "mlflow_client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow')\n",
    "\n",
    "# load dataframes from artifacts\n",
    "# mlflow.artifacts.download_artifacts(\n",
    "#     run_id=mlflow_run_id\n",
    "# )\n",
    "\n",
    "# cv_params are parameters for the sklearn CountVectorizer or TFIDFVectorizer\n",
    "cv_params = {\n",
    "    'strip_accents':\"unicode\",\n",
    "    'lowercase':True,\n",
    "    'analyzer': StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4),\n",
    "    'min_df':10,\n",
    "}\n",
    "\n",
    "# bertopic_params are a superset of cv_params\n",
    "bertopic_params = {\n",
    "    'top_n_words':20,\n",
    "    'min_topic_size':5,\n",
    "    'nr_topics':'auto',\n",
    "    'verbose':True,\n",
    "    'low_memory':True,\n",
    "    'calculate_probabilities':True\n",
    "}\n",
    "\n",
    "# update bertopic_params to include cv_params\n",
    "# bertopic_params.update(cv_params)\n",
    "\n",
    "# pipeline_params are parameters that will be logged in MLFlow and are a superset of library parameters\n",
    "pipeline_params = {\n",
    "    'stanza_model': 'en',\n",
    "    'sklearn-transformer': 'TfidfVectorizer'\n",
    "}\n",
    "\n",
    "# update the pipeline parameters with the library-specific ones so that they show up in MLflow Tracking\n",
    "pipeline_params.update(cv_params)\n",
    "pipeline_params.update(bertopic_params)\n",
    "\n",
    "with mlflow.start_run(experiment_id=get_experiment_id(f\"{DAGSHUB_EMAIL}/bertopic_stanza_ingreds_full_set_v1\")):    \n",
    "    # LOG PARAMETERS\n",
    "    mlflow.log_params(pipeline_params)\n",
    "\n",
    "    # LOG INPUTS (QUERIES) AND OUTPUTS\n",
    "    # MLflow example uses a list of strings or a list of str->str dicts\n",
    "    \n",
    "    # load raw data and preprocess/clean\n",
    "    data = dvc.api.read(\n",
    "           path='../data/recipes-en-201706/epicurious-recipes_m2.json'\n",
    "           , mode='r')\n",
    "    raw_df = pd.read_json(data)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print('Raw Dataframe:', end='\\n')\n",
    "    print(raw_df.head())\n",
    "    print(raw_df.shape)\n",
    "\n",
    "    # pre_proc_df is cleaned dataframe\n",
    "    pre_proc_df = dfpp.preprocess_dataframe(raw_df)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print('Preprocessed Dataframe:', end='\\n')\n",
    "    print(pre_proc_df.head())\n",
    "    print(pre_proc_df.shape)\n",
    "\n",
    "\n",
    "    # pre_proc_df = pd.read_json(\n",
    "    #     mlflow.artifacts.download_artifacts(\n",
    "    #         run_id=mlflow_run_id,\n",
    "    #         artifact_path='artifacts/preprocessed_dataframes/preprocessed_dataframe.json',\n",
    "    #         # tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow'\n",
    "    #     )\n",
    "    # )\n",
    "    # print('\\n')\n",
    "    # print('-' * 80)\n",
    "    # print('Preprocessed Dataframe:', end='\\n')\n",
    "    # print(pre_proc_df.head())\n",
    "    # print(pre_proc_df.shape)\n",
    "\n",
    "    # create subset for dev purposes\n",
    "    # to_nlp_df = pre_proc_df[0:50]\n",
    "    # print('\\n')\n",
    "    # print('-' * 80)\n",
    "    # print('Subset Dataframe:', end='\\n')\n",
    "    # print(to_nlp_df.head())\n",
    "    # print(to_nlp_df.shape)\n",
    "\n",
    "    # LOG MODEL\n",
    "    # Instantiate BERTopic\n",
    "    topic_model = BERTopic(\n",
    "        **bertopic_params,\n",
    "    )\n",
    "\n",
    "    def custom_analyzer(step_list, stanza_pipeline, minNgramLength, maxNgramLength):\n",
    "            lowered = \" brk \".join(map(str, [step for step in step_list if step is not None])).lower()\n",
    "\n",
    "            preproc = stanza_pipeline(lowered)\n",
    "            \n",
    "            lemmad = \" \".join(map(str,\n",
    "                                [word.text\n",
    "                                for sent in preproc.sentences \n",
    "                                for word in sent.words if (\n",
    "                                    word is not None\n",
    "                                )]\n",
    "                            )\n",
    "                        )\n",
    "            \n",
    "            # analyze each line of the input string seperately\n",
    "            for ln in lemmad.split(' brk '):\n",
    "                \n",
    "                # tokenize the input string (customize the regex as desired)\n",
    "                at_least_two_english_characters_whole_words = \"(?u)\\b[a-zA-Z]{2,}\\b\"\n",
    "                terms = re.split(at_least_two_english_characters_whole_words, ln)\n",
    "\n",
    "                # loop ngram creation for every number between min and max ngram length\n",
    "                for ngramLength in range(minNgramLength, maxNgramLength+1):\n",
    "\n",
    "                    # find and return all ngrams\n",
    "                    # for ngram in zip(*[terms[i:] for i in range(3)]): \n",
    "                        # <-- solution without a generator (works the same but has higher memory usage)\n",
    "                    for ngram in zip(*[islice(seq, i, len(terms)) for i, seq in enumerate(tee(terms, ngramLength))]):   # <-- solution using a generator\n",
    "                        \n",
    "                        ngram = ' '.join(map(str, ngram))\n",
    "                        # yield ngram\n",
    "                        return str(ngram)\n",
    "\n",
    "    analyzer_kwargs = {'stanza_pipeline': nlp\n",
    "                       , 'minNgramLength': 1\n",
    "                       , 'maxNgramLength': 4}\n",
    "    \n",
    "    recipe_ingreds = pre_proc_df[\"ingredients\"].apply(custom_analyzer, **analyzer_kwargs)\n",
    "\n",
    "    # recipe_steps = \"\".join(str(to_nlp_df[\"prepSteps\"].apply(StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4))))\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('Recipe ingredients:', end='\\n')\n",
    "    print(recipe_ingreds)\n",
    "\n",
    "    # train on the recipes' steps\n",
    "    topics, probs = topic_model.fit_transform(recipe_ingreds)\n",
    "\n",
    "    # since this uses a custom Stanza analyzer, we have to use a custom mlflow.Pyfunc.PythonModel\n",
    "    # Instantiate sklearn CountVectorizer\n",
    "    # steps_vectorizer_model = CountVectorizer(**cv_params)\n",
    "\n",
    "    # May need to use BERTopic's OnlineCountVectorizer\n",
    "    steps_vectorizer_model = OnlineCountVectorizer(**cv_params)\n",
    "\n",
    "    # Do fit transform on data\n",
    "    # steps_test_tfidf_transform = steps_tfidf_vectorizer_model.fit_transform(tqdm(to_nlp_df[\"steps\"]))\n",
    "    topic_model.update_topics(\n",
    "        recipe_ingreds\n",
    "        , vectorizer_model=steps_vectorizer_model\n",
    "    )\n",
    "\n",
    "    # Display topic model results\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('BERTopic Model Dataframe:', end='\\n')\n",
    "    print(topic_model.get_topic_info())\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('BERTopic Model Representations:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representation'])\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('BERTopic Model Representations:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representative_Docs'])\n",
    "\n",
    "    # Save and log the topic model dataframe\n",
    "    topic_model.get_topic_info().to_json('../data/processed/bertopic_model_ingreds_full_set_df.json')\n",
    "    mlflow.log_artifact('../data/processed/bertopic_model_ingreds_full_set_df.json',\n",
    "                        artifact_path='bertopic_models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
