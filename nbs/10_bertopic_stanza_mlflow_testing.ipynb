{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: test\n",
    "output-file: template.html\n",
    "title: Template\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# | default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import OnlineCountVectorizer\n",
    "import dagshub\n",
    "from datetime import datetime\n",
    "import dill as pickle\n",
    "import dvc.api\n",
    "from hdbscan import HDBSCAN\n",
    "from itertools import tee, islice\n",
    "import mlflow\n",
    "import nbdev\n",
    "from nbdev.showdoc import *\n",
    "import pandas as pd\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer\n",
    "    , TfidfTransformer\n",
    "    , TfidfVectorizer\n",
    "    ,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from src.custom_stanza_mlflow import StanzaWrapper\n",
    "import src.dataframe_preprocessor as dfpp\n",
    "import stanza\n",
    "import tqdm\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# | export\n",
    "def foo():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# this function allows us to get the experiment ID from an experiment name\n",
    "def get_experiment_id(name):\n",
    "    exp = mlflow.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "      exp_id = mlflow.create_experiment(name)\n",
    "      return exp_id\n",
    "    return exp.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_analyzer(step_list, stanza_pipeline, minNgramLength, maxNgramLength):\n",
    "    lowered = \" brk \".join(map(str, [step for step in step_list if step is not None])).lower()\n",
    "\n",
    "    preproc = stanza_pipeline(lowered)\n",
    "    \n",
    "    lemmad = \" \".join(map(str,\n",
    "                        [word.text\n",
    "                        for sent in preproc.sentences \n",
    "                        for word in sent.words if (\n",
    "                            word is not None\n",
    "                        )]\n",
    "                    )\n",
    "                )\n",
    "    \n",
    "    # analyze each line of the input string seperately\n",
    "    for ln in lemmad.split(' brk '):\n",
    "        \n",
    "        # tokenize the input string (customize the regex as desired)\n",
    "        at_least_two_english_characters_whole_words = \"(?u)\\b[a-zA-Z]{2,}\\b\"\n",
    "        terms = re.split(at_least_two_english_characters_whole_words, ln)\n",
    "\n",
    "        # loop ngram creation for every number between min and max ngram length\n",
    "        for ngramLength in range(minNgramLength, maxNgramLength+1):\n",
    "\n",
    "            # find and return all ngrams\n",
    "            # for ngram in zip(*[terms[i:] for i in range(3)]): \n",
    "                # <-- solution without a generator (works the same but has higher memory usage)\n",
    "            for ngram in zip(*[islice(seq, i, len(terms)) for i, seq in enumerate(tee(terms, ngramLength))]):   # <-- solution using a generator\n",
    "                \n",
    "                ngram = ' '.join(map(str, ngram))\n",
    "                # yield ngram\n",
    "                return str(ngram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# | Below this are blocks to use DagsHub with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@markdown Enter the username of your DAGsHub account:\n",
    "DAGSHUB_USER_NAME = \"AaronWChen\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the email for your DAGsHub account:\n",
    "DAGSHUB_EMAIL = \"awc33@cornell.edu\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the repo name \n",
    "DAGSHUB_REPO_NAME=\"MeaLeon\"\n",
    "\n",
    "#@markdown Enter the name of the branch you are working on \n",
    "BRANCH=\"STANZA-2/investigate_bertopic_compatibility\"\n",
    "dagshub.init(repo_name=DAGSHUB_REPO_NAME\n",
    "             , repo_owner=DAGSHUB_USER_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33710845ef0b4c19b4e73fd23a64ffd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 15:13:48 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-12-12 15:13:50 INFO: File exists: /home/awchen/stanza_resources/en/default.zip\n",
      "2023-12-12 15:13:54 INFO: Finished downloading models and saved to /home/awchen/stanza_resources.\n",
      "2023-12-12 15:13:54 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72d1c2d61234fb5afbce0c3d0f5679c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 15:13:55 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| lemma        | combined_nocharlm   |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "| depparse     | combined_charlm     |\n",
      "| sentiment    | sstplus             |\n",
      "| ner          | ontonotes_charlm    |\n",
      "======================================\n",
      "\n",
      "2023-12-12 15:13:55 INFO: Using device: cpu\n",
      "2023-12-12 15:13:55 INFO: Loading: tokenize\n",
      "2023-12-12 15:13:55 INFO: Loading: pos\n",
      "2023-12-12 15:13:55 INFO: Loading: lemma\n",
      "2023-12-12 15:13:55 INFO: Loading: constituency\n",
      "2023-12-12 15:13:56 INFO: Loading: depparse\n",
      "2023-12-12 15:13:56 INFO: Loading: sentiment\n",
      "2023-12-12 15:13:56 INFO: Loading: ner\n",
      "2023-12-12 15:13:57 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# instantiate stanza pipeline\n",
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline('en', \n",
    "                      depparse_batch_size=50, \n",
    "                      depparse_min_length_to_batch_separately=50,\n",
    "                      verbose=True,\n",
    "                      use_gpu=False,\n",
    "                    #   batch_size=100\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow')\n",
    "\n",
    "# starter idea for making an experiment name can be the git branch, but need more specificity\n",
    "experiment_name = f\"{DAGSHUB_EMAIL}/bertopic_stanza_small_set_v1\"\n",
    "mlflow_exp_id = get_experiment_id(experiment_name)\n",
    "\n",
    "# run_id that has the logged info needed\n",
    "mlflow_run_id = 'c6fbcf396af34ee3aade5503ee01c2bb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from MLflow\n",
    "mlflow_client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow')\n",
    "\n",
    "# load dataframes from artifacts\n",
    "# mlflow.artifacts.download_artifacts(\n",
    "#     run_id=mlflow_run_id\n",
    "# )\n",
    "\n",
    "# cv_params are parameters for the sklearn CountVectorizer or TFIDFVectorizer\n",
    "cv_params = {\n",
    "    'strip_accents':\"unicode\",\n",
    "    'lowercase':True,\n",
    "    'analyzer': StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4),\n",
    "    'min_df':3,\n",
    "}\n",
    "\n",
    "# bertopic_params are a superset of cv_params\n",
    "bertopic_params = {\n",
    "    'top_n_words':20,\n",
    "    'min_topic_size':5,\n",
    "    'nr_topics':'auto',\n",
    "    'verbose':True,\n",
    "    'low_memory':True,\n",
    "    'calculate_probabilities':True\n",
    "}\n",
    "\n",
    "# update bertopic_params to include cv_params\n",
    "# bertopic_params.update(cv_params)\n",
    "\n",
    "# pipeline_params are parameters that will be logged in MLFlow and are a superset of library parameters\n",
    "pipeline_params = {\n",
    "    'stanza_model': 'en',\n",
    "    'sklearn-transformer': 'TfidfVectorizer'\n",
    "}\n",
    "\n",
    "# update the pipeline parameters with the library-specific ones so that they show up in MLflow Tracking\n",
    "pipeline_params.update(cv_params)\n",
    "pipeline_params.update(bertopic_params)\n",
    "\n",
    "with mlflow.start_run(experiment_id=mlflow_exp_id):    \n",
    "    # LOG PARAMETERS\n",
    "    mlflow.log_params(pipeline_params)\n",
    "\n",
    "    # LOG INPUTS (QUERIES) AND OUTPUTS\n",
    "    # MLflow example uses a list of strings or a list of str->str dicts\n",
    "    \n",
    "    # load raw data and preprocess/clean\n",
    "    data = dvc.api.read(\n",
    "           path='../data/recipes-en-201706/epicurious-recipes_m2.json'\n",
    "           , mode='r')\n",
    "    raw_df = pd.read_json(data)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print('Raw Dataframe:', end='\\n')\n",
    "    print(raw_df.head())\n",
    "    print(raw_df.shape)\n",
    "\n",
    "    # pre_proc_df is cleaned dataframe\n",
    "    pre_proc_df = dfpp.preprocess_dataframe(raw_df)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print('Preprocessed Dataframe:', end='\\n')\n",
    "    print(pre_proc_df.head())\n",
    "    print(pre_proc_df.shape)\n",
    "\n",
    "\n",
    "    # pre_proc_df = pd.read_json(\n",
    "    #     mlflow.artifacts.download_artifacts(\n",
    "    #         run_id=mlflow_run_id,\n",
    "    #         artifact_path='artifacts/preprocessed_dataframes/preprocessed_dataframe.json',\n",
    "    #         # tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow'\n",
    "    #     )\n",
    "    # )\n",
    "    # print('\\n')\n",
    "    # print('-' * 80)\n",
    "    # print('Preprocessed Dataframe:', end='\\n')\n",
    "    # print(pre_proc_df.head())\n",
    "    # print(pre_proc_df.shape)\n",
    "\n",
    "    # create subset for dev purposes\n",
    "    to_nlp_df = pre_proc_df[0:50]\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('Subset Dataframe:', end='\\n')\n",
    "    print(to_nlp_df.head())\n",
    "    print(to_nlp_df.shape)\n",
    "\n",
    "    # LOG MODEL\n",
    "    # Instantiate BERTopic\n",
    "    topic_model = BERTopic(\n",
    "        **bertopic_params,\n",
    "    )\n",
    "\n",
    "    def custom_analyzer(step_list, stanza_pipeline, minNgramLength, maxNgramLength):\n",
    "            lowered = \" brk \".join(map(str, [step for step in step_list if step is not None])).lower()\n",
    "\n",
    "            preproc = stanza_pipeline(lowered)\n",
    "            \n",
    "            lemmad = \" \".join(map(str,\n",
    "                                [word.text\n",
    "                                for sent in preproc.sentences \n",
    "                                for word in sent.words if (\n",
    "                                    word is not None\n",
    "                                )]\n",
    "                            )\n",
    "                        )\n",
    "            \n",
    "            # analyze each line of the input string seperately\n",
    "            for ln in lemmad.split(' brk '):\n",
    "                \n",
    "                # tokenize the input string (customize the regex as desired)\n",
    "                at_least_two_english_characters_whole_words = \"(?u)\\b[a-zA-Z]{2,}\\b\"\n",
    "                terms = re.split(at_least_two_english_characters_whole_words, ln)\n",
    "\n",
    "                # loop ngram creation for every number between min and max ngram length\n",
    "                for ngramLength in range(minNgramLength, maxNgramLength+1):\n",
    "\n",
    "                    # find and return all ngrams\n",
    "                    # for ngram in zip(*[terms[i:] for i in range(3)]): \n",
    "                        # <-- solution without a generator (works the same but has higher memory usage)\n",
    "                    for ngram in zip(*[islice(seq, i, len(terms)) for i, seq in enumerate(tee(terms, ngramLength))]):   # <-- solution using a generator\n",
    "                        \n",
    "                        ngram = ' '.join(map(str, ngram))\n",
    "                        # yield ngram\n",
    "                        return str(ngram)\n",
    "\n",
    "    analyzer_kwargs = {'stanza_pipeline': nlp\n",
    "                       , 'minNgramLength': 1\n",
    "                       , 'maxNgramLength': 4}\n",
    "    \n",
    "    recipe_steps = to_nlp_df[\"prepSteps\"].apply(custom_analyzer, **analyzer_kwargs)\n",
    "\n",
    "    # recipe_steps = \"\".join(str(to_nlp_df[\"prepSteps\"].apply(StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4))))\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('Recipe steps:', end='\\n')\n",
    "    print(recipe_steps)\n",
    "\n",
    "    # train on the recipes' steps\n",
    "    topics, probs = topic_model.fit_transform(recipe_steps)\n",
    "\n",
    "    # since this uses a custom Stanza analyzer, we have to use a custom mlflow.Pyfunc.PythonModel\n",
    "    # Instantiate sklearn CountVectorizer\n",
    "    # steps_vectorizer_model = CountVectorizer(**cv_params)\n",
    "\n",
    "    # May need to use BERTopic's OnlineCountVectorizer\n",
    "    steps_vectorizer_model = OnlineCountVectorizer(**cv_params)\n",
    "\n",
    "    # Do fit transform on data\n",
    "    # steps_test_tfidf_transform = steps_tfidf_vectorizer_model.fit_transform(tqdm(to_nlp_df[\"steps\"]))\n",
    "    topic_model.update_topics(\n",
    "        recipe_steps\n",
    "        , vectorizer_model=steps_vectorizer_model\n",
    "    )\n",
    "\n",
    "    # Display topic model results\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('BERTopic Model Dataframe:', end='\\n')\n",
    "    print(topic_model.get_topic_info())\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('BERTopic Model Representations:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representation'])\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('BERTopic Model Representations:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representative_Docs'])\n",
    "\n",
    "    # Save and log the topic model dataframe\n",
    "    topic_model.get_topic_info().to_json('../data/processed/bertopic_model_small_set_df.json')\n",
    "    mlflow.log_artifact('../data/processed/bertopic_model_small_set_df.json',\n",
    "                        artifact_path='bertopic_models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from MLflow\n",
    "mlflow_client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow')\n",
    "\n",
    "# load dataframes from artifacts\n",
    "# mlflow.artifacts.download_artifacts(\n",
    "#     run_id=mlflow_run_id\n",
    "# )\n",
    "\n",
    "# cv_params are parameters for the sklearn CountVectorizer or TFIDFVectorizer\n",
    "cv_params = {\n",
    "    'strip_accents':\"unicode\",\n",
    "    'lowercase':True,\n",
    "    'analyzer': StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4),\n",
    "    'min_df':10,\n",
    "}\n",
    "\n",
    "# bertopic_params are a superset of cv_params\n",
    "bertopic_params = {\n",
    "    'top_n_words':20,\n",
    "    'min_topic_size':10,\n",
    "    'nr_topics':'auto',\n",
    "    'verbose':True,\n",
    "    'low_memory':True,\n",
    "    'calculate_probabilities':True\n",
    "}\n",
    "\n",
    "# update bertopic_params to include cv_params\n",
    "# bertopic_params.update(cv_params)\n",
    "\n",
    "# pipeline_params are parameters that will be logged in MLFlow and are a superset of library parameters\n",
    "pipeline_params = {\n",
    "    'stanza_model': 'en',\n",
    "    'sklearn-transformer': 'TfidfVectorizer'\n",
    "}\n",
    "\n",
    "# update the pipeline parameters with the library-specific ones so that they show up in MLflow Tracking\n",
    "pipeline_params.update(cv_params)\n",
    "pipeline_params.update(bertopic_params)\n",
    "\n",
    "with mlflow.start_run(experiment_id=get_experiment_id(f\"{DAGSHUB_EMAIL}/bertopic_stanza_ingreds_full_set_v1\")):    \n",
    "    # LOG PARAMETERS\n",
    "    mlflow.log_params(pipeline_params)\n",
    "\n",
    "    # LOG INPUTS (QUERIES) AND OUTPUTS\n",
    "    # MLflow example uses a list of strings or a list of str->str dicts\n",
    "    \n",
    "    # load raw data and preprocess/clean\n",
    "    data = dvc.api.read(\n",
    "           path='../data/recipes-en-201706/epicurious-recipes_m2.json'\n",
    "           , mode='r')\n",
    "    raw_df = pd.read_json(data)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print('Raw Dataframe:', end='\\n')\n",
    "    print(raw_df.head())\n",
    "    print(raw_df.shape)\n",
    "\n",
    "    # pre_proc_df is cleaned dataframe\n",
    "    pre_proc_df = dfpp.preprocess_dataframe(raw_df)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print('Preprocessed Dataframe:', end='\\n')\n",
    "    print(pre_proc_df.head())\n",
    "    print(pre_proc_df.shape)\n",
    "\n",
    "\n",
    "    # pre_proc_df = pd.read_json(\n",
    "    #     mlflow.artifacts.download_artifacts(\n",
    "    #         run_id=mlflow_run_id,\n",
    "    #         artifact_path='artifacts/preprocessed_dataframes/preprocessed_dataframe.json',\n",
    "    #         # tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow'\n",
    "    #     )\n",
    "    # )\n",
    "    # print('\\n')\n",
    "    # print('-' * 80)\n",
    "    # print('Preprocessed Dataframe:', end='\\n')\n",
    "    # print(pre_proc_df.head())\n",
    "    # print(pre_proc_df.shape)\n",
    "\n",
    "    # create subset for dev purposes\n",
    "    # to_nlp_df = pre_proc_df[0:50]\n",
    "    # print('\\n')\n",
    "    # print('-' * 80)\n",
    "    # print('Subset Dataframe:', end='\\n')\n",
    "    # print(to_nlp_df.head())\n",
    "    # print(to_nlp_df.shape)\n",
    "\n",
    "    # LOG MODEL\n",
    "    # Instantiate BERTopic\n",
    "    topic_model = BERTopic(\n",
    "        **bertopic_params,\n",
    "    )\n",
    "\n",
    "    def custom_analyzer(step_list, stanza_pipeline, minNgramLength, maxNgramLength):\n",
    "            lowered = \" brk \".join(map(str, [step for step in step_list if step is not None])).lower()\n",
    "\n",
    "            preproc = stanza_pipeline(lowered)\n",
    "            \n",
    "            lemmad = \" \".join(map(str,\n",
    "                                [word.text\n",
    "                                for sent in preproc.sentences \n",
    "                                for word in sent.words if (\n",
    "                                    word is not None\n",
    "                                )]\n",
    "                            )\n",
    "                        )\n",
    "            \n",
    "            # analyze each line of the input string seperately\n",
    "            for ln in lemmad.split(' brk '):\n",
    "                \n",
    "                # tokenize the input string (customize the regex as desired)\n",
    "                at_least_two_english_characters_whole_words = \"(?u)\\b[a-zA-Z]{2,}\\b\"\n",
    "                terms = re.split(at_least_two_english_characters_whole_words, ln)\n",
    "\n",
    "                # loop ngram creation for every number between min and max ngram length\n",
    "                for ngramLength in range(minNgramLength, maxNgramLength+1):\n",
    "\n",
    "                    # find and return all ngrams\n",
    "                    # for ngram in zip(*[terms[i:] for i in range(3)]): \n",
    "                        # <-- solution without a generator (works the same but has higher memory usage)\n",
    "                    for ngram in zip(*[islice(seq, i, len(terms)) for i, seq in enumerate(tee(terms, ngramLength))]):   # <-- solution using a generator\n",
    "                        \n",
    "                        ngram = ' '.join(map(str, ngram))\n",
    "                        # yield ngram\n",
    "                        return str(ngram)\n",
    "\n",
    "    analyzer_kwargs = {'stanza_pipeline': nlp\n",
    "                       , 'minNgramLength': 1\n",
    "                       , 'maxNgramLength': 4}\n",
    "    \n",
    "    recipe_ingreds = pre_proc_df[\"ingredients\"].apply(custom_analyzer, **analyzer_kwargs)\n",
    "\n",
    "    # recipe_steps = \"\".join(str(to_nlp_df[\"prepSteps\"].apply(StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4))))\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('Recipe ingredients:', end='\\n')\n",
    "    print(recipe_ingreds)\n",
    "\n",
    "    # train on the recipes' steps\n",
    "    topics, probs = topic_model.fit_transform(recipe_ingreds)\n",
    "\n",
    "    # since this uses a custom Stanza analyzer, we have to use a custom mlflow.Pyfunc.PythonModel\n",
    "    # Instantiate sklearn CountVectorizer\n",
    "    # steps_vectorizer_model = CountVectorizer(**cv_params)\n",
    "\n",
    "    # May need to use BERTopic's OnlineCountVectorizer\n",
    "    steps_vectorizer_model = OnlineCountVectorizer(**cv_params)\n",
    "\n",
    "    # Do fit transform on data\n",
    "    # steps_test_tfidf_transform = steps_tfidf_vectorizer_model.fit_transform(tqdm(to_nlp_df[\"steps\"]))\n",
    "    topic_model.update_topics(\n",
    "        recipe_ingreds\n",
    "        , vectorizer_model=steps_vectorizer_model\n",
    "    )\n",
    "\n",
    "    # Display topic model results\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('BERTopic Model Dataframe:', end='\\n')\n",
    "    print(topic_model.get_topic_info())\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('BERTopic Model Representations:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representation'])\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print('BERTopic Model Representations:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representative_Docs'])\n",
    "\n",
    "    # Save and log the topic model dataframe\n",
    "    topic_model.get_topic_info().to_json('../data/processed/bertopic_model_ingreds_full_set_df.json')\n",
    "    mlflow.log_artifact('../data/processed/bertopic_model_ingreds_full_set_df.json',\n",
    "                        artifact_path='bertopic_models')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt run with lighter weight configuration\n",
    "#### This attempt will still use Stanza processing on the ingredients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------\n",
      "2023-12-13 16:53:21.010671, Raw Dataframe: \n",
      "                         id  \\\n",
      "0  54a2b6b019925f464b373351   \n",
      "1  54a408a019925f464b3733bc   \n",
      "2  54a408a26529d92b2c003631   \n",
      "3  54a408a66529d92b2c003638   \n",
      "4  54a408a719925f464b3733cc   \n",
      "\n",
      "                                                 dek  \\\n",
      "0  How does fried chicken achieve No. 1 status? B...   \n",
      "1                                Spinaci all'Ebraica   \n",
      "2  This majestic, moist, and richly spiced honey ...   \n",
      "3  The idea for this sandwich came to me when my ...   \n",
      "4  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                     hed                   pubDate  \\\n",
      "0            Pickle-Brined Fried Chicken  2014-08-19T04:00:00.000Z   \n",
      "1                   Spinach Jewish Style  2008-09-09T04:00:00.000Z   \n",
      "2                  New Year’s Honey Cake  2008-09-10T04:00:00.000Z   \n",
      "3  The B.L.A.Bagel with Lox and Avocado  2008-09-08T04:00:00.000Z   \n",
      "4        Shakshuka a la Doktor Shakshuka  2008-09-09T04:00:00.000Z   \n",
      "\n",
      "                             author    type  \\\n",
      "0                                []  recipe   \n",
      "1  [{'name': 'Edda Servi Machlin'}]  recipe   \n",
      "2       [{'name': 'Marcy Goldman'}]  recipe   \n",
      "3           [{'name': 'Faye Levy'}]  recipe   \n",
      "4         [{'name': 'Joan Nathan'}]  recipe   \n",
      "\n",
      "                                                 url  \\\n",
      "0  /recipes/food/views/pickle-brined-fried-chicke...   \n",
      "1    /recipes/food/views/spinach-jewish-style-350152   \n",
      "2  /recipes/food/views/majestic-and-moist-new-yea...   \n",
      "3  /recipes/food/views/the-b-l-a-bagel-with-lox-a...   \n",
      "4  /recipes/food/views/shakshuka-a-la-doktor-shak...   \n",
      "\n",
      "                                           photoData  \\\n",
      "0  {'id': '54a2b64a6529d92b2c003409', 'filename':...   \n",
      "1  {'id': '56746182accb4c9831e45e0a', 'filename':...   \n",
      "2  {'id': '55e85ba4cf90d6663f728014', 'filename':...   \n",
      "3  {'id': '5674617e47d1a28026045e4f', 'filename':...   \n",
      "4  {'id': '56746183b47c050a284a4e15', 'filename':...   \n",
      "\n",
      "                                                 tag  aggregateRating  \\\n",
      "0  {'category': 'ingredient', 'name': 'Chicken', ...             3.11   \n",
      "1  {'category': 'cuisine', 'name': 'Italian', 'ur...             3.22   \n",
      "2  {'category': 'cuisine', 'name': 'Jewish', 'url...             3.62   \n",
      "3  {'category': 'cuisine', 'name': 'Jewish', 'url...             4.00   \n",
      "4  {'category': 'cuisine', 'name': 'Jewish', 'url...             2.71   \n",
      "\n",
      "                                         ingredients  \\\n",
      "0  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "1  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "2  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "3  [1 small ripe avocado, preferably Hass (see No...   \n",
      "4  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                           prepSteps  reviewsCount  \\\n",
      "0  [Toast mustard and coriander seeds in a dry me...             7   \n",
      "1  [Remove the stems and roots from the spinach. ...             5   \n",
      "2  [I like this cake best baked in a 9-inch angel...           105   \n",
      "3  [A short time before serving, mash avocado and...             7   \n",
      "4  [1. Place the tomatoes, garlic, salt, paprika,...             7   \n",
      "\n",
      "   willMakeAgainPct  dateCrawled  \n",
      "0               100   1498547035  \n",
      "1                80   1498547740  \n",
      "2                88   1498547738  \n",
      "3               100   1498547740  \n",
      "4                83   1498547740  \n",
      "(34756, 15)\n",
      "\n",
      "\n",
      "--------------\n",
      "2023-12-13 16:53:21.449956, Preprocessed Dataframe:\n",
      "                                                                        dek  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  How does fried chicken achieve No. 1 status? B...   \n",
      "54a408a019925f464b3733bc                                Spinaci all'Ebraica   \n",
      "54a408a26529d92b2c003631  This majestic, moist, and richly spiced honey ...   \n",
      "54a408a66529d92b2c003638  The idea for this sandwich came to me when my ...   \n",
      "54a408a719925f464b3733cc  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                                            hed  \\\n",
      "id                                                                \n",
      "54a2b6b019925f464b373351            Pickle-Brined Fried Chicken   \n",
      "54a408a019925f464b3733bc                   Spinach Jewish Style   \n",
      "54a408a26529d92b2c003631                  New Year’s Honey Cake   \n",
      "54a408a66529d92b2c003638  The B.L.A.Bagel with Lox and Avocado   \n",
      "54a408a719925f464b3733cc        Shakshuka a la Doktor Shakshuka   \n",
      "\n",
      "                          aggregateRating  \\\n",
      "id                                          \n",
      "54a2b6b019925f464b373351             3.11   \n",
      "54a408a019925f464b3733bc             3.22   \n",
      "54a408a26529d92b2c003631             3.62   \n",
      "54a408a66529d92b2c003638             4.00   \n",
      "54a408a719925f464b3733cc             2.71   \n",
      "\n",
      "                                                                ingredients  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "54a408a019925f464b3733bc  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "54a408a26529d92b2c003631  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "54a408a66529d92b2c003638  [1 small ripe avocado, preferably Hass (see No...   \n",
      "54a408a719925f464b3733cc  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                                                  prepSteps  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [Toast mustard and coriander seeds in a dry me...   \n",
      "54a408a019925f464b3733bc  [Remove the stems and roots from the spinach. ...   \n",
      "54a408a26529d92b2c003631  [I like this cake best baked in a 9-inch angel...   \n",
      "54a408a66529d92b2c003638  [A short time before serving, mash avocado and...   \n",
      "54a408a719925f464b3733cc  [1. Place the tomatoes, garlic, salt, paprika,...   \n",
      "\n",
      "                          reviewsCount  willMakeAgainPct     cuisine_name  \\\n",
      "id                                                                          \n",
      "54a2b6b019925f464b373351             7               100  Missing Cuisine   \n",
      "54a408a019925f464b3733bc             5                80          Italian   \n",
      "54a408a26529d92b2c003631           105                88           Kosher   \n",
      "54a408a66529d92b2c003638             7               100           Kosher   \n",
      "54a408a719925f464b3733cc             7                83           Kosher   \n",
      "\n",
      "                                               photo_filename  \\\n",
      "id                                                              \n",
      "54a2b6b019925f464b373351       51247610_fried-chicken_1x1.jpg   \n",
      "54a408a019925f464b3733bc  EP_12162015_placeholders_rustic.jpg   \n",
      "54a408a26529d92b2c003631          EP_09022015_honeycake-2.jpg   \n",
      "54a408a66529d92b2c003638  EP_12162015_placeholders_casual.jpg   \n",
      "54a408a719925f464b3733cc  EP_12162015_placeholders_formal.jpg   \n",
      "\n",
      "                                                               photo_credit  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351                Michael Graydon and Nikole Herriott   \n",
      "54a408a019925f464b3733bc  Photo by Chelsea Kyle, Prop Styling by Anna St...   \n",
      "54a408a26529d92b2c003631  Photo by Chelsea Kyle, Food Styling by Anna St...   \n",
      "54a408a66529d92b2c003638  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "54a408a719925f464b3733cc  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "\n",
      "                                  author_name            date_published  \\\n",
      "id                                                                        \n",
      "54a2b6b019925f464b373351  Missing Author Name 2014-08-19 04:00:00+00:00   \n",
      "54a408a019925f464b3733bc   Edda Servi Machlin 2008-09-09 04:00:00+00:00   \n",
      "54a408a26529d92b2c003631        Marcy Goldman 2008-09-10 04:00:00+00:00   \n",
      "54a408a66529d92b2c003638            Faye Levy 2008-09-08 04:00:00+00:00   \n",
      "54a408a719925f464b3733cc          Joan Nathan 2008-09-09 04:00:00+00:00   \n",
      "\n",
      "                                                                 recipe_url  \n",
      "id                                                                           \n",
      "54a2b6b019925f464b373351  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a019925f464b3733bc  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a26529d92b2c003631  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a66529d92b2c003638  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a719925f464b3733cc  https://www.epicurious.com/recipes/food/views/...  \n",
      "(34656, 13)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2023-12-13 16:53:21.491831, Subset Dataframe:\n",
      "                                                                        dek  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  How does fried chicken achieve No. 1 status? B...   \n",
      "54a408a019925f464b3733bc                                Spinaci all'Ebraica   \n",
      "54a408a26529d92b2c003631  This majestic, moist, and richly spiced honey ...   \n",
      "54a408a66529d92b2c003638  The idea for this sandwich came to me when my ...   \n",
      "54a408a719925f464b3733cc  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                                            hed  \\\n",
      "id                                                                \n",
      "54a2b6b019925f464b373351            Pickle-Brined Fried Chicken   \n",
      "54a408a019925f464b3733bc                   Spinach Jewish Style   \n",
      "54a408a26529d92b2c003631                  New Year’s Honey Cake   \n",
      "54a408a66529d92b2c003638  The B.L.A.Bagel with Lox and Avocado   \n",
      "54a408a719925f464b3733cc        Shakshuka a la Doktor Shakshuka   \n",
      "\n",
      "                          aggregateRating  \\\n",
      "id                                          \n",
      "54a2b6b019925f464b373351             3.11   \n",
      "54a408a019925f464b3733bc             3.22   \n",
      "54a408a26529d92b2c003631             3.62   \n",
      "54a408a66529d92b2c003638             4.00   \n",
      "54a408a719925f464b3733cc             2.71   \n",
      "\n",
      "                                                                ingredients  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "54a408a019925f464b3733bc  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "54a408a26529d92b2c003631  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "54a408a66529d92b2c003638  [1 small ripe avocado, preferably Hass (see No...   \n",
      "54a408a719925f464b3733cc  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                                                  prepSteps  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [Toast mustard and coriander seeds in a dry me...   \n",
      "54a408a019925f464b3733bc  [Remove the stems and roots from the spinach. ...   \n",
      "54a408a26529d92b2c003631  [I like this cake best baked in a 9-inch angel...   \n",
      "54a408a66529d92b2c003638  [A short time before serving, mash avocado and...   \n",
      "54a408a719925f464b3733cc  [1. Place the tomatoes, garlic, salt, paprika,...   \n",
      "\n",
      "                          reviewsCount  willMakeAgainPct     cuisine_name  \\\n",
      "id                                                                          \n",
      "54a2b6b019925f464b373351             7               100  Missing Cuisine   \n",
      "54a408a019925f464b3733bc             5                80          Italian   \n",
      "54a408a26529d92b2c003631           105                88           Kosher   \n",
      "54a408a66529d92b2c003638             7               100           Kosher   \n",
      "54a408a719925f464b3733cc             7                83           Kosher   \n",
      "\n",
      "                                               photo_filename  \\\n",
      "id                                                              \n",
      "54a2b6b019925f464b373351       51247610_fried-chicken_1x1.jpg   \n",
      "54a408a019925f464b3733bc  EP_12162015_placeholders_rustic.jpg   \n",
      "54a408a26529d92b2c003631          EP_09022015_honeycake-2.jpg   \n",
      "54a408a66529d92b2c003638  EP_12162015_placeholders_casual.jpg   \n",
      "54a408a719925f464b3733cc  EP_12162015_placeholders_formal.jpg   \n",
      "\n",
      "                                                               photo_credit  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351                Michael Graydon and Nikole Herriott   \n",
      "54a408a019925f464b3733bc  Photo by Chelsea Kyle, Prop Styling by Anna St...   \n",
      "54a408a26529d92b2c003631  Photo by Chelsea Kyle, Food Styling by Anna St...   \n",
      "54a408a66529d92b2c003638  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "54a408a719925f464b3733cc  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "\n",
      "                                  author_name            date_published  \\\n",
      "id                                                                        \n",
      "54a2b6b019925f464b373351  Missing Author Name 2014-08-19 04:00:00+00:00   \n",
      "54a408a019925f464b3733bc   Edda Servi Machlin 2008-09-09 04:00:00+00:00   \n",
      "54a408a26529d92b2c003631        Marcy Goldman 2008-09-10 04:00:00+00:00   \n",
      "54a408a66529d92b2c003638            Faye Levy 2008-09-08 04:00:00+00:00   \n",
      "54a408a719925f464b3733cc          Joan Nathan 2008-09-09 04:00:00+00:00   \n",
      "\n",
      "                                                                 recipe_url  \n",
      "id                                                                           \n",
      "54a2b6b019925f464b373351  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a019925f464b3733bc  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a26529d92b2c003631  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a66529d92b2c003638  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a719925f464b3733cc  https://www.epicurious.com/recipes/food/views/...  \n",
      "(100, 13)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2023-12-13 17:19:56.988002, Recipe ingredients:\n",
      "id\n",
      "54a2b6b019925f464b373351                   1 tablespoons yellow mustard seeds\n",
      "54a408a019925f464b3733bc                 3 pounds small - leaved bulk spinach\n",
      "54a408a26529d92b2c003631                       3 1/2 cups all - purpose flour\n",
      "54a408a66529d92b2c003638    1 small ripe avocado , preferably hass ( see n...\n",
      "54a408a719925f464b3733cc    2 pounds fresh tomatoes , unpeeled and cut in ...\n",
      "                                                  ...                        \n",
      "54a409376529d92b2c003884                 8 cups steaming - hot low - fat milk\n",
      "54a409386529d92b2c00388a                         3 carrots , coarsely chopped\n",
      "54a4093a19925f464b373600    5 large eggs , separated , at room temperature...\n",
      "54a4093b6529d92b2c003894    16 pieces bubblegum , preferably double bubble...\n",
      "54a4093c6529d92b2c003899                  1 1/2 pounds medium shrimp in shell\n",
      "Name: ingredients, Length: 100, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 17:20:01,611 - BERTopic - Reduced dimensionality\n",
      "2023-12-13 17:20:01,626 - BERTopic - Clustered reduced embeddings\n",
      "2023-12-13 17:20:01,637 - BERTopic - Reduced number of topics from 5 to 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2023-12-13 17:29:06.479388, BERTopic Model Dataframe:\n",
      "   Topic  Count                                               Name  \\\n",
      "0     -1      5  -1_o None and None e None None p None u None r...   \n",
      "1      0     19  0_None_3 None None None 2 None None c None u N...   \n",
      "2      1     51  1_for_1 None None t None a None billion None N...   \n",
      "3      2     12  2_3 None None p None o None u None and None wo...   \n",
      "4      3     13  3_1 None None None None None c None u None p N...   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [o None and None e None None p None u None r N...   \n",
      "1  [None, 3 None None None 2 None None c None u N...   \n",
      "2  [for, 1 None None t None a None billion None N...   \n",
      "3  [3 None None p None o None u None and None wou...   \n",
      "4  [1 None None None None None c None u None p No...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [one purchased 9 - inch angel food cake, 1 pou...  \n",
      "1  [2 1/4 cups all purpose flour, 2 cups all purp...  \n",
      "2  [2 1/2 cups dried white beans such as great no...  \n",
      "3  [nonstick vegetable oil spray, nonstick vegeta...  \n",
      "4  [1 1/2 lbs ( 600 g ) ground lamb , beef , or v...  \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2023-12-13 17:29:06.497605, BERTopic Model Representations:\n",
      "0    [o None and None e None None p None u None r N...\n",
      "1    [None, 3 None None None 2 None None c None u N...\n",
      "2    [for, 1 None None t None a None billion None N...\n",
      "3    [3 None None p None o None u None and None wou...\n",
      "4    [1 None None None None None c None u None p No...\n",
      "Name: Representation, dtype: object\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2023-12-13 17:29:06.506692, BERTopic Model Representations:\n",
      "0    [one purchased 9 - inch angel food cake, 1 pou...\n",
      "1    [2 1/4 cups all purpose flour, 2 cups all purp...\n",
      "2    [2 1/2 cups dried white beans such as great no...\n",
      "3    [nonstick vegetable oil spray, nonstick vegeta...\n",
      "4    [1 1/2 lbs ( 600 g ) ground lamb , beef , or v...\n",
      "Name: Representative_Docs, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# load from MLflow\n",
    "mlflow_client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow')\n",
    "\n",
    "# cv_params are parameters for the sklearn CountVectorizer or TFIDFVectorizer\n",
    "sklearn_nlp_params = {\n",
    "    'strip_accents':\"unicode\",\n",
    "    'lowercase':True,\n",
    "    'analyzer': StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4),\n",
    "    'min_df':10,\n",
    "}\n",
    "\n",
    "# create sklearn pipeline as in BERTopic lightweight configuration\n",
    "# pipe = make_pipeline(\n",
    "#     TfidfVectorizer(**sklearn_nlp_params),\n",
    "#     TruncatedSVD(100)\n",
    "# )\n",
    "\n",
    "# bertopic_params are a superset of cv_params\n",
    "bertopic_params = {\n",
    "    # 'embedding_model': TfidfVectorizer(**sklearn_nlp_params),\n",
    "    'top_n_words':20,\n",
    "    'min_topic_size':10,\n",
    "    'nr_topics':50,\n",
    "    'verbose':True,\n",
    "    'low_memory':True,\n",
    "    'calculate_probabilities':True,\n",
    "    # 'min_cluster_size': 10 # Possibly only works if modifying individual HDBSCAN component of BERTopic\n",
    "}\n",
    "\n",
    "# update bertopic_params to include cv_params\n",
    "# bertopic_params.update(cv_params)\n",
    "\n",
    "# pipeline_params are parameters that will be logged in MLFlow and are a superset of library parameters\n",
    "pipeline_params = {\n",
    "    'stanza_model': 'en',\n",
    "    'sklearn-transformer': 'TfidfVectorizer'\n",
    "}\n",
    "\n",
    "# update the pipeline parameters with the library-specific ones so that they show up in MLflow Tracking\n",
    "pipeline_params.update(sklearn_nlp_params)\n",
    "pipeline_params.update(bertopic_params)\n",
    "\n",
    "with mlflow.start_run(experiment_id=get_experiment_id(f\"{DAGSHUB_EMAIL}/bertopic_lightweight_stanza_ingreds_small_set_v1\")):    \n",
    "    # LOG PARAMETERS\n",
    "    mlflow.log_params(pipeline_params)\n",
    "\n",
    "    # LOG INPUTS (QUERIES) AND OUTPUTS\n",
    "    # MLflow example uses a list of strings or a list of str->str dicts\n",
    "    \n",
    "    # load raw data and preprocess/clean\n",
    "    data = dvc.api.read(\n",
    "           path='../data/recipes-en-201706/epicurious-recipes_m2.json'\n",
    "           , mode='r')\n",
    "    raw_df = pd.read_json(data)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print(f'{datetime.now()}, Raw Dataframe: ', end='\\n')\n",
    "    print(raw_df.head())\n",
    "    print(raw_df.shape)\n",
    "\n",
    "    # pre_proc_df is cleaned dataframe\n",
    "    pre_proc_df = dfpp.preprocess_dataframe(raw_df)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print(f'{datetime.now()}, Preprocessed Dataframe:', end='\\n')\n",
    "    print(pre_proc_df.head())\n",
    "    print(pre_proc_df.shape)\n",
    "\n",
    "\n",
    "    # pre_proc_df = pd.read_json(\n",
    "    #     mlflow.artifacts.download_artifacts(\n",
    "    #         run_id=mlflow_run_id,\n",
    "    #         artifact_path='artifacts/preprocessed_dataframes/preprocessed_dataframe.json',\n",
    "    #         # tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow'\n",
    "    #     )\n",
    "    # )\n",
    "    # print('\\n')\n",
    "    # print('-' * 80)\n",
    "    # print('Preprocessed Dataframe:', end='\\n')\n",
    "    # print(pre_proc_df.head())\n",
    "    # print(pre_proc_df.shape)\n",
    "\n",
    "    # create subset for dev purposes\n",
    "    to_nlp_df = pre_proc_df[0:100]\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, Subset Dataframe:', end='\\n')\n",
    "    print(to_nlp_df.head())\n",
    "    print(to_nlp_df.shape)\n",
    "\n",
    "    # LOG MODEL\n",
    "    # Instantiate BERTopic\n",
    "    topic_model = BERTopic(\n",
    "        **bertopic_params\n",
    "    )\n",
    "    \n",
    "    analyzer_kwargs = {'stanza_pipeline': nlp\n",
    "                       , 'minNgramLength': 1\n",
    "                       , 'maxNgramLength': 4}\n",
    "    \n",
    "    recipe_ingreds = to_nlp_df[\"ingredients\"].apply(custom_analyzer, **analyzer_kwargs)\n",
    "\n",
    "    # Create TF-IDF embeddings\n",
    "    vectorizer = TfidfVectorizer(**sklearn_nlp_params)\n",
    "    embeddings = vectorizer.fit_transform(recipe_ingreds)\n",
    "\n",
    "    # recipe_steps = \"\".join(str(to_nlp_df[\"prepSteps\"].apply(StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4))))\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, Recipe ingredients:', end='\\n')\n",
    "    print(recipe_ingreds)\n",
    "\n",
    "    # train on the recipes' ingredientss\n",
    "    topics, probs = topic_model.fit_transform(recipe_ingreds, embeddings)\n",
    "\n",
    "    # since this uses a custom Stanza analyzer, we have to use a custom mlflow.Pyfunc.PythonModel\n",
    "    # Instantiate sklearn CountVectorizer\n",
    "    sklearn_cv_params = {\n",
    "        'strip_accents':\"unicode\",\n",
    "        'lowercase':True,\n",
    "        'analyzer': StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4),\n",
    "        # 'min_df':10,\n",
    "    }\n",
    "    steps_vectorizer_model = CountVectorizer(**sklearn_cv_params)\n",
    "\n",
    "    # May need to use BERTopic's OnlineCountVectorizer\n",
    "    # steps_vectorizer_model = OnlineCountVectorizer(**sklearn_nlp_params)\n",
    "\n",
    "    # Do fit transform on data\n",
    "    # steps_test_tfidf_transform = steps_tfidf_vectorizer_model.fit_transform(tqdm(to_nlp_df[\"steps\"]))\n",
    "    topic_model.update_topics(\n",
    "        recipe_ingreds\n",
    "        , vectorizer_model=steps_vectorizer_model\n",
    "    )\n",
    "\n",
    "    # Display topic model results\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, BERTopic Model Dataframe:', end='\\n')\n",
    "    print(topic_model.get_topic_info())\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, BERTopic Model Representations:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representation'])\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, BERTopic Model Representative Docs:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representative_Docs'])\n",
    "\n",
    "    # Save and log the topic model dataframe\n",
    "    topic_model.get_topic_info().to_json('../data/processed/bertopic_model_ingreds_full_set_df.json')\n",
    "    mlflow.log_artifact('../data/processed/bertopic_model_ingreds_full_set_df.json',\n",
    "                        artifact_path='bertopic_models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [o None and None e None None p None u None r N...\n",
       "1    [None, 3 None None None 2 None None c None u N...\n",
       "2    [for, 1 None None t None a None billion None N...\n",
       "3    [3 None None p None o None u None and None wou...\n",
       "4    [1 None None None None None c None u None p No...\n",
       "Name: Representation, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()['Representation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o None and None e None None p None u None r None c None h None a None s None e None would None None 9 None None None I None and None c None h None None a None and None gram None e None None None None for None o None o None would None None c None a None thousand None e None None 1 None 4 None None t None s None p None None s None a None for None for None r None o None and None None t None h None r None e None a None would None s None None 2 None 3 None None o None z None None would None r None I None e None would None None million None o None r None e None None None None o None r None None p None o None r None c None I None and None I None None million None u None s None h None r None o None o None million None s None None 1 None None p None o None u None and None would None None e None a None c None h None None s None with None e None e None t None None a None and None would None None h None o None t None None I None t None a None None None I None a None and None None s None a None u None s None a None gram None e None None None p None o None r None thousand None None o None r None None t None u None r None thousand None e None y None None 5 None None None None a None r None gram None e None None e None gram None gram None s None None None s None e None p None a None r None a None t None e None would None None None a None t None None r None o None o None million None None t None e None million None p None e None r None a None t None u None r None e None None 3 None 0 None None million None I None and None u None t',\n",
       " 's',\n",
       " 'e',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()['Representation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------\n",
      "2023-12-13 17:55:54.774069, Raw Dataframe: \n",
      "                         id  \\\n",
      "0  54a2b6b019925f464b373351   \n",
      "1  54a408a019925f464b3733bc   \n",
      "2  54a408a26529d92b2c003631   \n",
      "3  54a408a66529d92b2c003638   \n",
      "4  54a408a719925f464b3733cc   \n",
      "\n",
      "                                                 dek  \\\n",
      "0  How does fried chicken achieve No. 1 status? B...   \n",
      "1                                Spinaci all'Ebraica   \n",
      "2  This majestic, moist, and richly spiced honey ...   \n",
      "3  The idea for this sandwich came to me when my ...   \n",
      "4  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                     hed                   pubDate  \\\n",
      "0            Pickle-Brined Fried Chicken  2014-08-19T04:00:00.000Z   \n",
      "1                   Spinach Jewish Style  2008-09-09T04:00:00.000Z   \n",
      "2                  New Year’s Honey Cake  2008-09-10T04:00:00.000Z   \n",
      "3  The B.L.A.Bagel with Lox and Avocado  2008-09-08T04:00:00.000Z   \n",
      "4        Shakshuka a la Doktor Shakshuka  2008-09-09T04:00:00.000Z   \n",
      "\n",
      "                             author    type  \\\n",
      "0                                []  recipe   \n",
      "1  [{'name': 'Edda Servi Machlin'}]  recipe   \n",
      "2       [{'name': 'Marcy Goldman'}]  recipe   \n",
      "3           [{'name': 'Faye Levy'}]  recipe   \n",
      "4         [{'name': 'Joan Nathan'}]  recipe   \n",
      "\n",
      "                                                 url  \\\n",
      "0  /recipes/food/views/pickle-brined-fried-chicke...   \n",
      "1    /recipes/food/views/spinach-jewish-style-350152   \n",
      "2  /recipes/food/views/majestic-and-moist-new-yea...   \n",
      "3  /recipes/food/views/the-b-l-a-bagel-with-lox-a...   \n",
      "4  /recipes/food/views/shakshuka-a-la-doktor-shak...   \n",
      "\n",
      "                                           photoData  \\\n",
      "0  {'id': '54a2b64a6529d92b2c003409', 'filename':...   \n",
      "1  {'id': '56746182accb4c9831e45e0a', 'filename':...   \n",
      "2  {'id': '55e85ba4cf90d6663f728014', 'filename':...   \n",
      "3  {'id': '5674617e47d1a28026045e4f', 'filename':...   \n",
      "4  {'id': '56746183b47c050a284a4e15', 'filename':...   \n",
      "\n",
      "                                                 tag  aggregateRating  \\\n",
      "0  {'category': 'ingredient', 'name': 'Chicken', ...             3.11   \n",
      "1  {'category': 'cuisine', 'name': 'Italian', 'ur...             3.22   \n",
      "2  {'category': 'cuisine', 'name': 'Jewish', 'url...             3.62   \n",
      "3  {'category': 'cuisine', 'name': 'Jewish', 'url...             4.00   \n",
      "4  {'category': 'cuisine', 'name': 'Jewish', 'url...             2.71   \n",
      "\n",
      "                                         ingredients  \\\n",
      "0  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "1  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "2  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "3  [1 small ripe avocado, preferably Hass (see No...   \n",
      "4  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                           prepSteps  reviewsCount  \\\n",
      "0  [Toast mustard and coriander seeds in a dry me...             7   \n",
      "1  [Remove the stems and roots from the spinach. ...             5   \n",
      "2  [I like this cake best baked in a 9-inch angel...           105   \n",
      "3  [A short time before serving, mash avocado and...             7   \n",
      "4  [1. Place the tomatoes, garlic, salt, paprika,...             7   \n",
      "\n",
      "   willMakeAgainPct  dateCrawled  \n",
      "0               100   1498547035  \n",
      "1                80   1498547740  \n",
      "2                88   1498547738  \n",
      "3               100   1498547740  \n",
      "4                83   1498547740  \n",
      "(34756, 15)\n",
      "\n",
      "\n",
      "--------------\n",
      "2023-12-13 17:55:55.191829, Preprocessed Dataframe:\n",
      "                                                                        dek  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  How does fried chicken achieve No. 1 status? B...   \n",
      "54a408a019925f464b3733bc                                Spinaci all'Ebraica   \n",
      "54a408a26529d92b2c003631  This majestic, moist, and richly spiced honey ...   \n",
      "54a408a66529d92b2c003638  The idea for this sandwich came to me when my ...   \n",
      "54a408a719925f464b3733cc  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                                            hed  \\\n",
      "id                                                                \n",
      "54a2b6b019925f464b373351            Pickle-Brined Fried Chicken   \n",
      "54a408a019925f464b3733bc                   Spinach Jewish Style   \n",
      "54a408a26529d92b2c003631                  New Year’s Honey Cake   \n",
      "54a408a66529d92b2c003638  The B.L.A.Bagel with Lox and Avocado   \n",
      "54a408a719925f464b3733cc        Shakshuka a la Doktor Shakshuka   \n",
      "\n",
      "                          aggregateRating  \\\n",
      "id                                          \n",
      "54a2b6b019925f464b373351             3.11   \n",
      "54a408a019925f464b3733bc             3.22   \n",
      "54a408a26529d92b2c003631             3.62   \n",
      "54a408a66529d92b2c003638             4.00   \n",
      "54a408a719925f464b3733cc             2.71   \n",
      "\n",
      "                                                                ingredients  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "54a408a019925f464b3733bc  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "54a408a26529d92b2c003631  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "54a408a66529d92b2c003638  [1 small ripe avocado, preferably Hass (see No...   \n",
      "54a408a719925f464b3733cc  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                                                  prepSteps  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [Toast mustard and coriander seeds in a dry me...   \n",
      "54a408a019925f464b3733bc  [Remove the stems and roots from the spinach. ...   \n",
      "54a408a26529d92b2c003631  [I like this cake best baked in a 9-inch angel...   \n",
      "54a408a66529d92b2c003638  [A short time before serving, mash avocado and...   \n",
      "54a408a719925f464b3733cc  [1. Place the tomatoes, garlic, salt, paprika,...   \n",
      "\n",
      "                          reviewsCount  willMakeAgainPct     cuisine_name  \\\n",
      "id                                                                          \n",
      "54a2b6b019925f464b373351             7               100  Missing Cuisine   \n",
      "54a408a019925f464b3733bc             5                80          Italian   \n",
      "54a408a26529d92b2c003631           105                88           Kosher   \n",
      "54a408a66529d92b2c003638             7               100           Kosher   \n",
      "54a408a719925f464b3733cc             7                83           Kosher   \n",
      "\n",
      "                                               photo_filename  \\\n",
      "id                                                              \n",
      "54a2b6b019925f464b373351       51247610_fried-chicken_1x1.jpg   \n",
      "54a408a019925f464b3733bc  EP_12162015_placeholders_rustic.jpg   \n",
      "54a408a26529d92b2c003631          EP_09022015_honeycake-2.jpg   \n",
      "54a408a66529d92b2c003638  EP_12162015_placeholders_casual.jpg   \n",
      "54a408a719925f464b3733cc  EP_12162015_placeholders_formal.jpg   \n",
      "\n",
      "                                                               photo_credit  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351                Michael Graydon and Nikole Herriott   \n",
      "54a408a019925f464b3733bc  Photo by Chelsea Kyle, Prop Styling by Anna St...   \n",
      "54a408a26529d92b2c003631  Photo by Chelsea Kyle, Food Styling by Anna St...   \n",
      "54a408a66529d92b2c003638  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "54a408a719925f464b3733cc  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "\n",
      "                                  author_name            date_published  \\\n",
      "id                                                                        \n",
      "54a2b6b019925f464b373351  Missing Author Name 2014-08-19 04:00:00+00:00   \n",
      "54a408a019925f464b3733bc   Edda Servi Machlin 2008-09-09 04:00:00+00:00   \n",
      "54a408a26529d92b2c003631        Marcy Goldman 2008-09-10 04:00:00+00:00   \n",
      "54a408a66529d92b2c003638            Faye Levy 2008-09-08 04:00:00+00:00   \n",
      "54a408a719925f464b3733cc          Joan Nathan 2008-09-09 04:00:00+00:00   \n",
      "\n",
      "                                                                 recipe_url  \n",
      "id                                                                           \n",
      "54a2b6b019925f464b373351  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a019925f464b3733bc  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a26529d92b2c003631  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a66529d92b2c003638  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a719925f464b3733cc  https://www.epicurious.com/recipes/food/views/...  \n",
      "(34656, 13)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2023-12-13 17:55:55.223662, Subset Dataframe:\n",
      "                                                                        dek  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  How does fried chicken achieve No. 1 status? B...   \n",
      "54a408a019925f464b3733bc                                Spinaci all'Ebraica   \n",
      "54a408a26529d92b2c003631  This majestic, moist, and richly spiced honey ...   \n",
      "54a408a66529d92b2c003638  The idea for this sandwich came to me when my ...   \n",
      "54a408a719925f464b3733cc  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                                            hed  \\\n",
      "id                                                                \n",
      "54a2b6b019925f464b373351            Pickle-Brined Fried Chicken   \n",
      "54a408a019925f464b3733bc                   Spinach Jewish Style   \n",
      "54a408a26529d92b2c003631                  New Year’s Honey Cake   \n",
      "54a408a66529d92b2c003638  The B.L.A.Bagel with Lox and Avocado   \n",
      "54a408a719925f464b3733cc        Shakshuka a la Doktor Shakshuka   \n",
      "\n",
      "                          aggregateRating  \\\n",
      "id                                          \n",
      "54a2b6b019925f464b373351             3.11   \n",
      "54a408a019925f464b3733bc             3.22   \n",
      "54a408a26529d92b2c003631             3.62   \n",
      "54a408a66529d92b2c003638             4.00   \n",
      "54a408a719925f464b3733cc             2.71   \n",
      "\n",
      "                                                                ingredients  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "54a408a019925f464b3733bc  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "54a408a26529d92b2c003631  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "54a408a66529d92b2c003638  [1 small ripe avocado, preferably Hass (see No...   \n",
      "54a408a719925f464b3733cc  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                                                  prepSteps  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [Toast mustard and coriander seeds in a dry me...   \n",
      "54a408a019925f464b3733bc  [Remove the stems and roots from the spinach. ...   \n",
      "54a408a26529d92b2c003631  [I like this cake best baked in a 9-inch angel...   \n",
      "54a408a66529d92b2c003638  [A short time before serving, mash avocado and...   \n",
      "54a408a719925f464b3733cc  [1. Place the tomatoes, garlic, salt, paprika,...   \n",
      "\n",
      "                          reviewsCount  willMakeAgainPct     cuisine_name  \\\n",
      "id                                                                          \n",
      "54a2b6b019925f464b373351             7               100  Missing Cuisine   \n",
      "54a408a019925f464b3733bc             5                80          Italian   \n",
      "54a408a26529d92b2c003631           105                88           Kosher   \n",
      "54a408a66529d92b2c003638             7               100           Kosher   \n",
      "54a408a719925f464b3733cc             7                83           Kosher   \n",
      "\n",
      "                                               photo_filename  \\\n",
      "id                                                              \n",
      "54a2b6b019925f464b373351       51247610_fried-chicken_1x1.jpg   \n",
      "54a408a019925f464b3733bc  EP_12162015_placeholders_rustic.jpg   \n",
      "54a408a26529d92b2c003631          EP_09022015_honeycake-2.jpg   \n",
      "54a408a66529d92b2c003638  EP_12162015_placeholders_casual.jpg   \n",
      "54a408a719925f464b3733cc  EP_12162015_placeholders_formal.jpg   \n",
      "\n",
      "                                                               photo_credit  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351                Michael Graydon and Nikole Herriott   \n",
      "54a408a019925f464b3733bc  Photo by Chelsea Kyle, Prop Styling by Anna St...   \n",
      "54a408a26529d92b2c003631  Photo by Chelsea Kyle, Food Styling by Anna St...   \n",
      "54a408a66529d92b2c003638  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "54a408a719925f464b3733cc  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "\n",
      "                                  author_name            date_published  \\\n",
      "id                                                                        \n",
      "54a2b6b019925f464b373351  Missing Author Name 2014-08-19 04:00:00+00:00   \n",
      "54a408a019925f464b3733bc   Edda Servi Machlin 2008-09-09 04:00:00+00:00   \n",
      "54a408a26529d92b2c003631        Marcy Goldman 2008-09-10 04:00:00+00:00   \n",
      "54a408a66529d92b2c003638            Faye Levy 2008-09-08 04:00:00+00:00   \n",
      "54a408a719925f464b3733cc          Joan Nathan 2008-09-09 04:00:00+00:00   \n",
      "\n",
      "                                                                 recipe_url  \n",
      "id                                                                           \n",
      "54a2b6b019925f464b373351  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a019925f464b3733bc  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a26529d92b2c003631  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a66529d92b2c003638  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a719925f464b3733cc  https://www.epicurious.com/recipes/food/views/...  \n",
      "(100, 13)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2023-12-13 18:16:48.195360, Recipe ingredients:\n",
      "id\n",
      "54a2b6b019925f464b373351                   1 tablespoons yellow mustard seeds\n",
      "54a408a019925f464b3733bc                 3 pounds small - leaved bulk spinach\n",
      "54a408a26529d92b2c003631                       3 1/2 cups all - purpose flour\n",
      "54a408a66529d92b2c003638    1 small ripe avocado , preferably hass ( see n...\n",
      "54a408a719925f464b3733cc    2 pounds fresh tomatoes , unpeeled and cut in ...\n",
      "                                                  ...                        \n",
      "54a409376529d92b2c003884                 8 cups steaming - hot low - fat milk\n",
      "54a409386529d92b2c00388a                         3 carrots , coarsely chopped\n",
      "54a4093a19925f464b373600    5 large eggs , separated , at room temperature...\n",
      "54a4093b6529d92b2c003894    16 pieces bubblegum , preferably double bubble...\n",
      "54a4093c6529d92b2c003899                  1 1/2 pounds medium shrimp in shell\n",
      "Name: ingredients, Length: 100, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 18:16:51,525 - BERTopic - Reduced dimensionality\n",
      "2023-12-13 18:16:51,537 - BERTopic - Clustered reduced embeddings\n",
      "2023-12-13 18:16:51,549 - BERTopic - Reduced number of topics from 3 to 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2023-12-13 18:16:51.565220, BERTopic Model Dataframe:\n",
      "   Topic  Count                          Name  \\\n",
      "0      0     19        0_12_all_purpose_flour   \n",
      "1      1     52  1_tablespoons_or_dried_about   \n",
      "2      2     29        2_oil_12_cups_nonstick   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [12, all, purpose, flour, cups, pounds, in, 14...   \n",
      "1  [tablespoons, or, dried, about, large, and, di...   \n",
      "2  [oil, 12, cups, nonstick, eggs, spray, vegetab...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [2 1/4 cups all purpose flour, 2 1/2 cups all ...  \n",
      "1  [4 large dried guajillo chiles or dried new me...  \n",
      "2  [nonstick vegetable oil spray, nonstick vegeta...  \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2023-12-13 18:16:51.576763, BERTopic Model Representations:\n",
      "0    [12, all, purpose, flour, cups, pounds, in, 14...\n",
      "1    [tablespoons, or, dried, about, large, and, di...\n",
      "2    [oil, 12, cups, nonstick, eggs, spray, vegetab...\n",
      "Name: Representation, dtype: object\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2023-12-13 18:16:51.585523, BERTopic Model Representative Docs:\n",
      "0    [2 1/4 cups all purpose flour, 2 1/2 cups all ...\n",
      "1    [4 large dried guajillo chiles or dried new me...\n",
      "2    [nonstick vegetable oil spray, nonstick vegeta...\n",
      "Name: Representative_Docs, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# load from MLflow\n",
    "mlflow_client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow')\n",
    "\n",
    "# cv_params are parameters for the sklearn CountVectorizer or TFIDFVectorizer\n",
    "sklearn_nlp_params = {\n",
    "    'strip_accents':\"unicode\",\n",
    "    'lowercase':True,\n",
    "    'analyzer': StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4),\n",
    "    'min_df':10,\n",
    "}\n",
    "\n",
    "# create sklearn pipeline as in BERTopic lightweight configuration\n",
    "# pipe = make_pipeline(\n",
    "#     TfidfVectorizer(**sklearn_nlp_params),\n",
    "#     TruncatedSVD(100)\n",
    "# )\n",
    "\n",
    "# bertopic_params are a superset of cv_params\n",
    "bertopic_params = {\n",
    "    # 'embedding_model': TfidfVectorizer(**sklearn_nlp_params),\n",
    "    'top_n_words':20,\n",
    "    'min_topic_size':10,\n",
    "    'nr_topics':50,\n",
    "    'verbose':True,\n",
    "    'low_memory':True,\n",
    "    'calculate_probabilities':True,\n",
    "    # 'min_cluster_size': 10 # Possibly only works if modifying individual HDBSCAN component of BERTopic\n",
    "}\n",
    "\n",
    "# update bertopic_params to include cv_params\n",
    "# bertopic_params.update(cv_params)\n",
    "\n",
    "# pipeline_params are parameters that will be logged in MLFlow and are a superset of library parameters\n",
    "pipeline_params = {\n",
    "    'stanza_model': 'en',\n",
    "    'sklearn-transformer': 'TfidfVectorizer'\n",
    "}\n",
    "\n",
    "# update the pipeline parameters with the library-specific ones so that they show up in MLflow Tracking\n",
    "pipeline_params.update(sklearn_nlp_params)\n",
    "pipeline_params.update(bertopic_params)\n",
    "\n",
    "with mlflow.start_run(experiment_id=get_experiment_id(f\"{DAGSHUB_EMAIL}/bertopic_lightweight_stanza_ingreds_small_set_v1\")):    \n",
    "    # LOG PARAMETERS\n",
    "    mlflow.log_params(pipeline_params)\n",
    "\n",
    "    # LOG INPUTS (QUERIES) AND OUTPUTS\n",
    "    # MLflow example uses a list of strings or a list of str->str dicts\n",
    "    \n",
    "    # load raw data and preprocess/clean\n",
    "    data = dvc.api.read(\n",
    "           path='../data/recipes-en-201706/epicurious-recipes_m2.json'\n",
    "           , mode='r')\n",
    "    raw_df = pd.read_json(data)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print(f'{datetime.now()}, Raw Dataframe: ', end='\\n')\n",
    "    print(raw_df.head())\n",
    "    print(raw_df.shape)\n",
    "\n",
    "    # pre_proc_df is cleaned dataframe\n",
    "    pre_proc_df = dfpp.preprocess_dataframe(raw_df)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print(f'{datetime.now()}, Preprocessed Dataframe:', end='\\n')\n",
    "    print(pre_proc_df.head())\n",
    "    print(pre_proc_df.shape)\n",
    "\n",
    "\n",
    "    # pre_proc_df = pd.read_json(\n",
    "    #     mlflow.artifacts.download_artifacts(\n",
    "    #         run_id=mlflow_run_id,\n",
    "    #         artifact_path='artifacts/preprocessed_dataframes/preprocessed_dataframe.json',\n",
    "    #         # tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow'\n",
    "    #     )\n",
    "    # )\n",
    "    # print('\\n')\n",
    "    # print('-' * 80)\n",
    "    # print('Preprocessed Dataframe:', end='\\n')\n",
    "    # print(pre_proc_df.head())\n",
    "    # print(pre_proc_df.shape)\n",
    "\n",
    "    # create subset for dev purposes\n",
    "    to_nlp_df = pre_proc_df[0:100]\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, Subset Dataframe:', end='\\n')\n",
    "    print(to_nlp_df.head())\n",
    "    print(to_nlp_df.shape)\n",
    "\n",
    "    # LOG MODEL\n",
    "    # Instantiate BERTopic\n",
    "    topic_model = BERTopic(\n",
    "        **bertopic_params\n",
    "    )\n",
    "    \n",
    "    analyzer_kwargs = {'stanza_pipeline': nlp\n",
    "                       , 'minNgramLength': 1\n",
    "                       , 'maxNgramLength': 4}\n",
    "    \n",
    "    recipe_ingreds = to_nlp_df[\"ingredients\"].apply(custom_analyzer, **analyzer_kwargs)\n",
    "\n",
    "    # Create TF-IDF embeddings\n",
    "    vectorizer = TfidfVectorizer(**sklearn_nlp_params)\n",
    "    embeddings = vectorizer.fit_transform(recipe_ingreds)\n",
    "\n",
    "    # recipe_steps = \"\".join(str(to_nlp_df[\"prepSteps\"].apply(StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4))))\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, Recipe ingredients:', end='\\n')\n",
    "    print(recipe_ingreds)\n",
    "\n",
    "    # train on the recipes' ingredientss\n",
    "    topics, probs = topic_model.fit_transform(recipe_ingreds, embeddings)\n",
    "\n",
    "    # since this uses a custom Stanza analyzer, we have to use a custom mlflow.Pyfunc.PythonModel\n",
    "    # Instantiate sklearn CountVectorizer\n",
    "    sklearn_cv_params = {\n",
    "        'strip_accents':\"unicode\",\n",
    "        'lowercase':True,\n",
    "        # 'analyzer': StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4),\n",
    "        # 'min_df':10,\n",
    "    }\n",
    "    steps_vectorizer_model = CountVectorizer(**sklearn_cv_params)\n",
    "\n",
    "    # May need to use BERTopic's OnlineCountVectorizer\n",
    "    # steps_vectorizer_model = OnlineCountVectorizer(**sklearn_nlp_params)\n",
    "\n",
    "    # Do fit transform on data\n",
    "    # steps_test_tfidf_transform = steps_tfidf_vectorizer_model.fit_transform(tqdm(to_nlp_df[\"steps\"]))\n",
    "    topic_model.update_topics(\n",
    "        recipe_ingreds\n",
    "        , vectorizer_model=steps_vectorizer_model\n",
    "    )\n",
    "\n",
    "    # Display topic model results\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, BERTopic Model Dataframe:', end='\\n')\n",
    "    print(topic_model.get_topic_info())\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, BERTopic Model Representations:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representation'])\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, BERTopic Model Representative Docs:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representative_Docs'])\n",
    "\n",
    "    # Save and log the topic model dataframe\n",
    "    topic_model.get_topic_info().to_json('../data/processed/bertopic_model_ingreds_full_set_df.json')\n",
    "    mlflow.log_artifact('../data/processed/bertopic_model_ingreds_full_set_df.json',\n",
    "                        artifact_path='bertopic_models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------\n",
      "2023-12-13 22:25:51.013932, Raw Dataframe: \n",
      "                         id  \\\n",
      "0  54a2b6b019925f464b373351   \n",
      "1  54a408a019925f464b3733bc   \n",
      "2  54a408a26529d92b2c003631   \n",
      "3  54a408a66529d92b2c003638   \n",
      "4  54a408a719925f464b3733cc   \n",
      "\n",
      "                                                 dek  \\\n",
      "0  How does fried chicken achieve No. 1 status? B...   \n",
      "1                                Spinaci all'Ebraica   \n",
      "2  This majestic, moist, and richly spiced honey ...   \n",
      "3  The idea for this sandwich came to me when my ...   \n",
      "4  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                     hed                   pubDate  \\\n",
      "0            Pickle-Brined Fried Chicken  2014-08-19T04:00:00.000Z   \n",
      "1                   Spinach Jewish Style  2008-09-09T04:00:00.000Z   \n",
      "2                  New Year’s Honey Cake  2008-09-10T04:00:00.000Z   \n",
      "3  The B.L.A.Bagel with Lox and Avocado  2008-09-08T04:00:00.000Z   \n",
      "4        Shakshuka a la Doktor Shakshuka  2008-09-09T04:00:00.000Z   \n",
      "\n",
      "                             author    type  \\\n",
      "0                                []  recipe   \n",
      "1  [{'name': 'Edda Servi Machlin'}]  recipe   \n",
      "2       [{'name': 'Marcy Goldman'}]  recipe   \n",
      "3           [{'name': 'Faye Levy'}]  recipe   \n",
      "4         [{'name': 'Joan Nathan'}]  recipe   \n",
      "\n",
      "                                                 url  \\\n",
      "0  /recipes/food/views/pickle-brined-fried-chicke...   \n",
      "1    /recipes/food/views/spinach-jewish-style-350152   \n",
      "2  /recipes/food/views/majestic-and-moist-new-yea...   \n",
      "3  /recipes/food/views/the-b-l-a-bagel-with-lox-a...   \n",
      "4  /recipes/food/views/shakshuka-a-la-doktor-shak...   \n",
      "\n",
      "                                           photoData  \\\n",
      "0  {'id': '54a2b64a6529d92b2c003409', 'filename':...   \n",
      "1  {'id': '56746182accb4c9831e45e0a', 'filename':...   \n",
      "2  {'id': '55e85ba4cf90d6663f728014', 'filename':...   \n",
      "3  {'id': '5674617e47d1a28026045e4f', 'filename':...   \n",
      "4  {'id': '56746183b47c050a284a4e15', 'filename':...   \n",
      "\n",
      "                                                 tag  aggregateRating  \\\n",
      "0  {'category': 'ingredient', 'name': 'Chicken', ...             3.11   \n",
      "1  {'category': 'cuisine', 'name': 'Italian', 'ur...             3.22   \n",
      "2  {'category': 'cuisine', 'name': 'Jewish', 'url...             3.62   \n",
      "3  {'category': 'cuisine', 'name': 'Jewish', 'url...             4.00   \n",
      "4  {'category': 'cuisine', 'name': 'Jewish', 'url...             2.71   \n",
      "\n",
      "                                         ingredients  \\\n",
      "0  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "1  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "2  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "3  [1 small ripe avocado, preferably Hass (see No...   \n",
      "4  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                           prepSteps  reviewsCount  \\\n",
      "0  [Toast mustard and coriander seeds in a dry me...             7   \n",
      "1  [Remove the stems and roots from the spinach. ...             5   \n",
      "2  [I like this cake best baked in a 9-inch angel...           105   \n",
      "3  [A short time before serving, mash avocado and...             7   \n",
      "4  [1. Place the tomatoes, garlic, salt, paprika,...             7   \n",
      "\n",
      "   willMakeAgainPct  dateCrawled  \n",
      "0               100   1498547035  \n",
      "1                80   1498547740  \n",
      "2                88   1498547738  \n",
      "3               100   1498547740  \n",
      "4                83   1498547740  \n",
      "(34756, 15)\n",
      "\n",
      "\n",
      "--------------\n",
      "2023-12-13 22:25:51.349240, Preprocessed Dataframe:\n",
      "                                                                        dek  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  How does fried chicken achieve No. 1 status? B...   \n",
      "54a408a019925f464b3733bc                                Spinaci all'Ebraica   \n",
      "54a408a26529d92b2c003631  This majestic, moist, and richly spiced honey ...   \n",
      "54a408a66529d92b2c003638  The idea for this sandwich came to me when my ...   \n",
      "54a408a719925f464b3733cc  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                                            hed  \\\n",
      "id                                                                \n",
      "54a2b6b019925f464b373351            Pickle-Brined Fried Chicken   \n",
      "54a408a019925f464b3733bc                   Spinach Jewish Style   \n",
      "54a408a26529d92b2c003631                  New Year’s Honey Cake   \n",
      "54a408a66529d92b2c003638  The B.L.A.Bagel with Lox and Avocado   \n",
      "54a408a719925f464b3733cc        Shakshuka a la Doktor Shakshuka   \n",
      "\n",
      "                          aggregateRating  \\\n",
      "id                                          \n",
      "54a2b6b019925f464b373351             3.11   \n",
      "54a408a019925f464b3733bc             3.22   \n",
      "54a408a26529d92b2c003631             3.62   \n",
      "54a408a66529d92b2c003638             4.00   \n",
      "54a408a719925f464b3733cc             2.71   \n",
      "\n",
      "                                                                ingredients  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "54a408a019925f464b3733bc  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "54a408a26529d92b2c003631  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "54a408a66529d92b2c003638  [1 small ripe avocado, preferably Hass (see No...   \n",
      "54a408a719925f464b3733cc  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                                                  prepSteps  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [Toast mustard and coriander seeds in a dry me...   \n",
      "54a408a019925f464b3733bc  [Remove the stems and roots from the spinach. ...   \n",
      "54a408a26529d92b2c003631  [I like this cake best baked in a 9-inch angel...   \n",
      "54a408a66529d92b2c003638  [A short time before serving, mash avocado and...   \n",
      "54a408a719925f464b3733cc  [1. Place the tomatoes, garlic, salt, paprika,...   \n",
      "\n",
      "                          reviewsCount  willMakeAgainPct     cuisine_name  \\\n",
      "id                                                                          \n",
      "54a2b6b019925f464b373351             7               100  Missing Cuisine   \n",
      "54a408a019925f464b3733bc             5                80          Italian   \n",
      "54a408a26529d92b2c003631           105                88           Kosher   \n",
      "54a408a66529d92b2c003638             7               100           Kosher   \n",
      "54a408a719925f464b3733cc             7                83           Kosher   \n",
      "\n",
      "                                               photo_filename  \\\n",
      "id                                                              \n",
      "54a2b6b019925f464b373351       51247610_fried-chicken_1x1.jpg   \n",
      "54a408a019925f464b3733bc  EP_12162015_placeholders_rustic.jpg   \n",
      "54a408a26529d92b2c003631          EP_09022015_honeycake-2.jpg   \n",
      "54a408a66529d92b2c003638  EP_12162015_placeholders_casual.jpg   \n",
      "54a408a719925f464b3733cc  EP_12162015_placeholders_formal.jpg   \n",
      "\n",
      "                                                               photo_credit  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351                Michael Graydon and Nikole Herriott   \n",
      "54a408a019925f464b3733bc  Photo by Chelsea Kyle, Prop Styling by Anna St...   \n",
      "54a408a26529d92b2c003631  Photo by Chelsea Kyle, Food Styling by Anna St...   \n",
      "54a408a66529d92b2c003638  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "54a408a719925f464b3733cc  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "\n",
      "                                  author_name            date_published  \\\n",
      "id                                                                        \n",
      "54a2b6b019925f464b373351  Missing Author Name 2014-08-19 04:00:00+00:00   \n",
      "54a408a019925f464b3733bc   Edda Servi Machlin 2008-09-09 04:00:00+00:00   \n",
      "54a408a26529d92b2c003631        Marcy Goldman 2008-09-10 04:00:00+00:00   \n",
      "54a408a66529d92b2c003638            Faye Levy 2008-09-08 04:00:00+00:00   \n",
      "54a408a719925f464b3733cc          Joan Nathan 2008-09-09 04:00:00+00:00   \n",
      "\n",
      "                                                                 recipe_url  \n",
      "id                                                                           \n",
      "54a2b6b019925f464b373351  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a019925f464b3733bc  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a26529d92b2c003631  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a66529d92b2c003638  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a719925f464b3733cc  https://www.epicurious.com/recipes/food/views/...  \n",
      "(34656, 13)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2023-12-13 22:25:51.368423, Subset Dataframe:\n",
      "                                                                        dek  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  How does fried chicken achieve No. 1 status? B...   \n",
      "54a408a019925f464b3733bc                                Spinaci all'Ebraica   \n",
      "54a408a26529d92b2c003631  This majestic, moist, and richly spiced honey ...   \n",
      "54a408a66529d92b2c003638  The idea for this sandwich came to me when my ...   \n",
      "54a408a719925f464b3733cc  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                                            hed  \\\n",
      "id                                                                \n",
      "54a2b6b019925f464b373351            Pickle-Brined Fried Chicken   \n",
      "54a408a019925f464b3733bc                   Spinach Jewish Style   \n",
      "54a408a26529d92b2c003631                  New Year’s Honey Cake   \n",
      "54a408a66529d92b2c003638  The B.L.A.Bagel with Lox and Avocado   \n",
      "54a408a719925f464b3733cc        Shakshuka a la Doktor Shakshuka   \n",
      "\n",
      "                          aggregateRating  \\\n",
      "id                                          \n",
      "54a2b6b019925f464b373351             3.11   \n",
      "54a408a019925f464b3733bc             3.22   \n",
      "54a408a26529d92b2c003631             3.62   \n",
      "54a408a66529d92b2c003638             4.00   \n",
      "54a408a719925f464b3733cc             2.71   \n",
      "\n",
      "                                                                ingredients  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "54a408a019925f464b3733bc  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "54a408a26529d92b2c003631  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "54a408a66529d92b2c003638  [1 small ripe avocado, preferably Hass (see No...   \n",
      "54a408a719925f464b3733cc  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                                                  prepSteps  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [Toast mustard and coriander seeds in a dry me...   \n",
      "54a408a019925f464b3733bc  [Remove the stems and roots from the spinach. ...   \n",
      "54a408a26529d92b2c003631  [I like this cake best baked in a 9-inch angel...   \n",
      "54a408a66529d92b2c003638  [A short time before serving, mash avocado and...   \n",
      "54a408a719925f464b3733cc  [1. Place the tomatoes, garlic, salt, paprika,...   \n",
      "\n",
      "                          reviewsCount  willMakeAgainPct     cuisine_name  \\\n",
      "id                                                                          \n",
      "54a2b6b019925f464b373351             7               100  Missing Cuisine   \n",
      "54a408a019925f464b3733bc             5                80          Italian   \n",
      "54a408a26529d92b2c003631           105                88           Kosher   \n",
      "54a408a66529d92b2c003638             7               100           Kosher   \n",
      "54a408a719925f464b3733cc             7                83           Kosher   \n",
      "\n",
      "                                               photo_filename  \\\n",
      "id                                                              \n",
      "54a2b6b019925f464b373351       51247610_fried-chicken_1x1.jpg   \n",
      "54a408a019925f464b3733bc  EP_12162015_placeholders_rustic.jpg   \n",
      "54a408a26529d92b2c003631          EP_09022015_honeycake-2.jpg   \n",
      "54a408a66529d92b2c003638  EP_12162015_placeholders_casual.jpg   \n",
      "54a408a719925f464b3733cc  EP_12162015_placeholders_formal.jpg   \n",
      "\n",
      "                                                               photo_credit  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351                Michael Graydon and Nikole Herriott   \n",
      "54a408a019925f464b3733bc  Photo by Chelsea Kyle, Prop Styling by Anna St...   \n",
      "54a408a26529d92b2c003631  Photo by Chelsea Kyle, Food Styling by Anna St...   \n",
      "54a408a66529d92b2c003638  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "54a408a719925f464b3733cc  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "\n",
      "                                  author_name            date_published  \\\n",
      "id                                                                        \n",
      "54a2b6b019925f464b373351  Missing Author Name 2014-08-19 04:00:00+00:00   \n",
      "54a408a019925f464b3733bc   Edda Servi Machlin 2008-09-09 04:00:00+00:00   \n",
      "54a408a26529d92b2c003631        Marcy Goldman 2008-09-10 04:00:00+00:00   \n",
      "54a408a66529d92b2c003638            Faye Levy 2008-09-08 04:00:00+00:00   \n",
      "54a408a719925f464b3733cc          Joan Nathan 2008-09-09 04:00:00+00:00   \n",
      "\n",
      "                                                                 recipe_url  \n",
      "id                                                                           \n",
      "54a2b6b019925f464b373351  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a019925f464b3733bc  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a26529d92b2c003631  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a66529d92b2c003638  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a719925f464b3733cc  https://www.epicurious.com/recipes/food/views/...  \n",
      "(100, 13)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2023-12-13 22:37:43.872777, Recipe ingredients:\n",
      "id\n",
      "54a2b6b019925f464b373351                   1 tablespoons yellow mustard seeds\n",
      "54a408a019925f464b3733bc                 3 pounds small - leaved bulk spinach\n",
      "54a408a26529d92b2c003631                       3 1/2 cups all - purpose flour\n",
      "54a408a66529d92b2c003638    1 small ripe avocado , preferably hass ( see n...\n",
      "54a408a719925f464b3733cc    2 pounds fresh tomatoes , unpeeled and cut in ...\n",
      "                                                  ...                        \n",
      "54a409376529d92b2c003884                 8 cups steaming - hot low - fat milk\n",
      "54a409386529d92b2c00388a                         3 carrots , coarsely chopped\n",
      "54a4093a19925f464b373600    5 large eggs , separated , at room temperature...\n",
      "54a4093b6529d92b2c003894    16 pieces bubblegum , preferably double bubble...\n",
      "54a4093c6529d92b2c003899                  1 1/2 pounds medium shrimp in shell\n",
      "Name: ingredients, Length: 100, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 22:37:46,398 - BERTopic - Reduced dimensionality\n",
      "2023-12-13 22:37:46,404 - BERTopic - Clustered reduced embeddings\n",
      "2023-12-13 22:37:46,413 - BERTopic - Reduced number of topics from 4 to 4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=125'>126</a>\u001b[0m steps_vectorizer_model \u001b[39m=\u001b[39m CountVectorizer(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39msklearn_cv_params)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=127'>128</a>\u001b[0m \u001b[39m# May need to use BERTopic's OnlineCountVectorizer\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39m# steps_vectorizer_model = OnlineCountVectorizer(**sklearn_nlp_params)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=129'>130</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39m# Do fit transform on data\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=131'>132</a>\u001b[0m \u001b[39m# steps_test_tfidf_transform = steps_tfidf_vectorizer_model.fit_transform(tqdm(to_nlp_df[\"steps\"]))\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=132'>133</a>\u001b[0m topic_model\u001b[39m.\u001b[39;49mupdate_topics(\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=133'>134</a>\u001b[0m     recipe_ingreds\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=134'>135</a>\u001b[0m     , vectorizer_model\u001b[39m=\u001b[39;49msteps_vectorizer_model\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=135'>136</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39m# Display topic model results\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/nbs/10_bertopic_stanza_mlflow_testing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=138'>139</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mealeon-uA1PI5_p-py3.10/lib/python3.10/site-packages/bertopic/_bertopic.py:1386\u001b[0m, in \u001b[0;36mBERTopic.update_topics\u001b[0;34m(self, docs, images, topics, top_n_words, n_gram_range, vectorizer_model, ctfidf_model, representation_model)\u001b[0m\n\u001b[1;32m   1384\u001b[0m documents \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m\"\u001b[39m\u001b[39mDocument\u001b[39m\u001b[39m\"\u001b[39m: docs, \u001b[39m\"\u001b[39m\u001b[39mTopic\u001b[39m\u001b[39m\"\u001b[39m: topics, \u001b[39m\"\u001b[39m\u001b[39mID\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(docs)), \u001b[39m\"\u001b[39m\u001b[39mImage\u001b[39m\u001b[39m\"\u001b[39m: images})\n\u001b[1;32m   1385\u001b[0m documents_per_topic \u001b[39m=\u001b[39m documents\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mTopic\u001b[39m\u001b[39m'\u001b[39m], as_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39magg({\u001b[39m'\u001b[39m\u001b[39mDocument\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin})\n\u001b[0;32m-> 1386\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_tf_idf_, words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_tf_idf(documents_per_topic)\n\u001b[1;32m   1387\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtopic_representations_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extract_words_per_topic(words, documents)\n\u001b[1;32m   1388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(topics) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtopics_:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mealeon-uA1PI5_p-py3.10/lib/python3.10/site-packages/bertopic/_bertopic.py:3488\u001b[0m, in \u001b[0;36mBERTopic._c_tf_idf\u001b[0;34m(self, documents_per_topic, fit, partial_fit)\u001b[0m\n\u001b[1;32m   3486\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorizer_model\u001b[39m.\u001b[39mpartial_fit(documents)\u001b[39m.\u001b[39mupdate_bow(documents)\n\u001b[1;32m   3487\u001b[0m \u001b[39melif\u001b[39;00m fit:\n\u001b[0;32m-> 3488\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectorizer_model\u001b[39m.\u001b[39;49mfit(documents)\n\u001b[1;32m   3489\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorizer_model\u001b[39m.\u001b[39mtransform(documents)\n\u001b[1;32m   3490\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mealeon-uA1PI5_p-py3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1340\u001b[0m, in \u001b[0;36mCountVectorizer.fit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, raw_documents, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1325\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Learn a vocabulary dictionary of all tokens in the raw documents.\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \n\u001b[1;32m   1327\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[39m        Fitted vectorizer.\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[1;32m   1341\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mealeon-uA1PI5_p-py3.10/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mealeon-uA1PI5_p-py3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1389\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1381\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1386\u001b[0m             )\n\u001b[1;32m   1387\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[1;32m   1391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[1;32m   1392\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mealeon-uA1PI5_p-py3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1295\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     vocabulary \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(vocabulary)\n\u001b[1;32m   1294\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m vocabulary:\n\u001b[0;32m-> 1295\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1296\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1297\u001b[0m         )\n\u001b[1;32m   1299\u001b[0m \u001b[39mif\u001b[39;00m indptr[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax:  \u001b[39m# = 2**31 - 1\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m     \u001b[39mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "# load from MLflow\n",
    "mlflow_client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow')\n",
    "\n",
    "# cv_params are parameters for the sklearn CountVectorizer or TFIDFVectorizer\n",
    "sklearn_nlp_params = {\n",
    "    'strip_accents':\"unicode\",\n",
    "    'lowercase':True,\n",
    "    'analyzer': StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4),\n",
    "    'min_df':10,\n",
    "}\n",
    "\n",
    "# create sklearn pipeline as in BERTopic lightweight configuration\n",
    "# pipe = make_pipeline(\n",
    "#     TfidfVectorizer(**sklearn_nlp_params),\n",
    "#     TruncatedSVD(100)\n",
    "# )\n",
    "\n",
    "# bertopic_params are a superset of cv_params\n",
    "bertopic_params = {\n",
    "    # 'embedding_model': TfidfVectorizer(**sklearn_nlp_params),\n",
    "    'top_n_words':20,\n",
    "    'min_topic_size':10,\n",
    "    'nr_topics':50,\n",
    "    'verbose':True,\n",
    "    'low_memory':True,\n",
    "    'calculate_probabilities':True,\n",
    "    # 'min_cluster_size': 10 # Possibly only works if modifying individual HDBSCAN component of BERTopic\n",
    "}\n",
    "\n",
    "# update bertopic_params to include cv_params\n",
    "# bertopic_params.update(cv_params)\n",
    "\n",
    "# pipeline_params are parameters that will be logged in MLFlow and are a superset of library parameters\n",
    "pipeline_params = {\n",
    "    'stanza_model': 'en',\n",
    "    'sklearn-transformer': 'TfidfVectorizer'\n",
    "}\n",
    "\n",
    "# update the pipeline parameters with the library-specific ones so that they show up in MLflow Tracking\n",
    "pipeline_params.update(sklearn_nlp_params)\n",
    "pipeline_params.update(bertopic_params)\n",
    "\n",
    "with mlflow.start_run(experiment_id=get_experiment_id(f\"{DAGSHUB_EMAIL}/bertopic_lightweight_stanza_ingreds_small_set_v1.01\")):    \n",
    "    # LOG PARAMETERS\n",
    "    mlflow.log_params(pipeline_params)\n",
    "\n",
    "    # LOG INPUTS (QUERIES) AND OUTPUTS\n",
    "    # MLflow example uses a list of strings or a list of str->str dicts\n",
    "    \n",
    "    # load raw data and preprocess/clean\n",
    "    data = dvc.api.read(\n",
    "           path='../data/recipes-en-201706/epicurious-recipes_m2.json'\n",
    "           , mode='r')\n",
    "    raw_df = pd.read_json(data)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print(f'{datetime.now()}, Raw Dataframe: ', end='\\n')\n",
    "    print(raw_df.head())\n",
    "    print(raw_df.shape)\n",
    "\n",
    "    # pre_proc_df is cleaned dataframe\n",
    "    pre_proc_df = dfpp.preprocess_dataframe(raw_df)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print(f'{datetime.now()}, Preprocessed Dataframe:', end='\\n')\n",
    "    print(pre_proc_df.head())\n",
    "    print(pre_proc_df.shape)\n",
    "\n",
    "\n",
    "    # pre_proc_df = pd.read_json(\n",
    "    #     mlflow.artifacts.download_artifacts(\n",
    "    #         run_id=mlflow_run_id,\n",
    "    #         artifact_path='artifacts/preprocessed_dataframes/preprocessed_dataframe.json',\n",
    "    #         # tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow'\n",
    "    #     )\n",
    "    # )\n",
    "    # print('\\n')\n",
    "    # print('-' * 80)\n",
    "    # print('Preprocessed Dataframe:', end='\\n')\n",
    "    # print(pre_proc_df.head())\n",
    "    # print(pre_proc_df.shape)\n",
    "\n",
    "    # create subset for dev purposes\n",
    "    to_nlp_df = pre_proc_df[0:100]\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, Subset Dataframe:', end='\\n')\n",
    "    print(to_nlp_df.head())\n",
    "    print(to_nlp_df.shape)\n",
    "\n",
    "    # LOG MODEL\n",
    "    # Instantiate BERTopic\n",
    "    topic_model = BERTopic(\n",
    "        **bertopic_params\n",
    "    )\n",
    "    \n",
    "    analyzer_kwargs = {'stanza_pipeline': nlp\n",
    "                       , 'minNgramLength': 1\n",
    "                       , 'maxNgramLength': 4}\n",
    "    \n",
    "    recipe_ingreds = to_nlp_df[\"ingredients\"].apply(custom_analyzer, **analyzer_kwargs)\n",
    "\n",
    "    # Create TF-IDF embeddings\n",
    "    vectorizer = TfidfVectorizer(**sklearn_nlp_params)\n",
    "    embeddings = vectorizer.fit_transform(recipe_ingreds)\n",
    "\n",
    "    # recipe_steps = \"\".join(str(to_nlp_df[\"prepSteps\"].apply(StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4))))\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, Recipe ingredients:', end='\\n')\n",
    "    print(recipe_ingreds)\n",
    "\n",
    "    # train on the recipes' ingredientss\n",
    "    topics, probs = topic_model.fit_transform(recipe_ingreds, embeddings)\n",
    "\n",
    "    # since this uses a custom Stanza analyzer, we have to use a custom mlflow.Pyfunc.PythonModel\n",
    "    # Instantiate sklearn CountVectorizer\n",
    "    sklearn_cv_params = {\n",
    "        'strip_accents':\"unicode\",\n",
    "        'lowercase':True,\n",
    "        # 'analyzer': StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4),\n",
    "        # 'min_df':10,\n",
    "        # 'token_pattern': \"(?u)\\b[a-zA-Z]{2,}\\b\"\n",
    "    }\n",
    "    steps_vectorizer_model = CountVectorizer(**sklearn_cv_params)\n",
    "\n",
    "    # May need to use BERTopic's OnlineCountVectorizer\n",
    "    # steps_vectorizer_model = OnlineCountVectorizer(**sklearn_nlp_params)\n",
    "\n",
    "    # Do fit transform on data\n",
    "    # steps_test_tfidf_transform = steps_tfidf_vectorizer_model.fit_transform(tqdm(to_nlp_df[\"steps\"]))\n",
    "    topic_model.update_topics(\n",
    "        recipe_ingreds\n",
    "        , vectorizer_model=steps_vectorizer_model\n",
    "    )\n",
    "\n",
    "    # Display topic model results\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, BERTopic Model Dataframe:', end='\\n')\n",
    "    print(topic_model.get_topic_info())\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, BERTopic Model Representations:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representation'])\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, BERTopic Model Representative Docs:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representative_Docs'])\n",
    "\n",
    "    # Save and log the topic model dataframe\n",
    "    topic_model.get_topic_info().to_json('../data/processed/bertopic_model_ingreds_full_set_df.json')\n",
    "    mlflow.log_artifact('../data/processed/bertopic_model_ingreds_full_set_df.json',\n",
    "                        artifact_path='bertopic_models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------\n",
      "2023-12-13 22:45:20.202117, Raw Dataframe: \n",
      "                         id  \\\n",
      "0  54a2b6b019925f464b373351   \n",
      "1  54a408a019925f464b3733bc   \n",
      "2  54a408a26529d92b2c003631   \n",
      "3  54a408a66529d92b2c003638   \n",
      "4  54a408a719925f464b3733cc   \n",
      "\n",
      "                                                 dek  \\\n",
      "0  How does fried chicken achieve No. 1 status? B...   \n",
      "1                                Spinaci all'Ebraica   \n",
      "2  This majestic, moist, and richly spiced honey ...   \n",
      "3  The idea for this sandwich came to me when my ...   \n",
      "4  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                     hed                   pubDate  \\\n",
      "0            Pickle-Brined Fried Chicken  2014-08-19T04:00:00.000Z   \n",
      "1                   Spinach Jewish Style  2008-09-09T04:00:00.000Z   \n",
      "2                  New Year’s Honey Cake  2008-09-10T04:00:00.000Z   \n",
      "3  The B.L.A.Bagel with Lox and Avocado  2008-09-08T04:00:00.000Z   \n",
      "4        Shakshuka a la Doktor Shakshuka  2008-09-09T04:00:00.000Z   \n",
      "\n",
      "                             author    type  \\\n",
      "0                                []  recipe   \n",
      "1  [{'name': 'Edda Servi Machlin'}]  recipe   \n",
      "2       [{'name': 'Marcy Goldman'}]  recipe   \n",
      "3           [{'name': 'Faye Levy'}]  recipe   \n",
      "4         [{'name': 'Joan Nathan'}]  recipe   \n",
      "\n",
      "                                                 url  \\\n",
      "0  /recipes/food/views/pickle-brined-fried-chicke...   \n",
      "1    /recipes/food/views/spinach-jewish-style-350152   \n",
      "2  /recipes/food/views/majestic-and-moist-new-yea...   \n",
      "3  /recipes/food/views/the-b-l-a-bagel-with-lox-a...   \n",
      "4  /recipes/food/views/shakshuka-a-la-doktor-shak...   \n",
      "\n",
      "                                           photoData  \\\n",
      "0  {'id': '54a2b64a6529d92b2c003409', 'filename':...   \n",
      "1  {'id': '56746182accb4c9831e45e0a', 'filename':...   \n",
      "2  {'id': '55e85ba4cf90d6663f728014', 'filename':...   \n",
      "3  {'id': '5674617e47d1a28026045e4f', 'filename':...   \n",
      "4  {'id': '56746183b47c050a284a4e15', 'filename':...   \n",
      "\n",
      "                                                 tag  aggregateRating  \\\n",
      "0  {'category': 'ingredient', 'name': 'Chicken', ...             3.11   \n",
      "1  {'category': 'cuisine', 'name': 'Italian', 'ur...             3.22   \n",
      "2  {'category': 'cuisine', 'name': 'Jewish', 'url...             3.62   \n",
      "3  {'category': 'cuisine', 'name': 'Jewish', 'url...             4.00   \n",
      "4  {'category': 'cuisine', 'name': 'Jewish', 'url...             2.71   \n",
      "\n",
      "                                         ingredients  \\\n",
      "0  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "1  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "2  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "3  [1 small ripe avocado, preferably Hass (see No...   \n",
      "4  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                           prepSteps  reviewsCount  \\\n",
      "0  [Toast mustard and coriander seeds in a dry me...             7   \n",
      "1  [Remove the stems and roots from the spinach. ...             5   \n",
      "2  [I like this cake best baked in a 9-inch angel...           105   \n",
      "3  [A short time before serving, mash avocado and...             7   \n",
      "4  [1. Place the tomatoes, garlic, salt, paprika,...             7   \n",
      "\n",
      "   willMakeAgainPct  dateCrawled  \n",
      "0               100   1498547035  \n",
      "1                80   1498547740  \n",
      "2                88   1498547738  \n",
      "3               100   1498547740  \n",
      "4                83   1498547740  \n",
      "(34756, 15)\n",
      "\n",
      "\n",
      "--------------\n",
      "2023-12-13 22:45:20.571950, Preprocessed Dataframe:\n",
      "                                                                        dek  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  How does fried chicken achieve No. 1 status? B...   \n",
      "54a408a019925f464b3733bc                                Spinaci all'Ebraica   \n",
      "54a408a26529d92b2c003631  This majestic, moist, and richly spiced honey ...   \n",
      "54a408a66529d92b2c003638  The idea for this sandwich came to me when my ...   \n",
      "54a408a719925f464b3733cc  In 1930, Simon Agranat, the chief justice of t...   \n",
      "\n",
      "                                                            hed  \\\n",
      "id                                                                \n",
      "54a2b6b019925f464b373351            Pickle-Brined Fried Chicken   \n",
      "54a408a019925f464b3733bc                   Spinach Jewish Style   \n",
      "54a408a26529d92b2c003631                  New Year’s Honey Cake   \n",
      "54a408a66529d92b2c003638  The B.L.A.Bagel with Lox and Avocado   \n",
      "54a408a719925f464b3733cc        Shakshuka a la Doktor Shakshuka   \n",
      "\n",
      "                          aggregateRating  \\\n",
      "id                                          \n",
      "54a2b6b019925f464b373351             3.11   \n",
      "54a408a019925f464b3733bc             3.22   \n",
      "54a408a26529d92b2c003631             3.62   \n",
      "54a408a66529d92b2c003638             4.00   \n",
      "54a408a719925f464b3733cc             2.71   \n",
      "\n",
      "                                                                ingredients  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
      "54a408a019925f464b3733bc  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
      "54a408a26529d92b2c003631  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
      "54a408a66529d92b2c003638  [1 small ripe avocado, preferably Hass (see No...   \n",
      "54a408a719925f464b3733cc  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
      "\n",
      "                                                                  prepSteps  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351  [Toast mustard and coriander seeds in a dry me...   \n",
      "54a408a019925f464b3733bc  [Remove the stems and roots from the spinach. ...   \n",
      "54a408a26529d92b2c003631  [I like this cake best baked in a 9-inch angel...   \n",
      "54a408a66529d92b2c003638  [A short time before serving, mash avocado and...   \n",
      "54a408a719925f464b3733cc  [1. Place the tomatoes, garlic, salt, paprika,...   \n",
      "\n",
      "                          reviewsCount  willMakeAgainPct     cuisine_name  \\\n",
      "id                                                                          \n",
      "54a2b6b019925f464b373351             7               100  Missing Cuisine   \n",
      "54a408a019925f464b3733bc             5                80          Italian   \n",
      "54a408a26529d92b2c003631           105                88           Kosher   \n",
      "54a408a66529d92b2c003638             7               100           Kosher   \n",
      "54a408a719925f464b3733cc             7                83           Kosher   \n",
      "\n",
      "                                               photo_filename  \\\n",
      "id                                                              \n",
      "54a2b6b019925f464b373351       51247610_fried-chicken_1x1.jpg   \n",
      "54a408a019925f464b3733bc  EP_12162015_placeholders_rustic.jpg   \n",
      "54a408a26529d92b2c003631          EP_09022015_honeycake-2.jpg   \n",
      "54a408a66529d92b2c003638  EP_12162015_placeholders_casual.jpg   \n",
      "54a408a719925f464b3733cc  EP_12162015_placeholders_formal.jpg   \n",
      "\n",
      "                                                               photo_credit  \\\n",
      "id                                                                            \n",
      "54a2b6b019925f464b373351                Michael Graydon and Nikole Herriott   \n",
      "54a408a019925f464b3733bc  Photo by Chelsea Kyle, Prop Styling by Anna St...   \n",
      "54a408a26529d92b2c003631  Photo by Chelsea Kyle, Food Styling by Anna St...   \n",
      "54a408a66529d92b2c003638  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "54a408a719925f464b3733cc  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
      "\n",
      "                                  author_name            date_published  \\\n",
      "id                                                                        \n",
      "54a2b6b019925f464b373351  Missing Author Name 2014-08-19 04:00:00+00:00   \n",
      "54a408a019925f464b3733bc   Edda Servi Machlin 2008-09-09 04:00:00+00:00   \n",
      "54a408a26529d92b2c003631        Marcy Goldman 2008-09-10 04:00:00+00:00   \n",
      "54a408a66529d92b2c003638            Faye Levy 2008-09-08 04:00:00+00:00   \n",
      "54a408a719925f464b3733cc          Joan Nathan 2008-09-09 04:00:00+00:00   \n",
      "\n",
      "                                                                 recipe_url  \n",
      "id                                                                           \n",
      "54a2b6b019925f464b373351  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a019925f464b3733bc  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a26529d92b2c003631  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a66529d92b2c003638  https://www.epicurious.com/recipes/food/views/...  \n",
      "54a408a719925f464b3733cc  https://www.epicurious.com/recipes/food/views/...  \n",
      "(34656, 13)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# load from MLflow\n",
    "mlflow_client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow')\n",
    "\n",
    "# cv_params are parameters for the sklearn CountVectorizer or TFIDFVectorizer\n",
    "sklearn_nlp_params = {\n",
    "    'strip_accents':\"unicode\",\n",
    "    'lowercase':True,\n",
    "    'analyzer': StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4),\n",
    "    'min_df':10,\n",
    "}\n",
    "\n",
    "# create sklearn pipeline as in BERTopic lightweight configuration\n",
    "# pipe = make_pipeline(\n",
    "#     TfidfVectorizer(**sklearn_nlp_params),\n",
    "#     TruncatedSVD(100)\n",
    "# )\n",
    "\n",
    "# bertopic_params are a superset of cv_params\n",
    "bertopic_params = {\n",
    "    # 'embedding_model': TfidfVectorizer(**sklearn_nlp_params),\n",
    "    'top_n_words':20,\n",
    "    'min_topic_size':10,\n",
    "    'nr_topics':50,\n",
    "    'verbose':True,\n",
    "    'low_memory':True,\n",
    "    'calculate_probabilities':True,\n",
    "    # 'min_cluster_size': 10 # Possibly only works if modifying individual HDBSCAN component of BERTopic\n",
    "}\n",
    "\n",
    "# update bertopic_params to include cv_params\n",
    "# bertopic_params.update(cv_params)\n",
    "\n",
    "# pipeline_params are parameters that will be logged in MLFlow and are a superset of library parameters\n",
    "pipeline_params = {\n",
    "    'stanza_model': 'en',\n",
    "    'sklearn-transformer': 'TfidfVectorizer'\n",
    "}\n",
    "\n",
    "# update the pipeline parameters with the library-specific ones so that they show up in MLflow Tracking\n",
    "pipeline_params.update(sklearn_nlp_params)\n",
    "pipeline_params.update(bertopic_params)\n",
    "\n",
    "with mlflow.start_run(experiment_id=get_experiment_id(f\"{DAGSHUB_EMAIL}/bertopic_lightweight_stanza_ingreds_full_set_v1.00\")):    \n",
    "    # LOG PARAMETERS\n",
    "    mlflow.log_params(pipeline_params)\n",
    "\n",
    "    # LOG INPUTS (QUERIES) AND OUTPUTS\n",
    "    # MLflow example uses a list of strings or a list of str->str dicts\n",
    "    \n",
    "    # load raw data and preprocess/clean\n",
    "    data = dvc.api.read(\n",
    "           path='../data/recipes-en-201706/epicurious-recipes_m2.json'\n",
    "           , mode='r')\n",
    "    raw_df = pd.read_json(data)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print(f'{datetime.now()}, Raw Dataframe: ', end='\\n')\n",
    "    print(raw_df.head())\n",
    "    print(raw_df.shape)\n",
    "\n",
    "    # pre_proc_df is cleaned dataframe\n",
    "    pre_proc_df = dfpp.preprocess_dataframe(raw_df)\n",
    "    print('\\n')\n",
    "    print('--------------')\n",
    "    print(f'{datetime.now()}, Preprocessed Dataframe:', end='\\n')\n",
    "    print(pre_proc_df.head())\n",
    "    print(pre_proc_df.shape)\n",
    "\n",
    "\n",
    "    # pre_proc_df = pd.read_json(\n",
    "    #     mlflow.artifacts.download_artifacts(\n",
    "    #         run_id=mlflow_run_id,\n",
    "    #         artifact_path='artifacts/preprocessed_dataframes/preprocessed_dataframe.json',\n",
    "    #         # tracking_uri=f'https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow'\n",
    "    #     )\n",
    "    # )\n",
    "    # print('\\n')\n",
    "    # print('-' * 80)\n",
    "    # print('Preprocessed Dataframe:', end='\\n')\n",
    "    # print(pre_proc_df.head())\n",
    "    # print(pre_proc_df.shape)\n",
    "\n",
    "    # create subset for dev purposes\n",
    "    # to_nlp_df = pre_proc_df[0:100]\n",
    "    # print('\\n')\n",
    "    # print('-' * 80)\n",
    "    # print(f'{datetime.now()}, Subset Dataframe:', end='\\n')\n",
    "    # print(to_nlp_df.head())\n",
    "    # print(to_nlp_df.shape)\n",
    "\n",
    "    # LOG MODEL\n",
    "    # Instantiate BERTopic\n",
    "    topic_model = BERTopic(\n",
    "        **bertopic_params\n",
    "    )\n",
    "    \n",
    "    analyzer_kwargs = {'stanza_pipeline': nlp\n",
    "                       , 'minNgramLength': 1\n",
    "                       , 'maxNgramLength': 4}\n",
    "    \n",
    "    recipe_ingreds = pre_proc_df[\"ingredients\"].apply(custom_analyzer, **analyzer_kwargs)\n",
    "\n",
    "    # Create TF-IDF embeddings\n",
    "    vectorizer = TfidfVectorizer(**sklearn_nlp_params)\n",
    "    embeddings = vectorizer.fit_transform(recipe_ingreds)\n",
    "\n",
    "    # recipe_steps = \"\".join(str(to_nlp_df[\"prepSteps\"].apply(StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4))))\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, Recipe ingredients:', end='\\n')\n",
    "    print(recipe_ingreds)\n",
    "\n",
    "    # train on the recipes' ingredientss\n",
    "    topics, probs = topic_model.fit_transform(recipe_ingreds, embeddings)\n",
    "\n",
    "    # since this uses a custom Stanza analyzer, we have to use a custom mlflow.Pyfunc.PythonModel\n",
    "    # Instantiate sklearn CountVectorizer\n",
    "    sklearn_cv_params = {\n",
    "        'strip_accents':\"unicode\",\n",
    "        'lowercase':True,\n",
    "        # 'analyzer': StanzaWrapper().stanza_analyzer(stanza_pipeline=nlp, minNgramLength=1, maxNgramLength=4),\n",
    "        # 'min_df':10,\n",
    "        # 'token_pattern': \"(?u)\\b[a-zA-Z]{2,}\\b\"\n",
    "    }\n",
    "    ingreds_vectorizer_model = CountVectorizer(**sklearn_cv_params)\n",
    "\n",
    "    # May need to use BERTopic's OnlineCountVectorizer\n",
    "    # steps_vectorizer_model = OnlineCountVectorizer(**sklearn_nlp_params)\n",
    "\n",
    "    # Do fit transform on data\n",
    "    # steps_test_tfidf_transform = steps_tfidf_vectorizer_model.fit_transform(tqdm(to_nlp_df[\"steps\"]))\n",
    "    topic_model.update_topics(\n",
    "        recipe_ingreds\n",
    "        , vectorizer_model=ingreds_vectorizer_model\n",
    "    )\n",
    "\n",
    "    # Display topic model results\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, BERTopic Model Dataframe:', end='\\n')\n",
    "    print(topic_model.get_topic_info())\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, BERTopic Model Representations:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representation'])\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 80)\n",
    "    print(f'{datetime.now()}, BERTopic Model Representative Docs:', end='\\n')\n",
    "    print(topic_model.get_topic_info()['Representative_Docs'])\n",
    "\n",
    "    # Save and log the topic model dataframe\n",
    "    topic_model.get_topic_info().to_json('../data/processed/bertopic_model_ingreds_full_set_df.json')\n",
    "    mlflow.log_artifact('../data/processed/bertopic_model_ingreds_full_set_df.json',\n",
    "                        artifact_path='bertopic_models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
