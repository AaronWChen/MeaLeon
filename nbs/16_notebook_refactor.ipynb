{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Refactor MeaLeon into notebook friendly\n",
    "---\n",
    "description: Refactoring Flask App requests into more a notebook friendly iteration\n",
    "output-file: template.html\n",
    "title: Notebook refactor\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# | default_exp testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import dagshub\n",
    "import dill as pickle\n",
    "import joblib\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import nbdev  # ; nbdev.nbdev_export()\n",
    "from nbdev.showdoc import *\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer,\n",
    "    TfidfTransformer,\n",
    "    TfidfVectorizer,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from src.backend.embedding_creation.apply_stanza import CustomSKLearnAnalyzer\n",
    "from src.backend.embedding_creation.sklearn_transformer_as_mlflow_model import (\n",
    "    CustomSKLearnWrapper,\n",
    ")\n",
    "import src.backend.raw_data_cleaning.raw_data_preprocessor as rdpp\n",
    "import stanza\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to call DAGsHub to keep track of what we're doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @markdown Enter the username of your DAGsHub account:\n",
    "DAGSHUB_USER_NAME = \"AaronWChen\"  # @param {type:\"string\"}\n",
    "\n",
    "# @markdown Enter the email for your DAGsHub account:\n",
    "DAGSHUB_EMAIL = \"awc33@cornell.edu\"  # @param {type:\"string\"}\n",
    "\n",
    "# @markdown Enter the repo name\n",
    "DAGSHUB_REPO_NAME = \"MeaLeon\"\n",
    "\n",
    "# @markdown Enter the name of the branch you are working on\n",
    "BRANCH = \"init_mealeon_to_notebook_refactor\"\n",
    "dagshub.init(repo_name=DAGSHUB_REPO_NAME, repo_owner=DAGSHUB_USER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things I need to do\n",
    "\n",
    "1. app.py calls find_similar_dishes, returns a render template\n",
    "2. find_similar_dishes needs to call the recipe database, the sklearn model, the model-transformed database (ie, TFIDF word matrix), and the query (which needs to be transformed)\n",
    "   1. Little confused by order; why would i need the original database if i can just call the model/vector-transformed version?\n",
    "      1. Original database has things like url and ID, which could be needed later\n",
    "      2. ~~Future vector data can use the same recipe_id unique key, but only have the ingredient vectors. Use unique key to join original...~~\n",
    "      3. Wait, need cuisine filter to improve search results...so vector database should have cuisine and recipe_id\n",
    "      4. From that, can call back to original database to get URLs and other metadata\n",
    "         1. SQLModel query to join\n",
    "   2. Sklearn model (really any model that transforms the query) needs to be loaded from MLflow\n",
    "      1. Model will be used to transform query for similarity analysis\n",
    "      2. MLflow load\n",
    "   3. Vector database needs to be loaded from currently a json, but should switch to Vespa\n",
    "      1. Wouldn't this need to be linked to the MLflow Model? DVC + Vespa?\n",
    "      2. Mlflow or DVC load?\n",
    "   4. Original recipe database might also be DVC?\n",
    "   5. \n",
    "3. original query should be formatted and stored into recipe database (CRUD)\n",
    "4. this is called to edamam API\n",
    "5. edamam return is currently model-transformed then cuisine filtered\n",
    "   1. Swap this order so we don't have to process as much text\n",
    "6. Vector comparison against filtered data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "This part can be the DVC import for our data\n",
    "\n",
    "Currently, raw/processed data can be imported with json, need to consider how to access data something like SQL and log some snapshot of this data (and its metadata?) with DVC\n",
    "\n",
    "- Can i reuse some parts of GitHub Actions?\n",
    "\n",
    "- DVC can handle data files fine, but SQL pulls are currently experimentally supported\n",
    "- using dvc import-db https://dvc.org/doc/command-reference/import-db\n",
    "\n",
    "- DVC with generative AI (might be relevant to vector databases): https://youtu.be/aqMXEvWTuVY?si=2lMKrofl9s10BXVx\n",
    "\n",
    "#### Let's start with local data files\n",
    "\n",
    "Via automated ETL, DVC could log the raw data, perform the text processing if not an embedding, add the pre processed data back to DVC, then start MLflow with embedding conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                                 \n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/awchen/Repos/Projects/MeaLeon/.dvc/cache'| |0/? [0\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out ../data/raw/201706-epicur0/? [00:00<?,    ?files/s]\u001b[A\n",
      "  0%|          |Checking out ../data/raw/201706-epicur0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00,  4.23file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add ../data.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# raw data\n",
    "\n",
    "!dvc add \"../data/raw/201706-epicurious-recipes-en.json\"\n",
    "raw_df = pd.read_json(\"../data/raw/201706-epicurious-recipes-en.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL work (currently, data cleaning/prep)\n",
    "# how the prep works is via dataframe_preprocessor\n",
    "cleaned_df = rdpp.preprocess_dataframe(raw_df)\n",
    "cleaned_df.to_parquet(\"../data/processed/cleaned_df.parquet.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                                 \n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/awchen/Repos/Projects/MeaLeon/.dvc/cache'| |0/? [0\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Transferring                          0/? [00:00<?,     ?file/s]\u001b[A\n",
      "  0%|          |Transferring                          0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out ../data/processed/cleaned0/? [00:00<?,    ?files/s]\u001b[A\n",
      "  0%|          |Checking out ../data/processed/cleaned0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 17.84file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add ../data.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# add cleaned dataframe to DVC\n",
    "!dvc add \"../data/processed/cleaned_df.parquet.gzip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to commit DVC/data changes to git, does that need to be done in this cell?\n",
    "- based off of the nbdev tools currently (where it essentially runs the whole notebook), this may not be a good idea\n",
    "- when working out of a notebook for testing, dvc maybe can pull the data, but we should not be doing the actual processing here\n",
    "\n",
    "In the future, can/should the data cleaning be done in dbt?\n",
    "\n",
    "- no, dbt is more about analytics then data cleaning, it seems\n",
    "\n",
    "- if text processing needed regularly, might have to put in Airflow\n",
    "\n",
    "---\n",
    "\n",
    "Now that we have converted the raw dataframe to a cleaner form with lemmatization (if needed/preferred) we can move on to the embedding transformation. Currently, this is another ETL done with `nlp_processor`, but performed with an MLflow model and this embedding transformed/vectorized data should then added back to DVC.\n",
    "\n",
    "---\n",
    "\n",
    "In the future, we can take the embeddings and convert them to PyTorch tensors/datasets, which is not something we can do with the original raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# this is a custom function to be used with MLflow to get or create experiments (is from the MLflow team)\n",
    "def get_mlflow_experiment_id(name):\n",
    "    # this function allows us to get the experiment ID from an experiment name\n",
    "    exp = mlflow.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "        exp_id = mlflow.create_experiment(name)\n",
    "        return exp_id\n",
    "    return exp.experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting DEV stage for TFIDF Encoded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(f\"https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow\")\n",
    "\n",
    "# starter idea for making an experiment name, can be the git branch, but need more specificity\n",
    "experiment_name = f\"{DAGSHUB_EMAIL}/DVC-MLflow-integration-test\"\n",
    "mlflow_exp_id = get_mlflow_experiment_id(experiment_name)\n",
    "\n",
    "# define processed data location and data to be added to DVC\n",
    "processed_data_base = \"../data/processed\"\n",
    "transformed_recipes_parquet_path = (\n",
    "    processed_data_base + \"/transformed_recipes.parquet.gzip\"\n",
    ")\n",
    "combined_df_path = processed_data_base + \"/combined_df.parquet.gzip\"\n",
    "\n",
    "\n",
    "# define model location\n",
    "model_directory = \"../models/sklearn_model\"\n",
    "\n",
    "# Define the required artifacts associated with the saved custom pyfunc\n",
    "sklearn_model_path = model_directory + \"/python_model.pkl\"\n",
    "sklearn_transformer_path = model_directory + \"/sklearn_transformer.pkl\"\n",
    "# transformed_recipes_path = model_directory + \"/transformed_recipes.pkl\"\n",
    "combined_df_sample_path = model_directory + \"/combined_df_sample.parquet\"\n",
    "\n",
    "artifacts = {\n",
    "    \"sklearn_model\": sklearn_model_path,\n",
    "    \"sklearn_transformer\": sklearn_transformer_path,\n",
    "    #  'transformed_recipes': transformed_recipes_path,\n",
    "    #  'combined_data': combined_df_path,\n",
    "    \"combined_data_sample\": combined_df_sample_path,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0% Checkout|                                      |0/27 [00:00<?,     ?file/s]\n",
      "!\u001b[A\n",
      "Building data objects from ../joblib/2022.08.23       |0.00 [00:00,      ?obj/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "Building data objects from ../data                    |0.00 [00:00,      ?obj/s]\u001b[A\n",
      "\u001b[33mM\u001b[0m       ..\u001b[35m/data/\u001b[0m                                              \u001b[A\n",
      "\u001b[31mD\u001b[0m       data/raw/\u001b[1;36m201706\u001b[0m-epicurious-recipes-en.json\n",
      "\u001b[31mD\u001b[0m       data/processed/cleaned_df.parquet.gzip\n",
      "2 files deleted and 1 file modified\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Prepare whole dataframe for new processing\n",
    "!dvc pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dek</th>\n",
       "      <th>hed</th>\n",
       "      <th>aggregateRating</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>prepSteps</th>\n",
       "      <th>reviewsCount</th>\n",
       "      <th>willMakeAgainPct</th>\n",
       "      <th>ingredients_lemmafied</th>\n",
       "      <th>cuisine_name</th>\n",
       "      <th>photo_filename</th>\n",
       "      <th>photo_credit</th>\n",
       "      <th>author_name</th>\n",
       "      <th>date_published</th>\n",
       "      <th>recipe_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54a2b6b019925f464b373351</th>\n",
       "      <td>How does fried chicken achieve No. 1 status? B...</td>\n",
       "      <td>Pickle-Brined Fried Chicken</td>\n",
       "      <td>3.11</td>\n",
       "      <td>[1 tablespoons yellow mustard seeds, 1 tablesp...</td>\n",
       "      <td>[Toast mustard and coriander seeds in a dry me...</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>tablespoon yellow mustard seed brk tablespoon ...</td>\n",
       "      <td>Missing Cuisine</td>\n",
       "      <td>51247610_fried-chicken_1x1.jpg</td>\n",
       "      <td>Michael Graydon and Nikole Herriott</td>\n",
       "      <td>Missing Author Name</td>\n",
       "      <td>2014-08-19 04:00:00+00:00</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a408a019925f464b3733bc</th>\n",
       "      <td>Spinaci all'Ebraica</td>\n",
       "      <td>Spinach Jewish Style</td>\n",
       "      <td>3.22</td>\n",
       "      <td>[3 pounds small-leaved bulk spinach, Salt, 1/2...</td>\n",
       "      <td>[Remove the stems and roots from the spinach. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>pound small leave bulk spinach brk salt brk cu...</td>\n",
       "      <td>Italian</td>\n",
       "      <td>EP_12162015_placeholders_rustic.jpg</td>\n",
       "      <td>Photo by Chelsea Kyle, Prop Styling by Anna St...</td>\n",
       "      <td>Edda Servi Machlin</td>\n",
       "      <td>2008-09-09 04:00:00+00:00</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a408a26529d92b2c003631</th>\n",
       "      <td>This majestic, moist, and richly spiced honey ...</td>\n",
       "      <td>New Year’s Honey Cake</td>\n",
       "      <td>3.62</td>\n",
       "      <td>[3 1/2 cups all-purpose flour, 1 tablespoon ba...</td>\n",
       "      <td>[I like this cake best baked in a 9-inch angel...</td>\n",
       "      <td>105</td>\n",
       "      <td>88</td>\n",
       "      <td>cup purpose flour brk tablespoon baking powder...</td>\n",
       "      <td>Kosher</td>\n",
       "      <td>EP_09022015_honeycake-2.jpg</td>\n",
       "      <td>Photo by Chelsea Kyle, Food Styling by Anna St...</td>\n",
       "      <td>Marcy Goldman</td>\n",
       "      <td>2008-09-10 04:00:00+00:00</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a408a66529d92b2c003638</th>\n",
       "      <td>The idea for this sandwich came to me when my ...</td>\n",
       "      <td>The B.L.A.Bagel with Lox and Avocado</td>\n",
       "      <td>4.00</td>\n",
       "      <td>[1 small ripe avocado, preferably Hass (see No...</td>\n",
       "      <td>[A short time before serving, mash avocado and...</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>small ripe avocado hass see note brk teaspoon ...</td>\n",
       "      <td>Kosher</td>\n",
       "      <td>EP_12162015_placeholders_casual.jpg</td>\n",
       "      <td>Photo by Chelsea Kyle, Prop Styling by Rhoda B...</td>\n",
       "      <td>Faye Levy</td>\n",
       "      <td>2008-09-08 04:00:00+00:00</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a408a719925f464b3733cc</th>\n",
       "      <td>In 1930, Simon Agranat, the chief justice of t...</td>\n",
       "      <td>Shakshuka a la Doktor Shakshuka</td>\n",
       "      <td>2.71</td>\n",
       "      <td>[2 pounds fresh tomatoes, unpeeled and cut in ...</td>\n",
       "      <td>[1. Place the tomatoes, garlic, salt, paprika,...</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>pound fresh tomato unpeeled cut quarter ounce ...</td>\n",
       "      <td>Kosher</td>\n",
       "      <td>EP_12162015_placeholders_formal.jpg</td>\n",
       "      <td>Photo by Chelsea Kyle, Prop Styling by Rhoda B...</td>\n",
       "      <td>Joan Nathan</td>\n",
       "      <td>2008-09-09 04:00:00+00:00</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        dek  \\\n",
       "id                                                                            \n",
       "54a2b6b019925f464b373351  How does fried chicken achieve No. 1 status? B...   \n",
       "54a408a019925f464b3733bc                                Spinaci all'Ebraica   \n",
       "54a408a26529d92b2c003631  This majestic, moist, and richly spiced honey ...   \n",
       "54a408a66529d92b2c003638  The idea for this sandwich came to me when my ...   \n",
       "54a408a719925f464b3733cc  In 1930, Simon Agranat, the chief justice of t...   \n",
       "\n",
       "                                                            hed  \\\n",
       "id                                                                \n",
       "54a2b6b019925f464b373351            Pickle-Brined Fried Chicken   \n",
       "54a408a019925f464b3733bc                   Spinach Jewish Style   \n",
       "54a408a26529d92b2c003631                  New Year’s Honey Cake   \n",
       "54a408a66529d92b2c003638  The B.L.A.Bagel with Lox and Avocado   \n",
       "54a408a719925f464b3733cc        Shakshuka a la Doktor Shakshuka   \n",
       "\n",
       "                          aggregateRating  \\\n",
       "id                                          \n",
       "54a2b6b019925f464b373351             3.11   \n",
       "54a408a019925f464b3733bc             3.22   \n",
       "54a408a26529d92b2c003631             3.62   \n",
       "54a408a66529d92b2c003638             4.00   \n",
       "54a408a719925f464b3733cc             2.71   \n",
       "\n",
       "                                                                ingredients  \\\n",
       "id                                                                            \n",
       "54a2b6b019925f464b373351  [1 tablespoons yellow mustard seeds, 1 tablesp...   \n",
       "54a408a019925f464b3733bc  [3 pounds small-leaved bulk spinach, Salt, 1/2...   \n",
       "54a408a26529d92b2c003631  [3 1/2 cups all-purpose flour, 1 tablespoon ba...   \n",
       "54a408a66529d92b2c003638  [1 small ripe avocado, preferably Hass (see No...   \n",
       "54a408a719925f464b3733cc  [2 pounds fresh tomatoes, unpeeled and cut in ...   \n",
       "\n",
       "                                                                  prepSteps  \\\n",
       "id                                                                            \n",
       "54a2b6b019925f464b373351  [Toast mustard and coriander seeds in a dry me...   \n",
       "54a408a019925f464b3733bc  [Remove the stems and roots from the spinach. ...   \n",
       "54a408a26529d92b2c003631  [I like this cake best baked in a 9-inch angel...   \n",
       "54a408a66529d92b2c003638  [A short time before serving, mash avocado and...   \n",
       "54a408a719925f464b3733cc  [1. Place the tomatoes, garlic, salt, paprika,...   \n",
       "\n",
       "                          reviewsCount  willMakeAgainPct  \\\n",
       "id                                                         \n",
       "54a2b6b019925f464b373351             7               100   \n",
       "54a408a019925f464b3733bc             5                80   \n",
       "54a408a26529d92b2c003631           105                88   \n",
       "54a408a66529d92b2c003638             7               100   \n",
       "54a408a719925f464b3733cc             7                83   \n",
       "\n",
       "                                                      ingredients_lemmafied  \\\n",
       "id                                                                            \n",
       "54a2b6b019925f464b373351  tablespoon yellow mustard seed brk tablespoon ...   \n",
       "54a408a019925f464b3733bc  pound small leave bulk spinach brk salt brk cu...   \n",
       "54a408a26529d92b2c003631  cup purpose flour brk tablespoon baking powder...   \n",
       "54a408a66529d92b2c003638  small ripe avocado hass see note brk teaspoon ...   \n",
       "54a408a719925f464b3733cc  pound fresh tomato unpeeled cut quarter ounce ...   \n",
       "\n",
       "                             cuisine_name  \\\n",
       "id                                          \n",
       "54a2b6b019925f464b373351  Missing Cuisine   \n",
       "54a408a019925f464b3733bc          Italian   \n",
       "54a408a26529d92b2c003631           Kosher   \n",
       "54a408a66529d92b2c003638           Kosher   \n",
       "54a408a719925f464b3733cc           Kosher   \n",
       "\n",
       "                                               photo_filename  \\\n",
       "id                                                              \n",
       "54a2b6b019925f464b373351       51247610_fried-chicken_1x1.jpg   \n",
       "54a408a019925f464b3733bc  EP_12162015_placeholders_rustic.jpg   \n",
       "54a408a26529d92b2c003631          EP_09022015_honeycake-2.jpg   \n",
       "54a408a66529d92b2c003638  EP_12162015_placeholders_casual.jpg   \n",
       "54a408a719925f464b3733cc  EP_12162015_placeholders_formal.jpg   \n",
       "\n",
       "                                                               photo_credit  \\\n",
       "id                                                                            \n",
       "54a2b6b019925f464b373351                Michael Graydon and Nikole Herriott   \n",
       "54a408a019925f464b3733bc  Photo by Chelsea Kyle, Prop Styling by Anna St...   \n",
       "54a408a26529d92b2c003631  Photo by Chelsea Kyle, Food Styling by Anna St...   \n",
       "54a408a66529d92b2c003638  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
       "54a408a719925f464b3733cc  Photo by Chelsea Kyle, Prop Styling by Rhoda B...   \n",
       "\n",
       "                                  author_name            date_published  \\\n",
       "id                                                                        \n",
       "54a2b6b019925f464b373351  Missing Author Name 2014-08-19 04:00:00+00:00   \n",
       "54a408a019925f464b3733bc   Edda Servi Machlin 2008-09-09 04:00:00+00:00   \n",
       "54a408a26529d92b2c003631        Marcy Goldman 2008-09-10 04:00:00+00:00   \n",
       "54a408a66529d92b2c003638            Faye Levy 2008-09-08 04:00:00+00:00   \n",
       "54a408a719925f464b3733cc          Joan Nathan 2008-09-09 04:00:00+00:00   \n",
       "\n",
       "                                                                 recipe_url  \n",
       "id                                                                           \n",
       "54a2b6b019925f464b373351  https://www.epicurious.com/recipes/food/views/...  \n",
       "54a408a019925f464b3733bc  https://www.epicurious.com/recipes/food/views/...  \n",
       "54a408a26529d92b2c003631  https://www.epicurious.com/recipes/food/views/...  \n",
       "54a408a66529d92b2c003638  https://www.epicurious.com/recipes/food/views/...  \n",
       "54a408a719925f464b3733cc  https://www.epicurious.com/recipes/food/views/...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this part can be done after a dvc pull\n",
    "whole_nlp_df = pd.read_parquet(\"../data/processed/cleaned_df.parquet.gzip\")\n",
    "whole_nlp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "sklearn fit transform on ingredients:\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Input Data: \n",
      "id\n",
      "54a2b6b019925f464b373351    tablespoon yellow mustard seed brk tablespoon ...\n",
      "54a408a019925f464b3733bc    pound small leave bulk spinach brk salt brk cu...\n",
      "54a408a26529d92b2c003631    cup purpose flour brk tablespoon baking powder...\n",
      "54a408a66529d92b2c003638    small ripe avocado hass see note brk teaspoon ...\n",
      "54a408a719925f464b3733cc    pound fresh tomato unpeeled cut quarter ounce ...\n",
      "                                                  ...                        \n",
      "59541a31bff3052847ae2107    tablespoon unsalt butter room temperature brk ...\n",
      "5954233ad52ca90dc28200e7    tablespoon stick salt butter room temperature ...\n",
      "595424c2109c972493636f83    tablespoon unsalted butter more greasing pan b...\n",
      "5956638625dc3d1d829b7166    coarse salt brk lime wedge brk ounce tomato ju...\n",
      "59566daa25dc3d1d829b7169    bottle millileter sour beer such almanac citra...\n",
      "Name: ingredients_lemmafied, Length: 34756, dtype: object\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Input Data Shape: \n",
      "(34756,)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Random 3 Records from Input Data: \n",
      "id\n",
      "54a40caa19925f464b374017    boneless muscovy duck breast half pound total ...\n",
      "55d4e08063b1ba1b5534b198    tablespoon white wine vinegar brk teaspoon sug...\n",
      "54a43ad16529d92b2c019fc3    cup basmati rice ounce brk cup sweeten flake c...\n",
      "Name: ingredients_lemmafied, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34756/34756 [00:03<00:00, 10450.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Transformed Data:\n",
      "                          100g  125g  13x9x2  150g  1pound  1tablespoon  \\\n",
      "id                                                                        \n",
      "54a2b6b019925f464b373351   0.0   0.0     0.0   0.0     0.0          0.0   \n",
      "54a408a019925f464b3733bc   0.0   0.0     0.0   0.0     0.0          0.0   \n",
      "54a408a26529d92b2c003631   0.0   0.0     0.0   0.0     0.0          0.0   \n",
      "54a408a66529d92b2c003638   0.0   0.0     0.0   0.0     0.0          0.0   \n",
      "54a408a719925f464b3733cc   0.0   0.0     0.0   0.0     0.0          0.0   \n",
      "\n",
      "                          1teaspoon  200g  250g  2cup  ...  árbol divide  \\\n",
      "id                                                     ...                 \n",
      "54a2b6b019925f464b373351        0.0   0.0   0.0   0.0  ...           0.0   \n",
      "54a408a019925f464b3733bc        0.0   0.0   0.0   0.0  ...           0.0   \n",
      "54a408a26529d92b2c003631        0.0   0.0   0.0   0.0  ...           0.0   \n",
      "54a408a66529d92b2c003638        0.0   0.0   0.0   0.0  ...           0.0   \n",
      "54a408a719925f464b3733cc        0.0   0.0   0.0   0.0  ...           0.0   \n",
      "\n",
      "                          árbol seed  árbol seed remove  árbol stem  \\\n",
      "id                                                                    \n",
      "54a2b6b019925f464b373351         0.0                0.0         0.0   \n",
      "54a408a019925f464b3733bc         0.0                0.0         0.0   \n",
      "54a408a26529d92b2c003631         0.0                0.0         0.0   \n",
      "54a408a66529d92b2c003638         0.0                0.0         0.0   \n",
      "54a408a719925f464b3733cc         0.0                0.0         0.0   \n",
      "\n",
      "                          árbol teaspoon  árbol teaspoon crush  \\\n",
      "id                                                               \n",
      "54a2b6b019925f464b373351             0.0                   0.0   \n",
      "54a408a019925f464b3733bc             0.0                   0.0   \n",
      "54a408a26529d92b2c003631             0.0                   0.0   \n",
      "54a408a66529d92b2c003638             0.0                   0.0   \n",
      "54a408a719925f464b3733cc             0.0                   0.0   \n",
      "\n",
      "                          árbol teaspoon crush red  árbol wipe  \\\n",
      "id                                                               \n",
      "54a2b6b019925f464b373351                       0.0         0.0   \n",
      "54a408a019925f464b3733bc                       0.0         0.0   \n",
      "54a408a26529d92b2c003631                       0.0         0.0   \n",
      "54a408a66529d92b2c003638                       0.0         0.0   \n",
      "54a408a719925f464b3733cc                       0.0         0.0   \n",
      "\n",
      "                          árbol wipe clean  épice  \n",
      "id                                                 \n",
      "54a2b6b019925f464b373351               0.0    0.0  \n",
      "54a408a019925f464b3733bc               0.0    0.0  \n",
      "54a408a26529d92b2c003631               0.0    0.0  \n",
      "54a408a66529d92b2c003638               0.0    0.0  \n",
      "54a408a719925f464b3733cc               0.0    0.0  \n",
      "\n",
      "[5 rows x 78381 columns]\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Random Sample of Combined Data:\n",
      "                          100g  125g  13x9x2  150g  1pound  1tablespoon  \\\n",
      "id                                                                        \n",
      "54a40caa19925f464b374017   0.0   0.0     0.0   0.0     0.0          0.0   \n",
      "54a43ad16529d92b2c019fc3   0.0   0.0     0.0   0.0     0.0          0.0   \n",
      "55d4e08063b1ba1b5534b198   0.0   0.0     0.0   0.0     0.0          0.0   \n",
      "\n",
      "                          1teaspoon  200g  250g  2cup  ...  árbol seed  \\\n",
      "id                                                     ...               \n",
      "54a40caa19925f464b374017        0.0   0.0   0.0   0.0  ...         0.0   \n",
      "54a43ad16529d92b2c019fc3        0.0   0.0   0.0   0.0  ...         0.0   \n",
      "55d4e08063b1ba1b5534b198        0.0   0.0   0.0   0.0  ...         0.0   \n",
      "\n",
      "                          árbol seed remove  árbol stem  árbol teaspoon  \\\n",
      "id                                                                        \n",
      "54a40caa19925f464b374017                0.0         0.0             0.0   \n",
      "54a43ad16529d92b2c019fc3                0.0         0.0             0.0   \n",
      "55d4e08063b1ba1b5534b198                0.0         0.0             0.0   \n",
      "\n",
      "                          árbol teaspoon crush  árbol teaspoon crush red  \\\n",
      "id                                                                         \n",
      "54a40caa19925f464b374017                   0.0                       0.0   \n",
      "54a43ad16529d92b2c019fc3                   0.0                       0.0   \n",
      "55d4e08063b1ba1b5534b198                   0.0                       0.0   \n",
      "\n",
      "                          árbol wipe  árbol wipe clean  épice  \\\n",
      "id                                                              \n",
      "54a40caa19925f464b374017         0.0               0.0    0.0   \n",
      "54a43ad16529d92b2c019fc3         0.0               0.0    0.0   \n",
      "55d4e08063b1ba1b5534b198         0.0               0.0    0.0   \n",
      "\n",
      "                                                      ingredients_lemmafied  \n",
      "id                                                                           \n",
      "54a40caa19925f464b374017  boneless muscovy duck breast half pound total ...  \n",
      "54a43ad16529d92b2c019fc3  cup basmati rice ounce brk cup sweeten flake c...  \n",
      "55d4e08063b1ba1b5534b198  tablespoon white wine vinegar brk teaspoon sug...  \n",
      "\n",
      "[3 rows x 78382 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413513de77ec40e097f0fe537db730da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f463247aaa654948a7d7170a6d90f997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf79aae1fe38472ba528d8b84d1b5f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/29 21:58:31 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpzmn49nj8/model, flavor: python_function), fall back to return ['cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback.\n",
      "/home/awchen/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/awchen/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "2024/07/29 21:59:09 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/5abd2670253447e0a4988212aabcf35a/e3cf27f656504b0d9b6d5a8d4ce1abb2/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    }
   ],
   "source": [
    "# load from MLflow\n",
    "mlflow_client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=f\"https://dagshub.com/{DAGSHUB_USER_NAME}/MeaLeon.mlflow\"\n",
    ")\n",
    "\n",
    "# cv_params are parameters for the sklearn CountVectorizer or TFIDFVectorizer\n",
    "sklearn_transformer_params = {\n",
    "    \"analyzer\": CustomSKLearnAnalyzer().ngram_maker(\n",
    "        min_ngram_length=1,\n",
    "        max_ngram_length=4,\n",
    "    ),\n",
    "    \"min_df\": 3,\n",
    "    \"binary\": False,\n",
    "}\n",
    "\n",
    "# pipeline_params are parameters that will be logged in MLFlow and are a superset of library parameters\n",
    "pipeline_params = {\"stanza_model\": \"en\", \"sklearn-transformer\": \"TFIDF\"}\n",
    "\n",
    "# update the pipeline parameters with the library-specific ones so that they show up in MLflow Tracking\n",
    "pipeline_params.update(sklearn_transformer_params)\n",
    "\n",
    "with mlflow.start_run(experiment_id=mlflow_exp_id):\n",
    "    # LOG PARAMETERS\n",
    "    mlflow.log_params(pipeline_params)\n",
    "\n",
    "    # LOG INPUTS (QUERIES) AND OUTPUTS\n",
    "    # MLflow example uses a list of strings or a list of str->str dicts\n",
    "    # Will be useful in STAGING/Evaluation\n",
    "\n",
    "    # LOG MODEL\n",
    "    # Instantiate sklearn TFIDFVectorizer\n",
    "    sklearn_transformer = TfidfVectorizer(**sklearn_transformer_params)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"sklearn fit transform on ingredients:\")\n",
    "\n",
    "    model_input = whole_nlp_df[\"ingredients_lemmafied\"]\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Input Data: \")\n",
    "    print(model_input)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Input Data Shape: \")\n",
    "    print(model_input.shape)\n",
    "\n",
    "    random_sample = model_input.sample(3, random_state=200)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Random 3 Records from Input Data: \")\n",
    "    print(random_sample)\n",
    "\n",
    "    # Do fit transform on data\n",
    "    response = sklearn_transformer.fit_transform(tqdm(model_input))\n",
    "\n",
    "    transformed_recipe = pd.DataFrame(\n",
    "        response.toarray(),\n",
    "        columns=sklearn_transformer.get_feature_names_out(),\n",
    "        index=model_input.index,\n",
    "    )\n",
    "\n",
    "    signature = infer_signature(\n",
    "        model_input=model_input, model_output=transformed_recipe\n",
    "    )\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Transformed Data:\")\n",
    "    print(transformed_recipe.head())\n",
    "\n",
    "    combined_df = transformed_recipe.join(model_input, how=\"inner\")\n",
    "    combined_df_sample = transformed_recipe.join(random_sample, how=\"inner\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Random Sample of Combined Data:\")\n",
    "    print(combined_df_sample.head())\n",
    "\n",
    "    with open(sklearn_transformer_path, \"wb\") as fo:\n",
    "        pickle.dump(sklearn_transformer, fo)\n",
    "\n",
    "    transformed_recipe.to_parquet(\n",
    "        path=transformed_recipes_parquet_path, compression=\"gzip\"\n",
    "    )\n",
    "\n",
    "    combined_df.to_parquet(path=combined_df_path, compression=\"gzip\")\n",
    "\n",
    "    combined_df_sample.to_parquet(path=combined_df_sample_path)\n",
    "\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        code_path=[\"../src/backend/\"],\n",
    "        python_model=CustomSKLearnWrapper(),\n",
    "        input_example=whole_nlp_df[\"ingredients_lemmafied\"][0],\n",
    "        signature=signature,\n",
    "        artifact_path=\"sklearn_model\",\n",
    "        artifacts=artifacts,\n",
    "    )\n",
    "\n",
    "    # since this uses a custom Stanza analyzer, we have to use a custom mlflow.Pyfunc.PythonModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                                 \n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/awchen/Repos/Projects/MeaLeon/.dvc/cache'| |0/? [0\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Transferring                          0/? [00:00<?,     ?file/s]\u001b[A\n",
      "  0%|          |Transferring                          0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out ../data/processed/transfo0/? [00:00<?,    ?files/s]\u001b[A\n",
      "  0%|          |Checking out ../data/processed/transfo0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00,  5.53file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add ../data.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc add \"../data/processed/transformed_recipes.parquet.gzip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                                 \n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/awchen/Repos/Projects/MeaLeon/.dvc/cache'| |0/? [0\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Transferring                          0/? [00:00<?,     ?file/s]\u001b[A\n",
      "  0%|          |Transferring                          0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out ../data/processed/combine0/? [00:00<?,    ?files/s]\u001b[A\n",
      "  0%|          |Checking out ../data/processed/combine0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00,  5.37file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add ../data.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc add \"../data/processed/combined_df.parquet.gzip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awchen/Repos/Projects/MeaLeon/.venv/lib/python3.10/site-packages/nbdev/export.py:73: UserWarning: Notebook '/home/awchen/Repos/Projects/MeaLeon/nbs/16_notebook_refactor.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
