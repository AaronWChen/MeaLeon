{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9afa101e-a9e5-4d1d-9e3e-416f1c767233",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Epicurious Scrape in a JSON file\n",
    "\n",
    "This is an idealized workflow for Aaron Chen in looking at data science problems. It likely isn't the best path, nor has he rigidly applied or stuck to this ideal, but he wishes that he worked this way more frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59c575-9aca-4d08-9b03-3425fa33cb03",
   "metadata": {},
   "source": [
    "## Purpose: This notebook will do some clustering and classification on the recipes missing cuisine labels. Make this fast and see what we can get. Then move on to:\n",
    "\n",
    "1. Fixing Render\n",
    "2. Creating login system to store searches and preferences\n",
    "3. Fixing the filtering\n",
    "4. Working on scrapers\n",
    "5. Working on the database\n",
    "\n",
    "### Author: Aaron Chen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21b7d4-5980-4adf-a62b-38b8e89031ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d4a89-cf20-435c-bcc0-6f1ebcd127c7",
   "metadata": {},
   "source": [
    "### If needed, run shell commands here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed4e2d-6f77-4196-b548-d5896e13193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -c \"import tkinter\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cede1d1-3a00-4471-91ae-50be260464a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b66d7b-46ad-4f10-9cb9-72c03e319fea",
   "metadata": {},
   "source": [
    "## External Resources\n",
    "\n",
    "List out references or documentation that has helped you with this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b23fd3-6cf1-42b3-aee3-82306eaade6a",
   "metadata": {},
   "source": [
    "### Code\n",
    "Regex Checker: https://regex101.com/\n",
    "\n",
    "#### Scikit-learn\n",
    "1. https://scikit-learn.org/stable/modules/decomposition.html#latent-dirichlet-allocation-lda\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf83f44-334c-448a-afa7-187f63dd7285",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "For this notebook, the data is stored in the repo base folder/data/raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0dcb8e-5a84-4e96-b07d-24909352935d",
   "metadata": {},
   "source": [
    "### Process\n",
    "\n",
    "Are there steps or tutorials you are following? Those are things I try to list in Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6a44e4-081e-4f8f-88d2-3eccd0f2d767",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418bdb7-3ecf-4eb5-af6f-2c0e699d2394",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f480787a-b5ed-4bf2-8553-504d6cfffe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bokeh.plotting import figure, output_file, save, show\n",
    "# from bokeh.io import output_notebook\n",
    "\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import FeatureAgglomeration, KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60dd0a-089e-41b7-9828-8f2b13648993",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde95259-0cd4-4ae1-8485-d51ada957529",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3ea1e-a26e-4545-b950-ec823cbd6a26",
   "metadata": {},
   "source": [
    "My workflow is to try things with code cells, then when the code cells get messy and repetitive, to convert into helper functions that can be called.\n",
    "\n",
    "When the helper functions are getting used a lot, it is usually better to convert them to scripts or classes that can be called/instantiated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fdd4b0-9acb-445e-acad-2b3eb6ab9e4c",
   "metadata": {},
   "source": [
    "### Import local script\n",
    "\n",
    "I started grouping this in with importing libraries, but putting them at the bottom of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27ae4f42-17a3-4564-95b7-7993e5989d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awchen/Repos/Projects/MeaLeon/.venv/lib/python3.8/site-packages/spacy/util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import project_path\n",
    "\n",
    "import src.dataframe_preprocessor as dfpp\n",
    "import src.nlp_processor as nlp_proc\n",
    "import src.plotter as ILoveMyKeyboard\n",
    "import src.transformers as skt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b7742-3b22-4f48-877f-9f32cd7251fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7445bf0-0b00-45b9-a2db-84c568bced29",
   "metadata": {},
   "source": [
    "## Define global variables \n",
    "### Remember to refactor these out, not ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61418b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98b748-74ad-4dff-bebe-aa794f7a4591",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325f7ef-07c7-46b1-8595-9749259da76b",
   "metadata": {},
   "source": [
    "## Running Commentary\n",
    "\n",
    "1. \n",
    "\n",
    "### To Do\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2173e5-db8a-4fff-8072-98d6b16f7a4d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf870da-c2ed-4cde-9dd8-1591cbd2f24c",
   "metadata": {},
   "source": [
    "## Importing and viewing the data as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "571d7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../../data/recipes-en-201706/epicurious-recipes_m2.json'\n",
    "\n",
    "joblib_basepath = '../../joblib/2022.08.23/'\n",
    "\n",
    "cv_path = joblib_basepath + 'countvec.joblib'\n",
    "tfidf_path = joblib_basepath + 'tfidf.joblib'\n",
    "full_df_path = joblib_basepath + 'recipes_with_cv.joblib'\n",
    "reduced_df_path = joblib_basepath + 'reduced_df.joblib'\n",
    "rfc_path = joblib_basepath + 'rfc_clf.joblib'\n",
    "X_path = joblib_basepath + 'X.joblib'\n",
    "y_path = joblib_basepath + 'y.joblib'\n",
    "truncSVD_path = joblib_basepath + 'truncSVD.joblib'\n",
    "truncSVD_transformed_path = joblib_basepath + 'truncSVD_transformed.joblib'\n",
    "svd_numpy_path = joblib_basepath + 'SVD_numpy.joblib'\n",
    "to_plot_path = joblib_basepath + 'to_plot.joblib'\n",
    "tsne_path = joblib_basepath + 'tsne.joblib'\n",
    "tsne_vis_path = joblib_basepath + 'tsne_vis.joblib'\n",
    "kmeans_path = joblib_basepath + 'kmeans.joblib'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cdaaf4",
   "metadata": {},
   "source": [
    "We can probably start with recipes_with_cv and the rfc_clf below\n",
    "\n",
    "Add in LGBM or XGBoost or KMeans/Silhouette "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938f47b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = load(cv_path)\n",
    "tfidf = load(tfidf_path)\n",
    "recipes_with_cv = load(full_df_path)\n",
    "recipes_with_cv.set_index('id', inplace=True, drop=True)\n",
    "reduced_df = load(reduced_df_path)\n",
    "reduced_df.set_index('id', inplace=True, drop=True)\n",
    "rfc_clf = load(rfc_path)\n",
    "X = load(X_path)\n",
    "y = load(y_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52539add",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=240, stratify=y\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e71568",
   "metadata": {},
   "source": [
    "Based on the user guide in sklearn, we should try Manhattan distance as a metric, but maybe also go with cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75fbe43",
   "metadata": {},
   "source": [
    "### Cosine distance first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d5210d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cosine affinity cannot be used when X contains zero vectors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/awchen/Repos/Projects/MeaLeon/notebooks/exploratory/2022.11.07 - JSON EDA12, Dimension Reduction and Clustering.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/notebooks/exploratory/2022.11.07%20-%20JSON%20EDA12%2C%20Dimension%20Reduction%20and%20Clustering.ipynb#Y122sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m cos_agglo \u001b[39m=\u001b[39m FeatureAgglomeration(n_clusters\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, affinity\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcosine\u001b[39m\u001b[39m'\u001b[39m, linkage\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maverage\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/awchen/Repos/Projects/MeaLeon/notebooks/exploratory/2022.11.07%20-%20JSON%20EDA12%2C%20Dimension%20Reduction%20and%20Clustering.ipynb#Y122sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m X_train_transformed \u001b[39m=\u001b[39m cos_agglo\u001b[39m.\u001b[39;49mfit_transform(X_train)\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.8/site-packages/sklearn/base.py:867\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.8/site-packages/sklearn/cluster/_agglomerative.py:1237\u001b[0m, in \u001b[0;36mFeatureAgglomeration.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[39m\"\"\"Fit the hierarchical clustering on the data.\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \n\u001b[1;32m   1223\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[39m    Returns the transformer.\u001b[39;00m\n\u001b[1;32m   1235\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1236\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, ensure_min_features\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m-> 1237\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(X\u001b[39m.\u001b[39;49mT)\n\u001b[1;32m   1238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clusters_\n\u001b[1;32m   1239\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.8/site-packages/sklearn/cluster/_agglomerative.py:998\u001b[0m, in \u001b[0;36mAgglomerativeClustering._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    994\u001b[0m distance_threshold \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistance_threshold\n\u001b[1;32m    996\u001b[0m return_distance \u001b[39m=\u001b[39m (distance_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_distances\n\u001b[0;32m--> 998\u001b[0m out \u001b[39m=\u001b[39m memory\u001b[39m.\u001b[39;49mcache(tree_builder)(\n\u001b[1;32m    999\u001b[0m     X,\n\u001b[1;32m   1000\u001b[0m     connectivity\u001b[39m=\u001b[39;49mconnectivity,\n\u001b[1;32m   1001\u001b[0m     n_clusters\u001b[39m=\u001b[39;49mn_clusters,\n\u001b[1;32m   1002\u001b[0m     return_distance\u001b[39m=\u001b[39;49mreturn_distance,\n\u001b[1;32m   1003\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1004\u001b[0m )\n\u001b[1;32m   1005\u001b[0m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_connected_components_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_leaves_, parents) \u001b[39m=\u001b[39m out[\n\u001b[1;32m   1006\u001b[0m     :\u001b[39m4\u001b[39m\n\u001b[1;32m   1007\u001b[0m ]\n\u001b[1;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m return_distance:\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.8/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.8/site-packages/sklearn/cluster/_agglomerative.py:667\u001b[0m, in \u001b[0;36m_average_linkage\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_average_linkage\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    666\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mlinkage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39maverage\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 667\u001b[0m     \u001b[39mreturn\u001b[39;00m linkage_tree(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Repos/Projects/MeaLeon/.venv/lib/python3.8/site-packages/sklearn/cluster/_agglomerative.py:486\u001b[0m, in \u001b[0;36mlinkage_tree\u001b[0;34m(X, connectivity, n_clusters, linkage, affinity, return_distance)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnknown linkage option, linkage should be one of \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, but \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m was given\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[39m%\u001b[39m (linkage_choices\u001b[39m.\u001b[39mkeys(), linkage)\n\u001b[1;32m    483\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[39mif\u001b[39;00m affinity \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcosine\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(\u001b[39m~\u001b[39mnp\u001b[39m.\u001b[39many(X, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)):\n\u001b[0;32m--> 486\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCosine affinity cannot be used when X contains zero vectors\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m connectivity \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m hierarchy  \u001b[39m# imports PIL\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Cosine affinity cannot be used when X contains zero vectors"
     ]
    }
   ],
   "source": [
    "cos_agglo = FeatureAgglomeration(n_clusters=50, affinity='cosine', linkage='average')\n",
    "X_train_transformed = cos_agglo.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f6b3d2",
   "metadata": {},
   "source": [
    "### ok! let's try manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "281fe3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "manh_agglo = FeatureAgglomeration(n_clusters=5, affinity='manhattan', linkage='average')\n",
    "X_train_transformed = manh_agglo.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for i in range(2, 32):\n",
    "    clustering = KMeans(n_clusters=i, random_state=200)\n",
    "    clustering.fit(X_train_transformed)\n",
    "    wcss.append(clustering.inertia_)\n",
    "\n",
    "ks = list(range(2,32))\n",
    "\n",
    "sns.lineplot(x = ks, y = wcss);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c7b73",
   "metadata": {},
   "source": [
    "This looks like 5 clusters on 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc0c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 23):\n",
    "\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    # ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    # ax1.set_ylim([0, len(to_plot_tsne) + (i + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=i, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X_train)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X_train, cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        i,\n",
    "        \"The average silhouette_score is :\",\n",
    "        silhouette_avg,\n",
    "    )\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X_train, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for j in range(i):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        jth_cluster_silhouette_values = sample_silhouette_values[cluster_labels == j]\n",
    "\n",
    "        jth_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_j = jth_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_j\n",
    "\n",
    "        color = cm.nipy_spectral(float(j) / i)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            jth_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_j, str(j))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    # colors = cm.nipy_spectral(cluster_labels.astype(float) / i)\n",
    "    # ax2.scatter(\n",
    "    #     to_plot_tsne['x'], to_plot_tsne['y'], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    "    # )\n",
    "\n",
    "    # # Labeling the clusters\n",
    "    # centers = clusterer.cluster_centers_\n",
    "    # # Draw white circles at cluster centers\n",
    "    # ax2.scatter(\n",
    "    #     centers[:, 0],\n",
    "    #     centers[:, 1],\n",
    "    #     marker=\"o\",\n",
    "    #     c=\"white\",\n",
    "    #     alpha=1,\n",
    "    #     s=200,\n",
    "    #     edgecolor=\"k\",\n",
    "    # )\n",
    "\n",
    "    # for k, c in enumerate(centers):\n",
    "    #     ax2.scatter(c[0], c[1], marker=\"$%d$\" % k, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "    # ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    # ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    # ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
    "        % i,\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1048abb",
   "metadata": {},
   "source": [
    "Silhouette analyis still pretty inconclusive...elbow method said around 5, but 5 clusters doesn't look that good in silhouette analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76938b87",
   "metadata": {},
   "source": [
    "## Let's try ~~Truncated SVD~~ Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definte objective function to be maximized\n",
    "def objective(trial):\n",
    "    clusterer = trial.suggest_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a8278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f922d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for i in range(2, 33):\n",
    "    clustering = KMeans(n_clusters=i, random_state=200)\n",
    "    clustering.fit(X_train)\n",
    "    wcss.append(clustering.inertia_)\n",
    "\n",
    "ks = list(range(2,33))\n",
    "\n",
    "sns.lineplot(x = ks, y = wcss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = agglo.transform(X_train)\n",
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbe151",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for i in range(2, 32):\n",
    "    clustering = KMeans(n_clusters=i, random_state=200)\n",
    "    clustering.fit(X_train_transformed)\n",
    "    wcss.append(clustering.inertia_)\n",
    "\n",
    "ks = list(range(2,32))\n",
    "\n",
    "sns.lineplot(x = ks, y = wcss);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d2d665",
   "metadata": {},
   "source": [
    "This kinda looks like 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 33):\n",
    "\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    # ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    # ax1.set_ylim([0, len(to_plot_tsne) + (i + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=i, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X_train_transformed)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X_train_transformed, cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        i,\n",
    "        \"The average silhouette_score is :\",\n",
    "        silhouette_avg,\n",
    "    )\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X_train_transformed, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for j in range(i):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        jth_cluster_silhouette_values = sample_silhouette_values[cluster_labels == j]\n",
    "\n",
    "        jth_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_j = jth_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_j\n",
    "\n",
    "        color = cm.nipy_spectral(float(j) / i)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            jth_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_j, str(j))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    # colors = cm.nipy_spectral(cluster_labels.astype(float) / i)\n",
    "    # ax2.scatter(\n",
    "    #     to_plot_tsne['x'], to_plot_tsne['y'], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    "    # )\n",
    "\n",
    "    # # Labeling the clusters\n",
    "    # centers = clusterer.cluster_centers_\n",
    "    # # Draw white circles at cluster centers\n",
    "    # ax2.scatter(\n",
    "    #     centers[:, 0],\n",
    "    #     centers[:, 1],\n",
    "    #     marker=\"o\",\n",
    "    #     c=\"white\",\n",
    "    #     alpha=1,\n",
    "    #     s=200,\n",
    "    #     edgecolor=\"k\",\n",
    "    # )\n",
    "\n",
    "    # for k, c in enumerate(centers):\n",
    "    #     ax2.scatter(c[0], c[1], marker=\"$%d$\" % k, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "    # ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    # ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    # ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
    "        % i,\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b75fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7142e37045ca6e2f7ebd069a40dd15c94e2caae7a512958c86ea35c1f050d31a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
