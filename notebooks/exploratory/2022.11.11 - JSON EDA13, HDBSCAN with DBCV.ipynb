{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9afa101e-a9e5-4d1d-9e3e-416f1c767233",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Epicurious Scrape in a JSON file\n",
    "\n",
    "This is an idealized workflow for Aaron Chen in looking at data science problems. It likely isn't the best path, nor has he rigidly applied or stuck to this ideal, but he wishes that he worked this way more frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59c575-9aca-4d08-9b03-3425fa33cb03",
   "metadata": {},
   "source": [
    "## Purpose: This notebook will do some clustering and classification on the recipes missing cuisine labels. Make this fast and see what we can get. Then move on to:\n",
    "\n",
    "1. Fixing Render\n",
    "2. Creating login system to store searches and preferences\n",
    "3. Fixing the filtering\n",
    "4. Working on scrapers\n",
    "5. Working on the database\n",
    "\n",
    "### Author: Aaron Chen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21b7d4-5980-4adf-a62b-38b8e89031ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d4a89-cf20-435c-bcc0-6f1ebcd127c7",
   "metadata": {},
   "source": [
    "### If needed, run shell commands here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ed4e2d-6f77-4196-b548-d5896e13193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -c \"import tkinter\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cede1d1-3a00-4471-91ae-50be260464a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b66d7b-46ad-4f10-9cb9-72c03e319fea",
   "metadata": {},
   "source": [
    "## External Resources\n",
    "\n",
    "List out references or documentation that has helped you with this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b23fd3-6cf1-42b3-aee3-82306eaade6a",
   "metadata": {},
   "source": [
    "### Code\n",
    "Regex Checker: https://regex101.com/\n",
    "\n",
    "#### Scikit-learn\n",
    "1. https://scikit-learn.org/stable/modules/decomposition.html#latent-dirichlet-allocation-lda\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf83f44-334c-448a-afa7-187f63dd7285",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "For this notebook, the data is stored in the repo base folder/data/raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0dcb8e-5a84-4e96-b07d-24909352935d",
   "metadata": {},
   "source": [
    "### Process\n",
    "\n",
    "Are there steps or tutorials you are following? Those are things I try to list in Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6a44e4-081e-4f8f-88d2-3eccd0f2d767",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418bdb7-3ecf-4eb5-af6f-2c0e699d2394",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f480787a-b5ed-4bf2-8553-504d6cfffe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bokeh.plotting import figure, output_file, save, show\n",
    "# from bokeh.io import output_notebook\n",
    "import DBCV\n",
    "import hdbscan\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "import seaborn as sns\n",
    "# from sklearn.cluster import FeatureAgglomeration, KMeans\n",
    "# from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60dd0a-089e-41b7-9828-8f2b13648993",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde95259-0cd4-4ae1-8485-d51ada957529",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3ea1e-a26e-4545-b950-ec823cbd6a26",
   "metadata": {},
   "source": [
    "My workflow is to try things with code cells, then when the code cells get messy and repetitive, to convert into helper functions that can be called.\n",
    "\n",
    "When the helper functions are getting used a lot, it is usually better to convert them to scripts or classes that can be called/instantiated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fdd4b0-9acb-445e-acad-2b3eb6ab9e4c",
   "metadata": {},
   "source": [
    "### Import local script\n",
    "\n",
    "I started grouping this in with importing libraries, but putting them at the bottom of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ae4f42-17a3-4564-95b7-7993e5989d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awchen/Repos/Projects/MeaLeon/.venv/lib/python3.8/site-packages/spacy/util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import project_path\n",
    "\n",
    "import src.dataframe_preprocessor as dfpp\n",
    "import src.nlp_processor as nlp_proc\n",
    "import src.plotter as ILoveMyKeyboard\n",
    "import src.transformers as skt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b7742-3b22-4f48-877f-9f32cd7251fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7445bf0-0b00-45b9-a2db-84c568bced29",
   "metadata": {},
   "source": [
    "## Define global variables \n",
    "### Remember to refactor these out, not ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61418b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98b748-74ad-4dff-bebe-aa794f7a4591",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325f7ef-07c7-46b1-8595-9749259da76b",
   "metadata": {},
   "source": [
    "## Running Commentary\n",
    "\n",
    "1. \n",
    "\n",
    "### To Do\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2173e5-db8a-4fff-8072-98d6b16f7a4d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf870da-c2ed-4cde-9dd8-1591cbd2f24c",
   "metadata": {},
   "source": [
    "## Importing and viewing the data as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571d7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../../data/recipes-en-201706/epicurious-recipes_m2.json'\n",
    "\n",
    "joblib_basepath = '../../joblib/2022.08.23/'\n",
    "\n",
    "cv_path = joblib_basepath + 'countvec.joblib'\n",
    "tfidf_path = joblib_basepath + 'tfidf.joblib'\n",
    "full_df_path = joblib_basepath + 'recipes_with_cv.joblib'\n",
    "reduced_df_path = joblib_basepath + 'reduced_df.joblib'\n",
    "rfc_path = joblib_basepath + 'rfc_clf.joblib'\n",
    "X_path = joblib_basepath + 'X.joblib'\n",
    "y_path = joblib_basepath + 'y.joblib'\n",
    "truncSVD_path = joblib_basepath + 'truncSVD.joblib'\n",
    "truncSVD_transformed_path = joblib_basepath + 'truncSVD_transformed.joblib'\n",
    "svd_numpy_path = joblib_basepath + 'SVD_numpy.joblib'\n",
    "to_plot_path = joblib_basepath + 'to_plot.joblib'\n",
    "tsne_path = joblib_basepath + 'tsne.joblib'\n",
    "tsne_vis_path = joblib_basepath + 'tsne_vis.joblib'\n",
    "kmeans_path = joblib_basepath + 'kmeans.joblib'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cdaaf4",
   "metadata": {},
   "source": [
    "Let's get Optuna working with HDBSCAN and DBCV.\n",
    "\n",
    "Seems like the idea is to maximize the DBCV score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "938f47b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = load(cv_path)\n",
    "tfidf = load(tfidf_path)\n",
    "recipes_with_cv = load(full_df_path)\n",
    "recipes_with_cv.set_index('id', inplace=True, drop=True)\n",
    "reduced_df = load(reduced_df_path)\n",
    "reduced_df.set_index('id', inplace=True, drop=True)\n",
    "rfc_clf = load(rfc_path)\n",
    "X = load(X_path)\n",
    "y = load(y_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52539add",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=240, stratify=y\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05342a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>achiote</th>\n",
       "      <th>acid</th>\n",
       "      <th>addition</th>\n",
       "      <th>adobo</th>\n",
       "      <th>adobo adobo</th>\n",
       "      <th>adobo adobo sauce</th>\n",
       "      <th>adobo sauce</th>\n",
       "      <th>adobo sauce chipotle</th>\n",
       "      <th>african</th>\n",
       "      <th>agave</th>\n",
       "      <th>...</th>\n",
       "      <th>zest pith</th>\n",
       "      <th>zest vegetable</th>\n",
       "      <th>zinfandel</th>\n",
       "      <th>ziti</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zucchini blossom</th>\n",
       "      <th>zucchini crookneck</th>\n",
       "      <th>zucchini squash</th>\n",
       "      <th>árbol</th>\n",
       "      <th>árbol pepper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54a45bfb6529d92b2c023f25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a4638719925f464b395c16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a441126529d92b2c01b5f2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a409bb19925f464b37380a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a42e1019925f464b3818d4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a436266529d92b2c018767</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a466e16529d92b2c026f67</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a451cd6529d92b2c01eefd</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a44e026529d92b2c01d6dd</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54a45aa06529d92b2c02364f</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11124 rows × 3351 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          achiote  acid  addition  adobo  adobo adobo  \\\n",
       "id                                                                      \n",
       "54a45bfb6529d92b2c023f25      0.0   0.0       0.0    0.0          0.0   \n",
       "54a4638719925f464b395c16      0.0   0.0       0.0    0.0          0.0   \n",
       "54a441126529d92b2c01b5f2      0.0   0.0       0.0    0.0          0.0   \n",
       "54a409bb19925f464b37380a      0.0   0.0       0.0    0.0          0.0   \n",
       "54a42e1019925f464b3818d4      0.0   0.0       0.0    0.0          0.0   \n",
       "...                           ...   ...       ...    ...          ...   \n",
       "54a436266529d92b2c018767      0.0   0.0       0.0    0.0          0.0   \n",
       "54a466e16529d92b2c026f67      0.0   0.0       0.0    0.0          0.0   \n",
       "54a451cd6529d92b2c01eefd      0.0   0.0       0.0    0.0          0.0   \n",
       "54a44e026529d92b2c01d6dd      0.0   0.0       0.0    0.0          0.0   \n",
       "54a45aa06529d92b2c02364f      0.0   0.0       0.0    0.0          0.0   \n",
       "\n",
       "                          adobo adobo sauce  adobo sauce  \\\n",
       "id                                                         \n",
       "54a45bfb6529d92b2c023f25                0.0          0.0   \n",
       "54a4638719925f464b395c16                0.0          0.0   \n",
       "54a441126529d92b2c01b5f2                0.0          0.0   \n",
       "54a409bb19925f464b37380a                0.0          0.0   \n",
       "54a42e1019925f464b3818d4                0.0          0.0   \n",
       "...                                     ...          ...   \n",
       "54a436266529d92b2c018767                0.0          0.0   \n",
       "54a466e16529d92b2c026f67                0.0          0.0   \n",
       "54a451cd6529d92b2c01eefd                0.0          0.0   \n",
       "54a44e026529d92b2c01d6dd                0.0          0.0   \n",
       "54a45aa06529d92b2c02364f                0.0          0.0   \n",
       "\n",
       "                          adobo sauce chipotle  african  agave  ...  \\\n",
       "id                                                              ...   \n",
       "54a45bfb6529d92b2c023f25                   0.0      0.0    0.0  ...   \n",
       "54a4638719925f464b395c16                   0.0      0.0    0.0  ...   \n",
       "54a441126529d92b2c01b5f2                   0.0      0.0    0.0  ...   \n",
       "54a409bb19925f464b37380a                   0.0      0.0    0.0  ...   \n",
       "54a42e1019925f464b3818d4                   0.0      0.0    0.0  ...   \n",
       "...                                        ...      ...    ...  ...   \n",
       "54a436266529d92b2c018767                   0.0      0.0    0.0  ...   \n",
       "54a466e16529d92b2c026f67                   0.0      0.0    0.0  ...   \n",
       "54a451cd6529d92b2c01eefd                   0.0      0.0    0.0  ...   \n",
       "54a44e026529d92b2c01d6dd                   0.0      0.0    0.0  ...   \n",
       "54a45aa06529d92b2c02364f                   0.0      0.0    0.0  ...   \n",
       "\n",
       "                          zest pith  zest vegetable  zinfandel  ziti  \\\n",
       "id                                                                     \n",
       "54a45bfb6529d92b2c023f25        0.0             0.0        0.0   0.0   \n",
       "54a4638719925f464b395c16        0.0             0.0        0.0   0.0   \n",
       "54a441126529d92b2c01b5f2        0.0             0.0        0.0   0.0   \n",
       "54a409bb19925f464b37380a        0.0             0.0        0.0   0.0   \n",
       "54a42e1019925f464b3818d4        0.0             0.0        0.0   0.0   \n",
       "...                             ...             ...        ...   ...   \n",
       "54a436266529d92b2c018767        0.0             0.0        0.0   0.0   \n",
       "54a466e16529d92b2c026f67        0.0             0.0        0.0   0.0   \n",
       "54a451cd6529d92b2c01eefd        0.0             0.0        0.0   0.0   \n",
       "54a44e026529d92b2c01d6dd        0.0             0.0        0.0   0.0   \n",
       "54a45aa06529d92b2c02364f        0.0             0.0        0.0   0.0   \n",
       "\n",
       "                          zucchini  zucchini blossom  zucchini crookneck  \\\n",
       "id                                                                         \n",
       "54a45bfb6529d92b2c023f25       0.0               0.0                 0.0   \n",
       "54a4638719925f464b395c16       0.0               0.0                 0.0   \n",
       "54a441126529d92b2c01b5f2       0.0               0.0                 0.0   \n",
       "54a409bb19925f464b37380a       0.0               0.0                 0.0   \n",
       "54a42e1019925f464b3818d4       0.0               0.0                 0.0   \n",
       "...                            ...               ...                 ...   \n",
       "54a436266529d92b2c018767       0.0               0.0                 0.0   \n",
       "54a466e16529d92b2c026f67       0.0               0.0                 0.0   \n",
       "54a451cd6529d92b2c01eefd       0.0               0.0                 0.0   \n",
       "54a44e026529d92b2c01d6dd       0.0               0.0                 0.0   \n",
       "54a45aa06529d92b2c02364f       0.0               0.0                 0.0   \n",
       "\n",
       "                          zucchini squash  árbol  árbol pepper  \n",
       "id                                                              \n",
       "54a45bfb6529d92b2c023f25              0.0    0.0           0.0  \n",
       "54a4638719925f464b395c16              0.0    0.0           0.0  \n",
       "54a441126529d92b2c01b5f2              0.0    0.0           0.0  \n",
       "54a409bb19925f464b37380a              0.0    0.0           0.0  \n",
       "54a42e1019925f464b3818d4              0.0    0.0           0.0  \n",
       "...                                   ...    ...           ...  \n",
       "54a436266529d92b2c018767              0.0    0.0           0.0  \n",
       "54a466e16529d92b2c026f67              0.0    0.0           0.0  \n",
       "54a451cd6529d92b2c01eefd              0.0    0.0           0.0  \n",
       "54a44e026529d92b2c01d6dd              0.0    0.0           0.0  \n",
       "54a45aa06529d92b2c02364f              0.0    0.0           0.0  \n",
       "\n",
       "[11124 rows x 3351 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75fbe43",
   "metadata": {},
   "source": [
    "### Defining our trial (Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1d5210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-11 23:29:01,703]\u001b[0m A new study created in memory with name: no-name-eb775700-1241-4aec-998d-a531d9c3413e\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    cluster_size = trial.suggest_int('min_cluster_size', 10, 200)\n",
    "    min_samps = trial.suggest_int('min_samples', 5, 60)\n",
    "    cluster_selection_eps = trial.suggest_float('cluster_selection_epsilon', 0.2, 0.7)\n",
    "\n",
    "    hdbscanner = hdbscan.HDBSCAN(min_cluster_size=cluster_size, min_samples=min_samps, cluster_selection_epsilon=cluster_selection_eps)\n",
    "\n",
    "    hdbscan_labels = hdbscanner.fit_predict(X_train.values)\n",
    "    hdbscan_score = hdbscan.validity.validity_index(X_train.values, hdbscan_labels, metric='euclidean')\n",
    "    \n",
    "    return hdbscan_score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000) #, gc_after_trial=True)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f6b3d2",
   "metadata": {},
   "source": [
    "### ok! let's try manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281fe3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "manh_agglo = FeatureAgglomeration(n_clusters=5, affinity='manhattan', linkage='average')\n",
    "X_train_transformed = manh_agglo.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for i in range(2, 32):\n",
    "    clustering = KMeans(n_clusters=i, random_state=200)\n",
    "    clustering.fit(X_train_transformed)\n",
    "    wcss.append(clustering.inertia_)\n",
    "\n",
    "ks = list(range(2,32))\n",
    "\n",
    "sns.lineplot(x = ks, y = wcss);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c7b73",
   "metadata": {},
   "source": [
    "This looks like 5 clusters on 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc0c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 23):\n",
    "\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    # ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    # ax1.set_ylim([0, len(to_plot_tsne) + (i + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=i, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X_train)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X_train, cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        i,\n",
    "        \"The average silhouette_score is :\",\n",
    "        silhouette_avg,\n",
    "    )\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X_train, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for j in range(i):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        jth_cluster_silhouette_values = sample_silhouette_values[cluster_labels == j]\n",
    "\n",
    "        jth_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_j = jth_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_j\n",
    "\n",
    "        color = cm.nipy_spectral(float(j) / i)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            jth_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_j, str(j))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    # colors = cm.nipy_spectral(cluster_labels.astype(float) / i)\n",
    "    # ax2.scatter(\n",
    "    #     to_plot_tsne['x'], to_plot_tsne['y'], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    "    # )\n",
    "\n",
    "    # # Labeling the clusters\n",
    "    # centers = clusterer.cluster_centers_\n",
    "    # # Draw white circles at cluster centers\n",
    "    # ax2.scatter(\n",
    "    #     centers[:, 0],\n",
    "    #     centers[:, 1],\n",
    "    #     marker=\"o\",\n",
    "    #     c=\"white\",\n",
    "    #     alpha=1,\n",
    "    #     s=200,\n",
    "    #     edgecolor=\"k\",\n",
    "    # )\n",
    "\n",
    "    # for k, c in enumerate(centers):\n",
    "    #     ax2.scatter(c[0], c[1], marker=\"$%d$\" % k, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "    # ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    # ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    # ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
    "        % i,\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1048abb",
   "metadata": {},
   "source": [
    "Silhouette analyis still pretty inconclusive...elbow method said around 5, but 5 clusters doesn't look that good in silhouette analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76938b87",
   "metadata": {},
   "source": [
    "## Let's try ~~Truncated SVD~~ Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definte objective function to be maximized\n",
    "def objective(trial):\n",
    "    clusterer = trial.suggest_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a8278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f922d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for i in range(2, 33):\n",
    "    clustering = KMeans(n_clusters=i, random_state=200)\n",
    "    clustering.fit(X_train)\n",
    "    wcss.append(clustering.inertia_)\n",
    "\n",
    "ks = list(range(2,33))\n",
    "\n",
    "sns.lineplot(x = ks, y = wcss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = agglo.transform(X_train)\n",
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbe151",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for i in range(2, 32):\n",
    "    clustering = KMeans(n_clusters=i, random_state=200)\n",
    "    clustering.fit(X_train_transformed)\n",
    "    wcss.append(clustering.inertia_)\n",
    "\n",
    "ks = list(range(2,32))\n",
    "\n",
    "sns.lineplot(x = ks, y = wcss);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d2d665",
   "metadata": {},
   "source": [
    "This kinda looks like 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 33):\n",
    "\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    # ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    # ax1.set_ylim([0, len(to_plot_tsne) + (i + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=i, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X_train_transformed)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X_train_transformed, cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        i,\n",
    "        \"The average silhouette_score is :\",\n",
    "        silhouette_avg,\n",
    "    )\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X_train_transformed, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for j in range(i):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        jth_cluster_silhouette_values = sample_silhouette_values[cluster_labels == j]\n",
    "\n",
    "        jth_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_j = jth_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_j\n",
    "\n",
    "        color = cm.nipy_spectral(float(j) / i)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            jth_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_j, str(j))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    # colors = cm.nipy_spectral(cluster_labels.astype(float) / i)\n",
    "    # ax2.scatter(\n",
    "    #     to_plot_tsne['x'], to_plot_tsne['y'], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    "    # )\n",
    "\n",
    "    # # Labeling the clusters\n",
    "    # centers = clusterer.cluster_centers_\n",
    "    # # Draw white circles at cluster centers\n",
    "    # ax2.scatter(\n",
    "    #     centers[:, 0],\n",
    "    #     centers[:, 1],\n",
    "    #     marker=\"o\",\n",
    "    #     c=\"white\",\n",
    "    #     alpha=1,\n",
    "    #     s=200,\n",
    "    #     edgecolor=\"k\",\n",
    "    # )\n",
    "\n",
    "    # for k, c in enumerate(centers):\n",
    "    #     ax2.scatter(c[0], c[1], marker=\"$%d$\" % k, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "    # ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    # ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    # ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
    "        % i,\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b75fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7142e37045ca6e2f7ebd069a40dd15c94e2caae7a512958c86ea35c1f050d31a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
