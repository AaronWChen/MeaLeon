"""
This script groups together the NLP steps and creation/modification of the pandas dataframe containing all of the recipe information and then the TF-IDF transformed matrices concatenated on. It is intended to feed into the plotter script.
"""

# Import libraries
from datetime import datetime
from joblib import dump, load
import matplotlib.pyplot as plt
import matplotlib.text as mlt
import numpy as np
from openTSNE import TSNE
import pandas as pd
from sklearn.base import TransformerMixin
from sklearn.cluster import KMeans
from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
import spacy
import en_core_web_sm
from spacy.lang.en.stop_words import STOP_WORDS
from tqdm import tqdm
from typing import Any
import umap

# Other custom functions in same folder
import dataframe_preprocessor as dfpp
import nlp_processor as nlp_proc

def concat_matrices_to_df(df: pd.DataFrame, vectorized_ingred_matrix: scipy.sparse.csr_matrix, cv: ):
    """
    This function takes in a dataframe and concats the matrix generated by either CountVectorizer or TFIDF-Transformer onto the records so that the recipes can be used for classification purposes.

    Args: 
        df: preprocessed dataframe from preprocess_dataframe
        vectorized_ingred_matrix: sparse csr matrix created from doing fit_transform on the recipe_megalist
        cv: sklearn CountVectorizer object

    Returns:
        A pandas dataframe with the vectorized_ingred_matrix appended as columns to df
    """
    repo_tfidf_df = pd.DataFrame(vectorized_ingred_matrix.toarray(), columns=cv.get_feature_names_out(), index=df.index)
    return pd.concat([df, repo_tfidf_df], axis=1)

def prepare_dataframe(data_path: Text = "../../data/recipes-en-201706/epicurious-recipes_m2.json") -> pd.DataFrame:
    """

    """
    source_df = pd.read_json(path_or_buf=data_path)

    preprocessed_df = dfpp.preprocess_dataframe(df=source_df)

    return df

def prepare_nlp(stopwords_path: Text = "../../food_stopwords.csv"):

# filter and clean dataframe
# CountVectorizer, TF-IDF
# TruncatedSVD, tSNE
